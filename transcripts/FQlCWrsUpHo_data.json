{
  "video_id": "FQlCWrsUpHo",
  "video_url": "https://youtu.be/FQlCWrsUpHo?si=9tseEqqWy97euMp6",
  "title": "Turn ANY Website into LLM Knowledge in Seconds - EVOLVED",
  "channel": "Cole Medin",
  "upload_date": "20250501",
  "description": "One of the biggest challenges we face with LLMs is their knowledge is too general and limited for anything new. That\u2019s why RAG is such a huge topic when it comes to AI right now - it\u2019s a method for providing an LLM with external knowledge you curate so it can become an expert at something it wasn\u2019t before - a specific AI framework, your ecommerce store, you name it. The problem is, that \u201ccurate\u201d step can be very difficult and slow.\n\nThat is where Crawl4AI comes in! Crawl4AI is an open source web crawling framework specifically designed for scraping websites and formatting the output in the BEST possible way for an LLM to understand. Plus it\u2019s VERY fast (hence turning a website into LLM knowledge in seconds). I\u2019ve covered in on my channel before, but now I\u2019ve evolved how I\u2019ve used it and I want to share that with you! I\u2019ve created a template which I cover in this video that shows you how to use Crawl4AI to pretty much scrape ANY website with a few different strategies!\n\nI\u2019ve got you covered no matter if you are crawling sitemaps, llms.txt pages, or scraping a full site recursively through the navigation!\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nSign up for Aqua Voice with the link below and use the code ICEWATER when you check out for a 50% discount! I use Aqua Voice myself everywhere now, especially in my AI coding assistants, so it\u2019s a genuine recommendation from me!\n\nhttps://withaqua.com/r/cole/YTv1\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nMy Crawl4AI Agent (free template for you!):\n\nhttps://github.com/coleam00/ottomator-agents/tree/main/crawl4AI-agent-v2\n\nCrawl4AI Documentation:\n\nhttps://docs.crawl4ai.com/\n\nCrawl4AI GitHub:\n\nhttps://github.com/unclecode/crawl4ai\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n00:00 - The Magic of Crawl4AI\n01:01 - Crawl4AI Quickstart\n03:23 - Simple Crawl4AI Demo\n05:16 - Crawling Strategy #1 - Sitemaps\n05:53 - Crawling Strategy #2 - Recursive Scraping\n06:17 - Crawling Strategy #3 - llms-full.txt\n07:14 - Introducing my Crawl4AI Templates\n09:34 - Aqua Voice\n11:13 - Main RAG Agent Template\n12:04 - Crawl4AI Strategies in Action\n15:21 - Crawl4AI RAG Demo\n17:15 - Deep Dive into the Crawl4AI Implementations\n23:12 - Important Archon Updates\n25:59 - Outro\n\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nJoin me as I push the limits of what is possible with AI. I'll be uploading videos two times a week - Sundays and Wednesdays at 7:00 PM CDT!",
  "transcript": "Kind: captions Language: en A<00:00:00.400><c> while</c><00:00:00.560><c> ago</c><00:00:00.719><c> on</c><00:00:00.960><c> my</c><00:00:01.199><c> channel,</c><00:00:01.439><c> I</c><00:00:01.680><c> covered</c> A while ago on my channel, I covered A while ago on my channel, I covered Crawl<00:00:02.399><c> forAI,</c><00:00:03.120><c> an</c><00:00:03.360><c> incredible</c><00:00:03.919><c> open-</c><00:00:04.240><c> source</c> Crawl forAI, an incredible open- source Crawl forAI, an incredible open- source tool<00:00:04.799><c> for</c><00:00:04.960><c> you</c><00:00:05.120><c> to</c><00:00:05.279><c> crawl</c><00:00:05.600><c> pretty</c><00:00:05.839><c> much</c><00:00:06.080><c> any</c> tool for you to crawl pretty much any tool for you to crawl pretty much any website<00:00:07.040><c> to</c><00:00:07.279><c> get</c><00:00:07.359><c> it</c><00:00:07.520><c> into</c><00:00:07.759><c> the</c><00:00:07.919><c> perfect</c> website to get it into the perfect website to get it into the perfect format<00:00:08.639><c> for</c><00:00:08.960><c> LLM</c><00:00:09.519><c> knowledge</c><00:00:10.000><c> for</c><00:00:10.240><c> things</c><00:00:10.400><c> like</c> format for LLM knowledge for things like format for LLM knowledge for things like your<00:00:10.880><c> rag</c><00:00:11.280><c> AI</c><00:00:11.679><c> agents.</c><00:00:12.480><c> And</c><00:00:12.719><c> let</c><00:00:12.960><c> me</c><00:00:13.120><c> just</c><00:00:13.360><c> say,</c> your rag AI agents. And let me just say, your rag AI agents. And let me just say, the<00:00:13.840><c> feedback</c><00:00:14.160><c> that</c><00:00:14.400><c> I</c><00:00:14.559><c> got</c><00:00:14.719><c> on</c><00:00:14.880><c> that</c><00:00:15.040><c> video</c> the feedback that I got on that video the feedback that I got on that video was<00:00:15.679><c> amazing.</c><00:00:16.240><c> And</c><00:00:16.480><c> so</c><00:00:16.720><c> many</c><00:00:16.880><c> of</c><00:00:16.960><c> you</c><00:00:17.199><c> started</c> was amazing. And so many of you started was amazing. And so many of you started using<00:00:17.760><c> crawl</c><00:00:18.080><c> for</c><00:00:18.320><c> AI</c><00:00:18.720><c> for</c><00:00:18.960><c> your</c><00:00:19.199><c> own</c> using crawl for AI for your own using crawl for AI for your own projects,<00:00:20.000><c> including</c><00:00:20.400><c> myself</c><00:00:20.880><c> for</c><00:00:21.119><c> Archon,</c> projects, including myself for Archon, projects, including myself for Archon, my<00:00:22.080><c> open-source</c><00:00:22.720><c> AI</c><00:00:23.119><c> agent</c><00:00:23.519><c> builder.</c><00:00:24.000><c> So</c><00:00:24.240><c> now</c> my open-source AI agent builder. So now my open-source AI agent builder. So now I<00:00:24.640><c> want</c><00:00:24.720><c> to</c><00:00:24.880><c> take</c><00:00:25.039><c> crawl</c><00:00:25.359><c> for</c><00:00:25.600><c> AAI</c><00:00:26.080><c> much</c> I want to take crawl for AAI much I want to take crawl for AAI much further<00:00:26.720><c> with</c><00:00:26.960><c> you</c><00:00:27.279><c> because</c><00:00:27.599><c> a</c><00:00:27.920><c> lot</c><00:00:28.000><c> of</c><00:00:28.080><c> the</c> further with you because a lot of the further with you because a lot of the questions<00:00:28.560><c> that</c><00:00:28.800><c> you</c><00:00:28.960><c> guys</c><00:00:29.199><c> had</c><00:00:29.679><c> were</c><00:00:30.000><c> how</c><00:00:30.240><c> to</c> questions that you guys had were how to questions that you guys had were how to handle<00:00:30.800><c> different</c><00:00:31.119><c> kinds</c><00:00:31.439><c> of</c><00:00:31.599><c> websites.</c> handle different kinds of websites. handle different kinds of websites. Sometimes<00:00:32.640><c> we</c><00:00:32.800><c> have</c><00:00:32.880><c> a</c><00:00:33.120><c> sitemap</c><00:00:33.760><c> so</c><00:00:34.000><c> we</c><00:00:34.160><c> can</c> Sometimes we have a sitemap so we can Sometimes we have a sitemap so we can see<00:00:34.480><c> the</c><00:00:34.640><c> different</c><00:00:34.880><c> URLs</c><00:00:35.280><c> that</c><00:00:35.520><c> we</c><00:00:35.680><c> need</c><00:00:35.760><c> to</c> see the different URLs that we need to see the different URLs that we need to crawl.<00:00:36.480><c> Other</c><00:00:36.719><c> times</c><00:00:36.880><c> we</c><00:00:37.120><c> have</c><00:00:37.200><c> to</c><00:00:37.360><c> figure</c><00:00:37.600><c> it</c> crawl. Other times we have to figure it crawl. Other times we have to figure it out<00:00:37.920><c> ourselves</c><00:00:38.399><c> from</c><00:00:38.640><c> the</c><00:00:38.800><c> navigation</c><00:00:39.760><c> and</c> out ourselves from the navigation and out ourselves from the navigation and then<00:00:40.160><c> other</c><00:00:40.399><c> times</c><00:00:40.719><c> we</c><00:00:40.879><c> have</c><00:00:41.040><c> this</c><00:00:41.280><c> new</c><00:00:41.440><c> idea</c> then other times we have this new idea then other times we have this new idea of<00:00:41.920><c> an</c><00:00:42.520><c> LLM.ext</c><00:00:43.520><c> where</c><00:00:44.000><c> the</c><00:00:44.320><c> website</c><00:00:44.800><c> gives</c><00:00:45.120><c> us</c> of an LLM.ext where the website gives us of an LLM.ext where the website gives us a<00:00:45.600><c> single</c><00:00:45.920><c> page</c><00:00:46.239><c> with</c><00:00:46.559><c> all</c><00:00:46.800><c> the</c><00:00:47.039><c> documentation</c> a single page with all the documentation a single page with all the documentation specifically<00:00:48.559><c> for</c><00:00:48.800><c> us</c><00:00:48.960><c> to</c><00:00:49.200><c> give</c><00:00:49.440><c> to</c><00:00:49.760><c> our</c><00:00:50.079><c> LLMs.</c> specifically for us to give to our LLMs. specifically for us to give to our LLMs. And<00:00:51.200><c> so</c><00:00:51.440><c> right</c><00:00:51.600><c> now</c><00:00:51.840><c> I'm</c><00:00:52.079><c> going</c><00:00:52.160><c> to</c><00:00:52.320><c> show</c><00:00:52.399><c> you</c> And so right now I'm going to show you And so right now I'm going to show you how<00:00:52.800><c> to</c><00:00:52.960><c> handle</c><00:00:53.360><c> all</c><00:00:54.000><c> of</c><00:00:54.160><c> these</c><00:00:54.480><c> different</c> how to handle all of these different how to handle all of these different scenarios<00:00:55.360><c> with</c><00:00:55.600><c> Crawl</c><00:00:55.840><c> forAI</c><00:00:56.559><c> so</c><00:00:56.719><c> that</c><00:00:56.879><c> no</c> scenarios with Crawl forAI so that no scenarios with Crawl forAI so that no matter<00:00:57.280><c> what</c><00:00:57.600><c> kind</c><00:00:57.760><c> of</c><00:00:57.920><c> knowledge</c><00:00:58.239><c> you</c><00:00:58.399><c> want</c> matter what kind of knowledge you want matter what kind of knowledge you want to<00:00:58.559><c> bring</c><00:00:58.719><c> into</c><00:00:58.960><c> your</c><00:00:59.120><c> LLMs,</c><00:00:59.760><c> you</c><00:00:59.920><c> can</c><00:01:00.079><c> do</c><00:01:00.160><c> that</c> to bring into your LLMs, you can do that to bring into your LLMs, you can do that in<00:01:00.800><c> seconds.</c><00:01:01.680><c> So</c><00:01:01.920><c> here</c><00:01:02.160><c> is</c><00:01:02.320><c> the</c><00:01:02.480><c> homepage</c><00:01:02.960><c> for</c> in seconds. So here is the homepage for in seconds. So here is the homepage for the<00:01:03.359><c> Crawl</c><00:01:03.680><c> for</c><00:01:04.000><c> AI</c><00:01:04.400><c> documentation.</c><00:01:05.280><c> I'll</c> the Crawl for AI documentation. I'll the Crawl for AI documentation. I'll have<00:01:05.519><c> a</c><00:01:05.680><c> link</c><00:01:05.840><c> to</c><00:01:05.920><c> this</c><00:01:06.080><c> in</c><00:01:06.320><c> the</c><00:01:06.479><c> description</c> have a link to this in the description have a link to this in the description as<00:01:07.040><c> well</c><00:01:07.280><c> because</c><00:01:07.600><c> this</c><00:01:07.840><c> is</c><00:01:08.000><c> my</c><00:01:08.240><c> resource</c><00:01:08.960><c> for</c> as well because this is my resource for as well because this is my resource for all<00:01:09.520><c> of</c><00:01:09.680><c> the</c><00:01:09.920><c> code</c><00:01:10.080><c> that</c><00:01:10.240><c> I</c><00:01:10.400><c> have</c><00:01:10.560><c> created</c><00:01:10.720><c> that</c> all of the code that I have created that all of the code that I have created that I'll<00:01:11.119><c> show</c><00:01:11.280><c> you</c><00:01:11.439><c> throughout</c><00:01:11.760><c> this</c><00:01:12.000><c> video.</c><00:01:12.560><c> And</c> I'll show you throughout this video. And I'll show you throughout this video. And I<00:01:12.880><c> covered</c><00:01:13.119><c> this</c><00:01:13.360><c> on</c><00:01:13.520><c> my</c><00:01:13.760><c> channel</c><00:01:14.000><c> before.</c> I covered this on my channel before. I covered this on my channel before. I've<00:01:14.640><c> talked</c><00:01:14.799><c> about</c><00:01:14.960><c> Crawl</c><00:01:15.280><c> for</c><00:01:15.520><c> AI,</c><00:01:15.840><c> but</c><00:01:16.159><c> a</c> I've talked about Crawl for AI, but a I've talked about Crawl for AI, but a lot<00:01:16.560><c> has</c><00:01:16.799><c> changed</c><00:01:17.200><c> and</c><00:01:17.520><c> this</c><00:01:17.840><c> project</c><00:01:18.159><c> has</c> lot has changed and this project has lot has changed and this project has completely<00:01:19.119><c> blown</c><00:01:19.520><c> up</c><00:01:19.680><c> recently.</c><00:01:20.400><c> Take</c><00:01:20.560><c> a</c> completely blown up recently. Take a completely blown up recently. Take a look<00:01:20.799><c> at</c><00:01:20.880><c> this.</c><00:01:21.119><c> It's</c><00:01:21.360><c> completely</c><00:01:21.680><c> open</c> look at this. It's completely open look at this. It's completely open source,<00:01:22.240><c> so</c><00:01:22.400><c> it's</c><00:01:22.560><c> on</c><00:01:22.720><c> GitHub.</c><00:01:23.439><c> And</c><00:01:23.600><c> the</c><00:01:23.840><c> repo</c> source, so it's on GitHub. And the repo source, so it's on GitHub. And the repo currently<00:01:24.560><c> has</c><00:01:25.400><c> 42,000</c><00:01:26.400><c> stars,</c><00:01:26.880><c> which</c><00:01:27.119><c> is</c> currently has 42,000 stars, which is currently has 42,000 stars, which is just<00:01:27.600><c> amazing.</c><00:01:28.400><c> People</c><00:01:28.640><c> are</c><00:01:28.880><c> realizing</c><00:01:29.280><c> that</c> just amazing. People are realizing that just amazing. People are realizing that this<00:01:29.759><c> tool</c><00:01:30.240><c> is</c><00:01:30.479><c> just</c><00:01:30.640><c> the</c><00:01:30.880><c> best</c><00:01:31.119><c> at</c><00:01:31.360><c> what</c><00:01:31.520><c> it</c> this tool is just the best at what it this tool is just the best at what it does.<00:01:32.320><c> And</c><00:01:32.560><c> scraping</c><00:01:32.960><c> the</c><00:01:33.200><c> internet</c><00:01:33.680><c> to</c> does. And scraping the internet to does. And scraping the internet to create<00:01:34.400><c> knowledge</c><00:01:34.720><c> for</c><00:01:35.200><c> our</c><00:01:35.520><c> LLMs</c><00:01:36.079><c> is</c><00:01:36.320><c> really</c> create knowledge for our LLMs is really create knowledge for our LLMs is really important<00:01:37.119><c> because</c><00:01:37.360><c> a</c><00:01:37.680><c> lot</c><00:01:37.759><c> of</c><00:01:37.920><c> the</c><00:01:38.079><c> knowledge</c> important because a lot of the knowledge important because a lot of the knowledge we<00:01:38.640><c> give</c><00:01:38.799><c> our</c><00:01:39.040><c> agents</c><00:01:39.680><c> comes</c><00:01:40.000><c> from</c><00:01:40.159><c> the</c> we give our agents comes from the we give our agents comes from the internet.<00:01:40.640><c> So,</c><00:01:40.799><c> we</c><00:01:40.960><c> need</c><00:01:41.040><c> a</c><00:01:41.200><c> way</c><00:01:41.360><c> to</c><00:01:41.520><c> scrape</c> internet. So, we need a way to scrape internet. So, we need a way to scrape that<00:01:42.079><c> effectively</c><00:01:42.560><c> and</c><00:01:42.720><c> to</c><00:01:42.960><c> do</c><00:01:43.040><c> it</c><00:01:43.280><c> quickly.</c> that effectively and to do it quickly. that effectively and to do it quickly. And<00:01:44.159><c> Crawl</c><00:01:44.479><c> for</c><00:01:44.720><c> AI</c><00:01:45.200><c> definitely</c><00:01:45.680><c> gives</c><00:01:45.920><c> us</c> And Crawl for AI definitely gives us And Crawl for AI definitely gives us both<00:01:46.399><c> of</c><00:01:46.640><c> those</c><00:01:46.880><c> things.</c><00:01:47.439><c> It</c><00:01:47.680><c> is</c><00:01:47.920><c> blazing</c> both of those things. It is blazing both of those things. It is blazing fast,<00:01:49.040><c> as</c><00:01:49.280><c> we'll</c><00:01:49.439><c> see</c><00:01:49.600><c> in</c><00:01:49.759><c> some</c><00:01:49.920><c> of</c><00:01:50.000><c> my</c><00:01:50.159><c> demos</c> fast, as we'll see in some of my demos fast, as we'll see in some of my demos that<00:01:50.640><c> I</c><00:01:50.799><c> have</c><00:01:50.880><c> for</c><00:01:51.040><c> you</c><00:01:51.200><c> in</c><00:01:51.360><c> a</c><00:01:51.520><c> bit.</c><00:01:52.079><c> And</c><00:01:52.320><c> it</c> that I have for you in a bit. And it that I have for you in a bit. And it produces<00:01:53.360><c> webpage</c><00:01:53.920><c> data</c><00:01:54.240><c> that</c><00:01:54.479><c> is</c><00:01:54.640><c> AI</c><00:01:55.119><c> ready.</c> produces webpage data that is AI ready. produces webpage data that is AI ready. It<00:01:55.920><c> spits</c><00:01:56.240><c> out</c><00:01:56.399><c> what's</c><00:01:56.640><c> called</c><00:01:56.880><c> markdown</c> It spits out what's called markdown It spits out what's called markdown format,<00:01:57.840><c> which</c><00:01:58.079><c> is</c><00:01:58.159><c> just</c><00:01:58.320><c> the</c><00:01:58.479><c> optimal</c><00:01:58.880><c> format</c> format, which is just the optimal format format, which is just the optimal format for<00:01:59.439><c> LLMs</c><00:02:00.000><c> to</c><00:02:00.479><c> understand</c><00:02:00.880><c> these</c><00:02:01.200><c> pages</c><00:02:01.520><c> and</c> for LLMs to understand these pages and for LLMs to understand these pages and pick<00:02:02.000><c> out</c><00:02:02.240><c> distinct</c><00:02:02.799><c> sections</c><00:02:03.200><c> from</c><00:02:03.439><c> them.</c> pick out distinct sections from them. pick out distinct sections from them. And<00:02:04.000><c> if</c><00:02:04.159><c> you're</c><00:02:04.399><c> curious</c><00:02:04.880><c> how</c><00:02:05.200><c> projects</c><00:02:05.600><c> like</c> And if you're curious how projects like And if you're curious how projects like Context<00:02:06.719><c> 7</c><00:02:07.280><c> are</c><00:02:07.520><c> able</c><00:02:07.759><c> to</c><00:02:08.000><c> scrape</c><00:02:08.319><c> up-to-date</c> Context 7 are able to scrape up-to-date Context 7 are able to scrape up-to-date documentation<00:02:09.599><c> constantly</c><00:02:10.160><c> to</c><00:02:10.479><c> provide</c><00:02:10.720><c> that</c> documentation constantly to provide that documentation constantly to provide that to<00:02:11.200><c> AI</c><00:02:11.520><c> coding</c><00:02:11.920><c> assistants,</c><00:02:12.800><c> I</c><00:02:13.040><c> can</c><00:02:13.200><c> guarantee</c> to AI coding assistants, I can guarantee to AI coding assistants, I can guarantee that<00:02:13.760><c> they're</c><00:02:14.080><c> using</c><00:02:14.319><c> something</c><00:02:14.640><c> like</c><00:02:15.040><c> crawl</c> that they're using something like crawl that they're using something like crawl for<00:02:15.599><c> AAI.</c><00:02:16.160><c> And</c><00:02:16.319><c> it</c><00:02:16.480><c> wouldn't</c><00:02:16.800><c> surprise</c><00:02:17.120><c> me</c><00:02:17.200><c> if</c> for AAI. And it wouldn't surprise me if for AAI. And it wouldn't surprise me if they<00:02:17.680><c> actually</c><00:02:18.000><c> are</c><00:02:18.239><c> using</c><00:02:18.560><c> crawl</c><00:02:18.959><c> for</c><00:02:19.200><c> AAI</c><00:02:19.680><c> to</c> they actually are using crawl for AAI to they actually are using crawl for AAI to scrape<00:02:20.239><c> all</c><00:02:20.400><c> the</c><00:02:20.560><c> documentation</c><00:02:21.040><c> for</c> scrape all the documentation for scrape all the documentation for Superbase<00:02:21.920><c> and</c><00:02:22.080><c> Fast</c><00:02:22.400><c> API,</c><00:02:23.200><c> MCP,</c><00:02:23.840><c> Nex.js,</c><00:02:24.560><c> all</c> Superbase and Fast API, MCP, Nex.js, all Superbase and Fast API, MCP, Nex.js, all these<00:02:24.959><c> different</c><00:02:25.120><c> libraries</c><00:02:25.599><c> because</c><00:02:25.920><c> it's</c> these different libraries because it's these different libraries because it's so<00:02:26.400><c> fast</c><00:02:26.959><c> and</c><00:02:27.280><c> so</c><00:02:27.599><c> efficient.</c><00:02:28.319><c> And</c><00:02:28.480><c> it's</c><00:02:28.640><c> also</c> so fast and so efficient. And it's also so fast and so efficient. And it's also what<00:02:29.040><c> I</c><00:02:29.120><c> use</c><00:02:29.280><c> for</c><00:02:29.520><c> Archon,</c><00:02:30.080><c> my</c><00:02:30.239><c> AI</c><00:02:30.560><c> agent</c> what I use for Archon, my AI agent what I use for Archon, my AI agent builder,<00:02:31.440><c> like</c><00:02:31.599><c> I</c><00:02:31.760><c> mentioned</c><00:02:32.080><c> in</c><00:02:32.239><c> the</c><00:02:32.400><c> intro,</c> builder, like I mentioned in the intro, builder, like I mentioned in the intro, which<00:02:33.200><c> speaking</c><00:02:33.519><c> of</c><00:02:33.760><c> Archon,</c><00:02:34.560><c> I</c><00:02:34.800><c> have</c><00:02:35.040><c> some</c> which speaking of Archon, I have some which speaking of Archon, I have some big<00:02:35.599><c> updates</c><00:02:35.920><c> for</c><00:02:36.160><c> that</c><00:02:36.480><c> slash</c><00:02:36.959><c> potential</c> big updates for that slash potential big updates for that slash potential changes<00:02:37.840><c> of</c><00:02:38.000><c> plans</c><00:02:38.480><c> that</c><00:02:38.640><c> I</c><00:02:38.879><c> definitely</c><00:02:39.120><c> want</c> changes of plans that I definitely want changes of plans that I definitely want to<00:02:39.440><c> get</c><00:02:39.519><c> your</c><00:02:39.840><c> feedback</c><00:02:40.160><c> on.</c><00:02:40.480><c> So,</c><00:02:40.640><c> if</c><00:02:40.800><c> you're</c> to get your feedback on. So, if you're to get your feedback on. So, if you're interested<00:02:41.120><c> in</c><00:02:41.280><c> Archon,</c><00:02:42.080><c> please</c><00:02:42.319><c> stay</c><00:02:42.560><c> tuned</c> interested in Archon, please stay tuned interested in Archon, please stay tuned for<00:02:42.959><c> the</c><00:02:43.120><c> end</c><00:02:43.200><c> of</c><00:02:43.360><c> this</c><00:02:43.519><c> video.</c><00:02:43.760><c> I</c><00:02:43.920><c> want</c><00:02:44.000><c> to</c> for the end of this video. I want to for the end of this video. I want to share<00:02:44.239><c> some</c><00:02:44.480><c> things</c><00:02:44.560><c> with</c><00:02:44.720><c> you</c><00:02:44.879><c> on</c><00:02:45.120><c> that.</c><00:02:45.440><c> But</c> share some things with you on that. But share some things with you on that. But right<00:02:45.840><c> now</c><00:02:46.000><c> I</c><00:02:46.160><c> want</c><00:02:46.239><c> to</c><00:02:46.400><c> focus</c><00:02:46.560><c> on</c><00:02:46.800><c> crawl</c><00:02:47.200><c> for</c> right now I want to focus on crawl for right now I want to focus on crawl for AAI.<00:02:48.239><c> And</c><00:02:48.400><c> then</c><00:02:48.560><c> in</c><00:02:48.800><c> the</c><00:02:48.959><c> documentation</c><00:02:49.599><c> for</c> AAI. And then in the documentation for AAI. And then in the documentation for crawl<00:02:50.239><c> for</c><00:02:50.480><c> AI</c><00:02:50.800><c> on</c><00:02:50.959><c> their</c><00:02:51.120><c> homepage</c><00:02:51.840><c> they</c><00:02:52.000><c> have</c> crawl for AI on their homepage they have crawl for AI on their homepage they have a<00:02:52.319><c> quick</c><00:02:52.560><c> start</c><00:02:52.800><c> that</c><00:02:53.040><c> shows</c><00:02:53.200><c> us</c><00:02:53.360><c> at</c><00:02:53.519><c> a</c><00:02:53.680><c> high</c> a quick start that shows us at a high a quick start that shows us at a high level<00:02:54.319><c> how</c><00:02:54.560><c> we</c><00:02:54.800><c> can</c><00:02:54.959><c> build</c><00:02:55.280><c> this</c><00:02:55.519><c> crawler</c><00:02:55.920><c> and</c> level how we can build this crawler and level how we can build this crawler and then<00:02:56.319><c> use</c><00:02:56.560><c> it</c><00:02:56.720><c> to</c><00:02:57.040><c> crawl</c><00:02:57.440><c> pretty</c><00:02:57.760><c> much</c><00:02:57.920><c> any</c><00:02:58.239><c> URL</c> then use it to crawl pretty much any URL then use it to crawl pretty much any URL that<00:02:58.879><c> we</c><00:02:59.040><c> give</c><00:02:59.200><c> it.</c><00:02:59.440><c> It</c><00:02:59.599><c> is</c><00:02:59.760><c> so</c><00:03:00.080><c> easy</c><00:03:00.400><c> to</c><00:03:00.720><c> use</c> that we give it. It is so easy to use that we give it. It is so easy to use this.<00:03:01.760><c> And</c><00:03:01.920><c> then</c><00:03:02.159><c> within</c><00:03:02.640><c> their</c><00:03:02.959><c> installation</c> this. And then within their installation this. And then within their installation instructions<00:03:04.080><c> we</c><00:03:04.239><c> can</c><00:03:04.319><c> see</c><00:03:04.480><c> just</c><00:03:04.720><c> how</c><00:03:05.040><c> easy</c><00:03:05.280><c> it</c> instructions we can see just how easy it instructions we can see just how easy it is<00:03:05.519><c> to</c><00:03:05.760><c> set</c><00:03:05.920><c> this</c><00:03:06.159><c> up.</c><00:03:06.640><c> You</c><00:03:06.800><c> just</c><00:03:06.959><c> have</c><00:03:07.120><c> to</c><00:03:07.200><c> have</c> is to set this up. You just have to have is to set this up. You just have to have Python<00:03:07.840><c> installed</c><00:03:08.319><c> and</c><00:03:08.560><c> then</c><00:03:08.640><c> you</c><00:03:08.800><c> can</c><00:03:08.879><c> pip</c> Python installed and then you can pip Python installed and then you can pip install<00:03:09.599><c> crawl</c><00:03:09.840><c> for</c><00:03:10.080><c> AI</c><00:03:10.640><c> and</c><00:03:10.800><c> then</c><00:03:11.040><c> run</c><00:03:11.200><c> their</c> install crawl for AI and then run their install crawl for AI and then run their setup<00:03:11.840><c> command</c><00:03:12.239><c> to</c><00:03:12.800><c> install</c><00:03:13.200><c> the</c><00:03:13.360><c> playright</c> setup command to install the playright setup command to install the playright browser<00:03:14.159><c> so</c><00:03:14.319><c> that</c><00:03:14.480><c> your</c><00:03:14.800><c> terminal</c><00:03:15.280><c> can</c><00:03:15.519><c> run</c><00:03:15.680><c> a</c> browser so that your terminal can run a browser so that your terminal can run a browser<00:03:16.159><c> to</c><00:03:16.319><c> scrape</c><00:03:16.640><c> pages</c><00:03:16.959><c> under</c><00:03:17.200><c> the</c><00:03:17.360><c> hood</c> browser to scrape pages under the hood browser to scrape pages under the hood and<00:03:17.920><c> do</c><00:03:18.080><c> the</c><00:03:18.239><c> rest</c><00:03:18.400><c> of</c><00:03:18.560><c> the</c><00:03:18.800><c> necessary</c><00:03:19.280><c> setup.</c> and do the rest of the necessary setup. and do the rest of the necessary setup. So<00:03:19.760><c> that's</c><00:03:20.000><c> all</c><00:03:20.159><c> you</c><00:03:20.319><c> have</c><00:03:20.400><c> to</c><00:03:20.560><c> run</c><00:03:20.800><c> to</c><00:03:21.040><c> get</c> So that's all you have to run to get So that's all you have to run to get things<00:03:21.440><c> set</c><00:03:21.680><c> up</c><00:03:22.000><c> and</c><00:03:22.239><c> then</c><00:03:22.319><c> I</c><00:03:22.480><c> can</c><00:03:22.560><c> show</c><00:03:22.720><c> you</c> things set up and then I can show you things set up and then I can show you that<00:03:22.959><c> within</c><00:03:23.360><c> my</c><00:03:23.760><c> windsurf</c><00:03:24.319><c> here</c><00:03:24.560><c> I</c><00:03:24.800><c> have</c><00:03:25.040><c> a</c> that within my windsurf here I have a that within my windsurf here I have a first<00:03:25.519><c> example</c><00:03:25.920><c> to</c><00:03:26.080><c> show</c><00:03:26.159><c> you</c><00:03:26.400><c> really</c><00:03:26.560><c> quickly</c> first example to show you really quickly first example to show you really quickly which<00:03:27.120><c> is</c><00:03:27.360><c> definitely</c><00:03:27.760><c> inspired</c><00:03:28.239><c> by</c><00:03:28.480><c> the</c> which is definitely inspired by the which is definitely inspired by the quick<00:03:28.959><c> start</c><00:03:29.200><c> that</c><00:03:29.360><c> we</c><00:03:29.599><c> just</c><00:03:29.760><c> saw.</c><00:03:30.239><c> So</c><00:03:30.480><c> I</c> quick start that we just saw. So I quick start that we just saw. So I create<00:03:30.959><c> this</c><00:03:31.280><c> instance</c><00:03:31.680><c> of</c><00:03:31.840><c> an</c><00:03:32.080><c> async</c><00:03:32.480><c> web</c> create this instance of an async web create this instance of an async web crawler<00:03:33.120><c> through</c><00:03:33.360><c> crawl</c><00:03:33.680><c> for</c><00:03:33.920><c> AAI.</c><00:03:34.480><c> And</c><00:03:34.640><c> then</c> crawler through crawl for AAI. And then crawler through crawl for AAI. And then the<00:03:34.959><c> URL</c><00:03:35.280><c> that</c><00:03:35.440><c> I'm</c><00:03:35.599><c> having</c><00:03:35.760><c> it</c><00:03:36.000><c> scrape</c><00:03:36.400><c> is</c><00:03:36.640><c> the</c> the URL that I'm having it scrape is the the URL that I'm having it scrape is the Pantic<00:03:37.599><c> AI</c><00:03:38.120><c> documentation.</c><00:03:39.120><c> And</c><00:03:39.280><c> so</c><00:03:39.519><c> going</c> Pantic AI documentation. And so going Pantic AI documentation. And so going back<00:03:39.920><c> to</c><00:03:40.159><c> my</c><00:03:40.400><c> browser</c><00:03:40.720><c> here,</c><00:03:40.959><c> I'll</c><00:03:41.120><c> show</c><00:03:41.200><c> you</c> back to my browser here, I'll show you back to my browser here, I'll show you that<00:03:41.920><c> this</c><00:03:42.159><c> is</c><00:03:42.319><c> the</c><00:03:42.560><c> page</c><00:03:42.720><c> that</c><00:03:42.959><c> we</c><00:03:43.200><c> are</c><00:03:43.360><c> about</c> that this is the page that we are about that this is the page that we are about to<00:03:43.760><c> scrape</c><00:03:44.080><c> with</c><00:03:44.400><c> crawl</c><00:03:44.720><c> for</c><00:03:44.959><c> AI.</c><00:03:45.599><c> And</c><00:03:45.760><c> I</c><00:03:46.000><c> could</c> to scrape with crawl for AI. And I could to scrape with crawl for AI. And I could just<00:03:46.400><c> take</c><00:03:46.560><c> the</c><00:03:46.879><c> raw</c><00:03:47.280><c> HTML</c><00:03:47.760><c> of</c><00:03:48.000><c> this</c><00:03:48.159><c> page</c><00:03:48.319><c> and</c> just take the raw HTML of this page and just take the raw HTML of this page and give<00:03:48.640><c> it</c><00:03:48.720><c> to</c><00:03:48.879><c> an</c><00:03:49.040><c> LLM,</c><00:03:49.680><c> but</c><00:03:49.840><c> it's</c><00:03:50.080><c> not</c><00:03:50.239><c> going</c><00:03:50.319><c> to</c> give it to an LLM, but it's not going to give it to an LLM, but it's not going to be<00:03:50.560><c> able</c><00:03:50.720><c> to</c><00:03:50.799><c> pick</c><00:03:51.040><c> out</c><00:03:51.200><c> different</c><00:03:51.519><c> sections</c> be able to pick out different sections be able to pick out different sections very<00:03:52.159><c> well</c><00:03:52.480><c> and</c><00:03:52.720><c> just</c><00:03:52.959><c> understand</c><00:03:53.360><c> the</c><00:03:53.599><c> page</c> very well and just understand the page very well and just understand the page as<00:03:54.000><c> well</c><00:03:54.239><c> as</c><00:03:54.480><c> if</c><00:03:54.640><c> we</c><00:03:54.799><c> give</c><00:03:54.879><c> it</c><00:03:55.040><c> the</c><00:03:55.200><c> markdown</c> as well as if we give it the markdown as well as if we give it the markdown format.<00:03:56.080><c> And</c><00:03:56.159><c> I'll</c><00:03:56.400><c> show</c><00:03:56.480><c> you</c><00:03:56.640><c> in</c><00:03:56.799><c> a</c><00:03:56.959><c> second</c> format. And I'll show you in a second format. And I'll show you in a second exactly<00:03:57.599><c> what</c><00:03:57.760><c> that</c><00:03:58.000><c> looks</c><00:03:58.159><c> like</c><00:03:58.239><c> when</c><00:03:58.480><c> we</c><00:03:58.640><c> run</c> exactly what that looks like when we run exactly what that looks like when we run this<00:03:59.040><c> script.</c><00:03:59.680><c> And</c><00:03:59.920><c> so</c><00:04:00.159><c> this</c><00:04:00.400><c> page</c><00:04:00.720><c> right</c><00:04:00.959><c> here</c> this script. And so this page right here this script. And so this page right here is<00:04:01.680><c> what</c><00:04:01.840><c> we're</c><00:04:02.080><c> going</c><00:04:02.159><c> to</c><00:04:02.480><c> transform</c><00:04:03.200><c> into</c> is what we're going to transform into is what we're going to transform into LLM<00:04:04.239><c> knowledge.</c><00:04:05.040><c> And</c><00:04:05.200><c> so</c><00:04:05.280><c> I</c><00:04:05.519><c> have</c><00:04:05.680><c> my</c><00:04:05.840><c> terminal</c> LLM knowledge. And so I have my terminal LLM knowledge. And so I have my terminal open.<00:04:07.040><c> Um</c><00:04:07.280><c> and</c><00:04:07.519><c> I'm</c><00:04:07.760><c> going</c><00:04:07.840><c> to</c><00:04:07.920><c> just</c><00:04:08.159><c> run</c><00:04:08.319><c> that</c> open. Um and I'm going to just run that open. Um and I'm going to just run that exact<00:04:08.879><c> same</c><00:04:09.120><c> script</c><00:04:09.360><c> that</c><00:04:09.599><c> I</c><00:04:09.840><c> just</c><00:04:10.080><c> showed</c> exact same script that I just showed exact same script that I just showed you.<00:04:10.720><c> And</c><00:04:10.879><c> on</c><00:04:11.120><c> top</c><00:04:11.280><c> of</c><00:04:11.439><c> getting</c><00:04:11.760><c> this</c> you. And on top of getting this you. And on top of getting this beautiful<00:04:12.319><c> markdown</c><00:04:12.799><c> format</c><00:04:13.040><c> that</c><00:04:13.200><c> you'll</c> beautiful markdown format that you'll beautiful markdown format that you'll see<00:04:13.439><c> in</c><00:04:13.599><c> a</c><00:04:13.680><c> second,</c><00:04:13.920><c> you'll</c><00:04:14.159><c> also</c><00:04:14.400><c> see</c><00:04:14.560><c> just</c> see in a second, you'll also see just see in a second, you'll also see just how<00:04:15.120><c> fast</c><00:04:15.280><c> that</c><00:04:15.519><c> is.</c><00:04:15.760><c> Just</c><00:04:15.920><c> take</c><00:04:16.000><c> a</c><00:04:16.079><c> look</c><00:04:16.160><c> at</c> how fast that is. Just take a look at how fast that is. Just take a look at that.<00:04:16.560><c> It</c><00:04:16.720><c> just</c><00:04:16.959><c> in</c><00:04:17.359><c> seconds</c><00:04:17.759><c> scraped</c><00:04:18.079><c> this</c> that. It just in seconds scraped this that. It just in seconds scraped this entire<00:04:18.639><c> page</c><00:04:19.199><c> and</c><00:04:19.440><c> formatted</c><00:04:20.000><c> it</c><00:04:20.160><c> for</c><00:04:20.320><c> us</c><00:04:20.479><c> into</c> entire page and formatted it for us into entire page and formatted it for us into something<00:04:20.959><c> that</c><00:04:21.199><c> is</c><00:04:21.440><c> much</c><00:04:21.680><c> easier</c><00:04:22.079><c> for</c><00:04:22.639><c> our</c> something that is much easier for our something that is much easier for our agents<00:04:23.280><c> and</c><00:04:23.440><c> LLMs</c><00:04:24.080><c> to</c><00:04:24.320><c> understand.</c><00:04:25.199><c> And</c><00:04:25.440><c> so</c><00:04:25.600><c> we</c> agents and LLMs to understand. And so we agents and LLMs to understand. And so we have<00:04:26.160><c> these</c><00:04:26.560><c> bullet</c><00:04:26.880><c> points</c><00:04:27.199><c> and</c><00:04:27.440><c> then</c><00:04:27.600><c> we</c> have these bullet points and then we have these bullet points and then we have<00:04:27.919><c> the</c><00:04:28.560><c> markdown</c><00:04:29.040><c> where</c><00:04:29.280><c> we</c><00:04:29.440><c> have</c><00:04:29.520><c> the</c> have the markdown where we have the have the markdown where we have the different<00:04:30.000><c> headings</c><00:04:30.479><c> and</c><00:04:30.720><c> the</c><00:04:30.880><c> subheadings.</c> different headings and the subheadings. different headings and the subheadings. And<00:04:31.919><c> so</c><00:04:32.160><c> everything</c><00:04:32.400><c> is</c><00:04:32.560><c> just</c><00:04:32.880><c> very</c> And so everything is just very And so everything is just very structured<00:04:33.919><c> for</c><00:04:34.240><c> our</c><00:04:34.479><c> agents.</c><00:04:35.280><c> And</c><00:04:35.440><c> so</c><00:04:35.600><c> that's</c> structured for our agents. And so that's structured for our agents. And so that's my<00:04:36.080><c> first</c><00:04:36.400><c> example</c><00:04:36.880><c> just</c><00:04:37.040><c> to</c><00:04:37.199><c> give</c><00:04:37.360><c> you</c><00:04:37.600><c> the</c> my first example just to give you the my first example just to give you the basics<00:04:38.320><c> of</c><00:04:38.560><c> how</c><00:04:38.720><c> we</c><00:04:38.960><c> use</c><00:04:39.199><c> crawl</c><00:04:39.520><c> for</c><00:04:39.759><c> AI.</c><00:04:40.160><c> But</c> basics of how we use crawl for AI. But basics of how we use crawl for AI. But now<00:04:40.560><c> we</c><00:04:40.720><c> get</c><00:04:40.880><c> to</c><00:04:41.040><c> the</c><00:04:41.280><c> real</c><00:04:41.520><c> stuff</c><00:04:41.919><c> because</c><00:04:42.160><c> I</c> now we get to the real stuff because I now we get to the real stuff because I want<00:04:42.560><c> to</c><00:04:42.720><c> show</c><00:04:42.800><c> you</c><00:04:42.960><c> what</c><00:04:43.199><c> you</c><00:04:43.440><c> really</c><00:04:43.680><c> came</c><00:04:43.919><c> to</c> want to show you what you really came to want to show you what you really came to this<00:04:44.479><c> video</c><00:04:44.800><c> for</c><00:04:45.120><c> which</c><00:04:45.360><c> is</c><00:04:45.600><c> scraping</c><00:04:46.479><c> entire</c> this video for which is scraping entire this video for which is scraping entire websites.<00:04:47.759><c> Right</c><00:04:47.919><c> now,</c><00:04:48.080><c> we</c><00:04:48.240><c> just</c><00:04:48.400><c> crawled</c><00:04:48.720><c> a</c> websites. Right now, we just crawled a websites. Right now, we just crawled a single<00:04:49.280><c> page,</c><00:04:49.600><c> which</c><00:04:50.000><c> it</c><00:04:50.240><c> was</c><00:04:50.320><c> important</c><00:04:50.639><c> for</c> single page, which it was important for single page, which it was important for me<00:04:50.960><c> to</c><00:04:51.120><c> show</c><00:04:51.199><c> you</c><00:04:51.360><c> a</c><00:04:51.600><c> basic</c><00:04:51.919><c> example.</c><00:04:52.720><c> But</c><00:04:52.880><c> what</c> me to show you a basic example. But what me to show you a basic example. But what we<00:04:53.280><c> really</c><00:04:53.520><c> want</c><00:04:53.680><c> to</c><00:04:53.919><c> do</c><00:04:54.320><c> is</c><00:04:54.560><c> crawl</c><00:04:55.040><c> entire</c> we really want to do is crawl entire we really want to do is crawl entire websites.<00:04:56.240><c> We</c><00:04:56.400><c> want</c><00:04:56.479><c> to</c><00:04:56.560><c> pull</c><00:04:56.720><c> the</c><00:04:56.880><c> markdown</c> websites. We want to pull the markdown websites. We want to pull the markdown for<00:04:57.680><c> every</c><00:04:58.080><c> page</c><00:04:58.320><c> that</c><00:04:58.560><c> is</c><00:04:58.720><c> available</c><00:04:59.040><c> to</c><00:04:59.199><c> us,</c> for every page that is available to us, for every page that is available to us, then<00:04:59.919><c> feed</c><00:05:00.160><c> that</c><00:05:00.400><c> into</c><00:05:00.800><c> our</c><00:05:01.360><c> AI</c><00:05:01.680><c> agent</c><00:05:02.080><c> for</c><00:05:02.320><c> rag</c> then feed that into our AI agent for rag then feed that into our AI agent for rag so<00:05:02.960><c> that</c><00:05:03.120><c> it</c><00:05:03.280><c> can</c><00:05:03.360><c> become</c><00:05:03.600><c> the</c><00:05:03.840><c> expert</c><00:05:04.160><c> on</c><00:05:04.320><c> our</c> so that it can become the expert on our so that it can become the expert on our e-commerce<00:05:05.040><c> store</c><00:05:05.440><c> or</c><00:05:06.000><c> understand</c><00:05:06.400><c> the</c><00:05:06.720><c> full</c> e-commerce store or understand the full e-commerce store or understand the full documentation<00:05:07.520><c> for</c><00:05:07.840><c> something</c><00:05:08.000><c> like</c><00:05:08.240><c> Pantic</c> documentation for something like Pantic documentation for something like Pantic AI,<00:05:09.440><c> whatever</c><00:05:09.759><c> website</c><00:05:10.160><c> it</c><00:05:10.320><c> is.</c><00:05:10.639><c> I</c><00:05:10.880><c> have</c><00:05:11.039><c> you</c> AI, whatever website it is. I have you AI, whatever website it is. I have you covered<00:05:11.600><c> now</c><00:05:11.840><c> with</c><00:05:12.000><c> a</c><00:05:12.240><c> few</c><00:05:12.400><c> different</c> covered now with a few different covered now with a few different strategies<00:05:13.360><c> for</c><00:05:13.680><c> crawling</c><00:05:14.240><c> really</c><00:05:14.479><c> any</c> strategies for crawling really any strategies for crawling really any website<00:05:15.199><c> that</c><00:05:15.360><c> I'll</c><00:05:15.520><c> hit</c><00:05:15.680><c> on</c><00:05:16.000><c> right</c><00:05:16.240><c> now.</c><00:05:16.720><c> So</c> website that I'll hit on right now. So website that I'll hit on right now. So the<00:05:17.440><c> first</c><00:05:17.680><c> main</c><00:05:18.000><c> way</c><00:05:18.160><c> that</c><00:05:18.320><c> you</c><00:05:18.479><c> can</c><00:05:18.560><c> crawl</c> the first main way that you can crawl the first main way that you can crawl websites<00:05:19.680><c> is</c><00:05:20.000><c> through</c><00:05:20.240><c> what</c><00:05:20.400><c> is</c><00:05:20.560><c> called</c><00:05:20.720><c> a</c> websites is through what is called a websites is through what is called a sitemap.<00:05:21.680><c> And</c><00:05:21.840><c> so</c><00:05:22.000><c> a</c><00:05:22.240><c> lot</c><00:05:22.320><c> of</c><00:05:22.479><c> websites</c><00:05:22.880><c> will</c> sitemap. And so a lot of websites will sitemap. And so a lot of websites will make<00:05:23.199><c> this</c><00:05:23.440><c> available</c><00:05:24.000><c> where</c><00:05:24.240><c> you</c><00:05:24.400><c> can</c><00:05:24.479><c> go</c><00:05:24.639><c> to</c> make this available where you can go to make this available where you can go to the<00:05:25.199><c> root</c><00:05:25.600><c> domain</c><00:05:26.160><c> and</c><00:05:26.400><c> then</c><00:05:26.639><c> slash</c> the root domain and then slash the root domain and then slash sitemap.xml.<00:05:29.039><c> There</c><00:05:29.199><c> are</c><00:05:29.280><c> a</c><00:05:29.440><c> couple</c><00:05:29.600><c> other</c> sitemap.xml. There are a couple other sitemap.xml. There are a couple other different<00:05:30.160><c> URLs.</c><00:05:30.800><c> They</c><00:05:31.039><c> might</c><00:05:31.199><c> look</c><00:05:31.360><c> a</c><00:05:31.600><c> little</c> different URLs. They might look a little different URLs. They might look a little different,<00:05:32.240><c> but</c><00:05:32.479><c> usually</c><00:05:32.720><c> it's</c><00:05:32.880><c> going</c><00:05:32.960><c> to</c><00:05:33.039><c> be</c> different, but usually it's going to be different, but usually it's going to be /sitemap.xml.<00:05:35.120><c> And</c><00:05:35.360><c> this</c><00:05:35.520><c> is</c><00:05:35.680><c> going</c><00:05:35.759><c> to</c><00:05:36.000><c> give</c> /sitemap.xml. And this is going to give /sitemap.xml. And this is going to give you<00:05:36.400><c> this</c><00:05:36.639><c> very</c><00:05:36.960><c> structured</c><00:05:37.520><c> document</c><00:05:38.000><c> here</c> you this very structured document here you this very structured document here that<00:05:38.960><c> tells</c><00:05:39.199><c> you</c><00:05:39.440><c> all</c><00:05:39.600><c> the</c><00:05:39.840><c> URLs</c><00:05:40.320><c> that</c><00:05:40.560><c> are</c> that tells you all the URLs that are that tells you all the URLs that are available<00:05:41.039><c> for</c><00:05:41.280><c> you</c><00:05:41.520><c> to</c><00:05:41.759><c> visit</c><00:05:42.320><c> for</c><00:05:42.720><c> this</c> available for you to visit for this available for you to visit for this website.<00:05:43.759><c> And</c><00:05:44.000><c> so</c><00:05:44.240><c> this</c><00:05:44.400><c> is</c><00:05:44.560><c> the</c><00:05:44.720><c> primary</c> website. And so this is the primary website. And so this is the primary method<00:05:45.360><c> in</c><00:05:45.600><c> my</c><00:05:45.759><c> previous</c><00:05:46.080><c> crawl</c><00:05:46.320><c> for</c><00:05:46.560><c> AI</c><00:05:46.880><c> video</c> method in my previous crawl for AI video method in my previous crawl for AI video that<00:05:47.280><c> I</c><00:05:47.440><c> showed</c><00:05:47.840><c> as</c><00:05:48.160><c> a</c><00:05:48.320><c> way</c><00:05:48.479><c> to</c><00:05:48.720><c> get</c><00:05:48.880><c> access</c><00:05:49.199><c> to</c> that I showed as a way to get access to that I showed as a way to get access to all<00:05:49.600><c> the</c><00:05:49.759><c> different</c><00:05:50.000><c> web</c><00:05:50.240><c> pages</c><00:05:50.560><c> that</c><00:05:50.880><c> are</c> all the different web pages that are all the different web pages that are available<00:05:51.360><c> in</c><00:05:51.680><c> a</c><00:05:51.840><c> given</c><00:05:52.520><c> website.</c><00:05:53.520><c> But</c> available in a given website. But available in a given website. But sometimes<00:05:54.320><c> you</c><00:05:54.560><c> don't</c><00:05:54.720><c> always</c><00:05:55.039><c> have</c><00:05:55.199><c> a</c> sometimes you don't always have a sometimes you don't always have a sitemap.<00:05:56.000><c> This</c><00:05:56.160><c> is</c><00:05:56.320><c> really</c><00:05:56.639><c> convenient</c><00:05:57.039><c> and</c> sitemap. This is really convenient and sitemap. This is really convenient and if<00:05:57.360><c> it's</c><00:05:57.600><c> available</c><00:05:57.840><c> to</c><00:05:58.000><c> you,</c><00:05:58.240><c> you</c><00:05:58.479><c> probably</c> if it's available to you, you probably if it's available to you, you probably want<00:05:58.880><c> to</c><00:05:59.120><c> use</c><00:05:59.360><c> it.</c><00:05:59.840><c> But</c><00:06:00.080><c> sometimes</c><00:06:00.400><c> you</c><00:06:00.720><c> don't</c> want to use it. But sometimes you don't want to use it. But sometimes you don't have<00:06:01.039><c> that.</c><00:06:01.360><c> And</c><00:06:01.520><c> so</c><00:06:02.000><c> you</c><00:06:02.240><c> need</c><00:06:02.639><c> crawl</c><00:06:02.960><c> for</c><00:06:03.199><c> AAI</c> have that. And so you need crawl for AAI have that. And so you need crawl for AAI to<00:06:04.240><c> actually</c><00:06:04.639><c> start</c><00:06:04.960><c> from</c><00:06:05.120><c> the</c><00:06:05.280><c> homepage</c><00:06:06.080><c> and</c> to actually start from the homepage and to actually start from the homepage and then<00:06:06.560><c> find</c><00:06:06.960><c> the</c><00:06:07.199><c> rest</c><00:06:07.360><c> of</c><00:06:07.440><c> the</c><00:06:07.600><c> pages</c><00:06:07.919><c> through</c> then find the rest of the pages through then find the rest of the pages through navigation.<00:06:08.880><c> do</c><00:06:09.120><c> some</c><00:06:09.280><c> kind</c><00:06:09.440><c> of</c><00:06:09.520><c> recursive</c> navigation. do some kind of recursive navigation. do some kind of recursive scraping<00:06:10.479><c> where</c><00:06:10.720><c> it</c><00:06:10.880><c> goes</c><00:06:11.039><c> through</c><00:06:11.120><c> these</c> scraping where it goes through these scraping where it goes through these pages<00:06:11.680><c> and</c><00:06:11.919><c> finds</c><00:06:12.240><c> all</c><00:06:12.400><c> the</c><00:06:12.560><c> links</c><00:06:12.800><c> that</c><00:06:12.960><c> it</c> pages and finds all the links that it pages and finds all the links that it has<00:06:13.280><c> to</c><00:06:13.440><c> visit.</c><00:06:14.080><c> That</c><00:06:14.240><c> is</c><00:06:14.400><c> the</c><00:06:14.639><c> second</c><00:06:14.960><c> method</c> has to visit. That is the second method has to visit. That is the second method that<00:06:15.360><c> I</c><00:06:15.520><c> have</c><00:06:15.680><c> covered</c><00:06:16.000><c> for</c><00:06:16.240><c> you</c><00:06:16.400><c> here.</c><00:06:16.960><c> And</c> that I have covered for you here. And that I have covered for you here. And then<00:06:17.280><c> the</c><00:06:17.440><c> last</c><00:06:17.680><c> method</c><00:06:18.479><c> is</c><00:06:18.800><c> a</c><00:06:19.120><c> lot</c><00:06:19.280><c> of</c> then the last method is a lot of then the last method is a lot of especially<00:06:20.639><c> documentation</c><00:06:21.360><c> for</c><00:06:21.680><c> frameworks</c> especially documentation for frameworks especially documentation for frameworks and<00:06:22.319><c> tools.</c><00:06:22.960><c> They've</c><00:06:23.360><c> started</c><00:06:23.600><c> to</c><00:06:24.000><c> put</c><00:06:24.240><c> out</c> and tools. They've started to put out and tools. They've started to put out what's<00:06:24.639><c> called</c><00:06:24.960><c> an</c> what's called an what's called an LLMs.ext.<00:06:26.639><c> And</c><00:06:26.880><c> so</c><00:06:27.280><c> usually</c><00:06:27.600><c> this</c><00:06:27.759><c> is</c><00:06:27.919><c> going</c> LLMs.ext. And so usually this is going LLMs.ext. And so usually this is going to<00:06:28.080><c> be</c><00:06:28.160><c> either</c><00:06:29.000><c> /lms.ext</c> orlms-full.ext.<00:06:33.360><c> And</c><00:06:33.680><c> essentially</c><00:06:33.919><c> what</c> orlms-full.ext. And essentially what orlms-full.ext. And essentially what they<00:06:34.319><c> do</c><00:06:34.400><c> with</c><00:06:34.560><c> this</c><00:06:34.800><c> is</c><00:06:35.039><c> they</c><00:06:35.280><c> take</c><00:06:35.759><c> every</c> they do with this is they take every they do with this is they take every single<00:06:36.400><c> page</c><00:06:36.720><c> for</c><00:06:36.960><c> their</c><00:06:37.120><c> documentation</c><00:06:37.759><c> and</c> single page for their documentation and single page for their documentation and they<00:06:38.160><c> combine</c><00:06:38.479><c> it</c><00:06:38.720><c> together</c><00:06:38.960><c> into</c><00:06:39.280><c> a</c><00:06:39.600><c> single</c> they combine it together into a single they combine it together into a single page.<00:06:40.720><c> So</c><00:06:40.880><c> we</c><00:06:41.039><c> have</c><00:06:41.280><c> one</c><00:06:41.600><c> document</c><00:06:42.160><c> that</c><00:06:42.400><c> we</c> page. So we have one document that we page. So we have one document that we can<00:06:42.800><c> bring</c><00:06:43.039><c> into</c><00:06:43.919><c> our</c><00:06:44.400><c> program</c><00:06:45.120><c> we</c><00:06:45.280><c> can</c><00:06:45.440><c> chunk</c> can bring into our program we can chunk can bring into our program we can chunk up<00:06:45.840><c> and</c><00:06:46.000><c> add</c><00:06:46.160><c> it</c><00:06:46.319><c> into</c><00:06:46.479><c> our</c><00:06:46.639><c> vector</c><00:06:47.039><c> database</c> up and add it into our vector database up and add it into our vector database for<00:06:47.600><c> rag.</c><00:06:48.080><c> So</c><00:06:48.160><c> it's</c><00:06:48.400><c> literally</c><00:06:49.120><c> documentation</c> for rag. So it's literally documentation for rag. So it's literally documentation formatted<00:06:50.479><c> and</c><00:06:50.800><c> this</c><00:06:50.960><c> is</c><00:06:51.120><c> all</c><00:06:51.360><c> markdown</c><00:06:52.000><c> just</c> formatted and this is all markdown just formatted and this is all markdown just like<00:06:52.319><c> crawl</c><00:06:52.639><c> for</c><00:06:53.120><c> produces.</c><00:06:54.000><c> It's</c><00:06:54.160><c> formatted</c> like crawl for produces. It's formatted like crawl for produces. It's formatted specifically<00:06:55.360><c> for</c><00:06:56.080><c> LLM</c><00:06:56.720><c> knowledge.</c><00:06:57.280><c> And</c><00:06:57.440><c> so</c> specifically for LLM knowledge. And so specifically for LLM knowledge. And so that<00:06:57.840><c> is</c><00:06:57.919><c> the</c><00:06:58.160><c> third</c><00:06:58.479><c> method</c><00:06:59.120><c> of</c><00:06:59.440><c> scraping</c> that is the third method of scraping that is the third method of scraping data<00:07:00.160><c> from</c><00:07:00.319><c> a</c><00:07:00.560><c> website</c><00:07:00.720><c> that</c><00:07:00.960><c> I'll</c><00:07:01.199><c> show</c><00:07:01.280><c> you</c> data from a website that I'll show you data from a website that I'll show you with<00:07:01.759><c> crawl</c><00:07:02.080><c> for</c><00:07:02.319><c> AAI.</c><00:07:02.720><c> And</c><00:07:03.039><c> essentially</c><00:07:03.440><c> one</c> with crawl for AAI. And essentially one with crawl for AAI. And essentially one of<00:07:03.759><c> these</c><00:07:04.080><c> three</c><00:07:04.400><c> methods</c><00:07:05.120><c> is</c><00:07:05.440><c> going</c><00:07:05.599><c> to</c><00:07:05.759><c> be</c> of these three methods is going to be of these three methods is going to be able<00:07:06.400><c> to</c><00:07:06.560><c> be</c><00:07:06.720><c> used</c><00:07:07.039><c> no</c><00:07:07.120><c> matter</c><00:07:07.440><c> what</c><00:07:07.759><c> website</c> able to be used no matter what website able to be used no matter what website you<00:07:08.400><c> are</c><00:07:08.560><c> crawling.</c><00:07:08.880><c> And</c><00:07:09.039><c> so</c><00:07:09.199><c> I</c><00:07:09.360><c> truly</c><00:07:09.759><c> am</c> you are crawling. And so I truly am you are crawling. And so I truly am showing<00:07:10.240><c> you</c><00:07:10.479><c> here</c><00:07:10.880><c> how</c><00:07:11.199><c> to</c><00:07:11.680><c> extract</c><00:07:12.319><c> LLM</c> showing you here how to extract LLM showing you here how to extract LLM knowledge<00:07:13.199><c> from</c><00:07:13.440><c> any</c><00:07:13.759><c> website</c><00:07:14.160><c> that</c><00:07:14.400><c> you</c> knowledge from any website that you knowledge from any website that you want.<00:07:15.039><c> So</c><00:07:15.280><c> your</c><00:07:15.599><c> golden</c><00:07:16.000><c> ticket</c><00:07:16.319><c> to</c><00:07:16.560><c> crawl</c><00:07:16.800><c> any</c> want. So your golden ticket to crawl any want. So your golden ticket to crawl any web<00:07:17.360><c> page</c><00:07:17.599><c> with</c><00:07:17.919><c> any</c><00:07:18.160><c> of</c><00:07:18.240><c> the</c><00:07:18.400><c> three</c><00:07:18.639><c> methods</c> web page with any of the three methods web page with any of the three methods that<00:07:19.039><c> I</c><00:07:19.280><c> shared</c><00:07:19.440><c> with</c><00:07:19.599><c> you</c><00:07:19.680><c> and</c><00:07:19.919><c> to</c><00:07:20.080><c> do</c><00:07:20.160><c> it</c><00:07:20.400><c> very</c> that I shared with you and to do it very that I shared with you and to do it very fast<00:07:21.440><c> is</c><00:07:21.759><c> this</c><00:07:22.080><c> GitHub</c><00:07:22.479><c> repository</c><00:07:23.039><c> which</c><00:07:23.280><c> I</c> fast is this GitHub repository which I fast is this GitHub repository which I have<00:07:23.520><c> as</c><00:07:23.759><c> a</c><00:07:23.919><c> free</c><00:07:24.160><c> resource</c><00:07:24.560><c> for</c><00:07:24.720><c> you.</c><00:07:25.039><c> So</c><00:07:25.360><c> link</c> have as a free resource for you. So link have as a free resource for you. So link to<00:07:25.680><c> this</c><00:07:25.840><c> in</c><00:07:26.000><c> the</c><00:07:26.160><c> description</c><00:07:26.560><c> of</c><00:07:26.880><c> this</c> to this in the description of this to this in the description of this video.<00:07:27.520><c> And</c><00:07:27.759><c> the</c><00:07:27.919><c> way</c><00:07:28.000><c> that</c><00:07:28.160><c> I</c><00:07:28.319><c> have</c> video. And the way that I have video. And the way that I have structured<00:07:28.800><c> this</c><00:07:29.039><c> repository</c><00:07:29.599><c> is</c><00:07:29.840><c> I</c><00:07:30.160><c> first</c> structured this repository is I first structured this repository is I first have<00:07:30.560><c> this</c><00:07:30.800><c> crawl</c><00:07:31.120><c> for</c><00:07:31.360><c> AAI</c><00:07:31.759><c> examples</c><00:07:32.319><c> folder.</c> have this crawl for AAI examples folder. have this crawl for AAI examples folder. This<00:07:32.880><c> is</c><00:07:32.960><c> where</c><00:07:33.120><c> I</c><00:07:33.280><c> show</c><00:07:33.440><c> you</c><00:07:33.919><c> at</c><00:07:34.160><c> more</c><00:07:34.319><c> a</c> This is where I show you at more a This is where I show you at more a granular<00:07:35.039><c> level</c><00:07:35.599><c> how</c><00:07:35.840><c> we</c><00:07:36.080><c> have</c><00:07:36.160><c> these</c> granular level how we have these granular level how we have these different<00:07:36.720><c> strategies</c><00:07:37.199><c> set</c><00:07:37.440><c> up</c><00:07:37.599><c> to</c><00:07:37.919><c> crawl</c><00:07:38.160><c> web</c> different strategies set up to crawl web different strategies set up to crawl web pages<00:07:38.720><c> in</c><00:07:38.960><c> crawl</c><00:07:39.280><c> for</c><00:07:39.520><c> AI.</c><00:07:40.160><c> So</c><00:07:40.400><c> first</c><00:07:40.639><c> we</c><00:07:40.880><c> have</c> pages in crawl for AI. So first we have pages in crawl for AI. So first we have crawling<00:07:41.440><c> a</c><00:07:41.840><c> single</c><00:07:42.160><c> page.</c><00:07:42.400><c> So</c><00:07:42.560><c> this</c><00:07:42.720><c> is</c><00:07:42.800><c> the</c> crawling a single page. So this is the crawling a single page. So this is the very<00:07:43.199><c> basic</c><00:07:43.599><c> example</c><00:07:43.919><c> that</c><00:07:44.080><c> I</c><00:07:44.240><c> showed</c><00:07:44.479><c> you</c> very basic example that I showed you very basic example that I showed you earlier.<00:07:45.280><c> Then</c><00:07:45.440><c> we</c><00:07:45.680><c> have</c><00:07:45.919><c> this</c><00:07:46.160><c> example</c><00:07:46.560><c> that</c> earlier. Then we have this example that earlier. Then we have this example that I<00:07:47.039><c> don't</c><00:07:47.199><c> want</c><00:07:47.280><c> to</c><00:07:47.360><c> cover</c><00:07:47.599><c> too</c><00:07:47.840><c> much</c><00:07:48.000><c> in</c><00:07:48.160><c> this</c> I don't want to cover too much in this I don't want to cover too much in this video<00:07:48.560><c> but</c><00:07:48.800><c> you</c><00:07:48.960><c> can</c><00:07:49.039><c> crawl</c><00:07:49.360><c> web</c><00:07:49.599><c> pages</c> video but you can crawl web pages video but you can crawl web pages sequentially.<00:07:50.800><c> So</c><00:07:50.960><c> you</c><00:07:51.120><c> just</c><00:07:51.280><c> process</c><00:07:52.000><c> one</c> sequentially. So you just process one sequentially. So you just process one URL<00:07:52.880><c> at</c><00:07:53.120><c> a</c><00:07:53.360><c> time.</c><00:07:53.840><c> But</c><00:07:54.080><c> what</c><00:07:54.240><c> crawl</c><00:07:54.479><c> for</c><00:07:54.720><c> AAI</c> URL at a time. But what crawl for AAI URL at a time. But what crawl for AAI does<00:07:55.360><c> really</c><00:07:55.759><c> well</c><00:07:55.919><c> and</c><00:07:56.160><c> what</c><00:07:56.319><c> makes</c><00:07:56.479><c> it</c> does really well and what makes it does really well and what makes it blazingly<00:07:57.360><c> fast</c><00:07:57.919><c> is</c><00:07:58.160><c> you</c><00:07:58.400><c> can</c><00:07:58.479><c> crawl</c><00:07:58.960><c> batches</c> blazingly fast is you can crawl batches blazingly fast is you can crawl batches of<00:07:59.759><c> URLs</c><00:08:00.400><c> in</c><00:08:00.879><c> parallel.</c><00:08:01.360><c> And</c><00:08:01.520><c> so</c><00:08:01.680><c> that's</c><00:08:01.919><c> what</c> of URLs in parallel. And so that's what of URLs in parallel. And so that's what I<00:08:02.319><c> have</c><00:08:02.639><c> for</c><00:08:02.879><c> the</c><00:08:03.120><c> last</c><00:08:03.360><c> three</c><00:08:03.680><c> scripts</c><00:08:04.000><c> in</c><00:08:04.240><c> the</c> I have for the last three scripts in the I have for the last three scripts in the examples<00:08:04.800><c> folder</c><00:08:05.199><c> here.</c><00:08:05.520><c> So</c><00:08:05.759><c> starting</c><00:08:06.080><c> with</c> examples folder here. So starting with examples folder here. So starting with the<00:08:06.479><c> script</c><00:08:06.800><c> to</c><00:08:07.039><c> crawl</c><00:08:07.360><c> our</c><00:08:07.759><c> site</c><00:08:08.080><c> maps.</c><00:08:08.560><c> This</c> the script to crawl our site maps. This the script to crawl our site maps. This is<00:08:08.879><c> going</c><00:08:08.960><c> to</c><00:08:09.199><c> take</c><00:08:09.440><c> that</c><00:08:09.680><c> site</c><00:08:10.000><c> map</c><00:08:10.319><c> like</c><00:08:10.720><c> this</c> is going to take that site map like this is going to take that site map like this is<00:08:10.960><c> the</c><00:08:11.120><c> one</c><00:08:11.280><c> that</c><00:08:11.440><c> we</c><00:08:11.520><c> have</c><00:08:11.680><c> for</c><00:08:11.840><c> crawl</c><00:08:12.160><c> for</c> is the one that we have for crawl for is the one that we have for crawl for AAI<00:08:12.560><c> that</c><00:08:12.720><c> we</c><00:08:12.879><c> saw</c><00:08:13.120><c> earlier</c><00:08:13.680><c> and</c><00:08:13.840><c> it's</c><00:08:14.080><c> going</c> AAI that we saw earlier and it's going AAI that we saw earlier and it's going to<00:08:14.479><c> take</c><00:08:14.800><c> batches</c><00:08:15.280><c> of</c><00:08:15.520><c> these</c><00:08:15.759><c> URLs</c><00:08:16.560><c> and</c> to take batches of these URLs and to take batches of these URLs and extract<00:08:17.360><c> them</c><00:08:17.599><c> markdown</c><00:08:18.080><c> from</c><00:08:18.319><c> each</c><00:08:18.479><c> of</c><00:08:18.639><c> them</c> extract them markdown from each of them extract them markdown from each of them in<00:08:19.120><c> parallel.</c><00:08:19.599><c> So</c><00:08:19.680><c> we</c><00:08:19.840><c> can</c><00:08:19.919><c> then</c><00:08:20.080><c> feed</c><00:08:20.319><c> that</c> in parallel. So we can then feed that in parallel. So we can then feed that into<00:08:20.720><c> our</c><00:08:20.879><c> vector</c><00:08:21.280><c> database</c><00:08:22.160><c> for</c><00:08:22.319><c> our</c><00:08:22.560><c> rag</c> into our vector database for our rag into our vector database for our rag knowledge<00:08:23.280><c> base.</c><00:08:23.840><c> I</c><00:08:24.000><c> know</c><00:08:24.160><c> it's</c><00:08:24.319><c> very</c><00:08:24.479><c> meta</c> knowledge base. I know it's very meta knowledge base. I know it's very meta here.<00:08:25.039><c> We're</c><00:08:25.199><c> using</c><00:08:25.360><c> crawl</c><00:08:25.680><c> for</c><00:08:25.919><c> AAI</c><00:08:26.400><c> to</c><00:08:26.720><c> crawl</c> here. We're using crawl for AAI to crawl here. We're using crawl for AAI to crawl crawl<00:08:27.599><c> for</c><00:08:27.919><c> AI.</c><00:08:28.400><c> But</c><00:08:28.639><c> I</c><00:08:28.800><c> mean,</c><00:08:28.960><c> yeah,</c><00:08:29.120><c> this</c><00:08:29.280><c> is</c> crawl for AI. But I mean, yeah, this is crawl for AI. But I mean, yeah, this is good<00:08:29.599><c> documentation</c><00:08:30.080><c> to</c><00:08:30.319><c> crawl</c><00:08:30.479><c> and</c><00:08:30.720><c> get</c><00:08:30.800><c> into</c> good documentation to crawl and get into good documentation to crawl and get into our<00:08:31.120><c> AI</c><00:08:31.440><c> coding</c><00:08:31.680><c> assistance</c><00:08:32.080><c> and</c><00:08:32.320><c> things</c><00:08:32.479><c> like</c> our AI coding assistance and things like our AI coding assistance and things like that<00:08:32.800><c> because</c><00:08:32.959><c> we</c><00:08:33.120><c> definitely</c><00:08:33.440><c> want</c><00:08:33.599><c> to</c> that because we definitely want to that because we definitely want to create<00:08:34.240><c> a</c><00:08:34.399><c> lot</c><00:08:34.479><c> of</c><00:08:34.560><c> agents</c><00:08:34.959><c> around</c><00:08:35.200><c> this.</c><00:08:35.680><c> So</c> create a lot of agents around this. So create a lot of agents around this. So that's<00:08:36.399><c> for</c><00:08:36.719><c> sitemaps.</c><00:08:37.360><c> Then</c><00:08:37.519><c> we</c><00:08:37.680><c> have</c><00:08:37.760><c> the</c> that's for sitemaps. Then we have the that's for sitemaps. Then we have the one<00:08:38.159><c> to</c><00:08:38.399><c> crawl</c><00:08:38.959><c> our</c><00:08:39.240><c> LLM.ext.</c><00:08:40.240><c> So</c><00:08:40.320><c> this</c><00:08:40.479><c> is</c> one to crawl our LLM.ext. So this is one to crawl our LLM.ext. So this is just<00:08:40.719><c> going</c><00:08:40.880><c> to</c><00:08:41.039><c> take</c><00:08:41.440><c> a</c><00:08:41.760><c> single</c><00:08:42.159><c> URL.</c><00:08:42.880><c> It's</c><00:08:43.120><c> a</c> just going to take a single URL. It's a just going to take a single URL. It's a lot<00:08:43.440><c> simpler</c><00:08:43.919><c> because</c><00:08:44.159><c> the</c><00:08:44.360><c> LLM's.ext</c><00:08:45.360><c> is</c> lot simpler because the LLM's.ext is lot simpler because the LLM's.ext is just<00:08:45.760><c> one</c><00:08:46.000><c> page</c><00:08:46.320><c> with</c><00:08:46.560><c> all</c><00:08:46.800><c> of</c><00:08:47.040><c> the</c> just one page with all of the just one page with all of the documentation.<00:08:48.320><c> And</c><00:08:48.560><c> I</c><00:08:48.720><c> do</c><00:08:48.880><c> show</c><00:08:48.959><c> you</c><00:08:49.120><c> in</c><00:08:49.279><c> this</c> documentation. And I do show you in this documentation. And I do show you in this script<00:08:49.600><c> how</c><00:08:49.839><c> to</c><00:08:50.000><c> chunk</c><00:08:50.320><c> things</c><00:08:50.480><c> as</c><00:08:50.640><c> well</c> script how to chunk things as well script how to chunk things as well because<00:08:51.120><c> obviously</c><00:08:51.519><c> we</c><00:08:51.760><c> would</c><00:08:51.920><c> not</c><00:08:52.080><c> want</c><00:08:52.240><c> to</c> because obviously we would not want to because obviously we would not want to take<00:08:52.640><c> this</c><00:08:52.959><c> massive</c><00:08:53.440><c> document</c><00:08:54.000><c> and</c><00:08:54.320><c> dump</c><00:08:54.640><c> that</c> take this massive document and dump that take this massive document and dump that into<00:08:55.040><c> a</c><00:08:55.279><c> prompt</c><00:08:55.519><c> for</c><00:08:55.760><c> the</c><00:08:55.920><c> LLM.</c><00:08:56.320><c> And</c><00:08:56.399><c> so</c><00:08:56.560><c> we</c> into a prompt for the LLM. And so we into a prompt for the LLM. And so we want<00:08:56.720><c> to</c><00:08:56.800><c> chunk</c><00:08:57.120><c> that</c><00:08:57.279><c> up.</c><00:08:57.920><c> And</c><00:08:58.080><c> so</c><00:08:58.240><c> then</c><00:08:58.480><c> that</c> want to chunk that up. And so then that want to chunk that up. And so then that leads<00:08:58.959><c> us</c><00:08:59.120><c> to</c><00:08:59.360><c> our</c><00:08:59.680><c> last</c><00:08:59.920><c> one</c><00:09:00.080><c> here.</c><00:09:00.320><c> And</c><00:09:00.480><c> this</c> leads us to our last one here. And this leads us to our last one here. And this is<00:09:00.720><c> the</c><00:09:00.880><c> most</c><00:09:01.120><c> complex</c><00:09:01.839><c> but</c><00:09:02.080><c> also</c><00:09:02.320><c> the</c><00:09:02.560><c> most</c> is the most complex but also the most is the most complex but also the most flexible<00:09:03.519><c> because</c><00:09:03.760><c> we</c><00:09:03.920><c> can</c><00:09:04.000><c> give</c><00:09:04.160><c> it</c><00:09:04.399><c> any</c> flexible because we can give it any flexible because we can give it any website<00:09:05.200><c> URL.</c><00:09:05.680><c> It</c><00:09:05.839><c> doesn't</c><00:09:06.000><c> have</c><00:09:06.080><c> to</c><00:09:06.160><c> be</c><00:09:06.240><c> an</c> website URL. It doesn't have to be an website URL. It doesn't have to be an LLM.ext.<00:09:07.519><c> It</c><00:09:07.760><c> doesn't</c><00:09:07.920><c> have</c><00:09:08.000><c> to</c><00:09:08.080><c> be</c><00:09:08.240><c> a</c> LLM.ext. It doesn't have to be a LLM.ext. It doesn't have to be a sitemap.<00:09:09.200><c> and</c><00:09:09.440><c> it</c><00:09:09.600><c> can</c><00:09:09.760><c> scrape</c><00:09:10.080><c> the</c><00:09:10.240><c> homepage</c> sitemap. and it can scrape the homepage sitemap. and it can scrape the homepage or<00:09:11.040><c> whatever</c><00:09:11.360><c> that</c><00:09:11.600><c> page</c><00:09:11.760><c> is</c><00:09:11.920><c> that</c><00:09:12.080><c> we</c><00:09:12.240><c> gave</c><00:09:12.399><c> it</c> or whatever that page is that we gave it or whatever that page is that we gave it and<00:09:13.040><c> then</c><00:09:13.279><c> intelligently</c><00:09:14.080><c> determine</c><00:09:14.959><c> other</c> and then intelligently determine other and then intelligently determine other links<00:09:15.760><c> to</c><00:09:15.920><c> other</c><00:09:16.160><c> parts</c><00:09:16.399><c> of</c><00:09:16.640><c> this</c><00:09:16.880><c> web</c><00:09:17.120><c> page</c> links to other parts of this web page links to other parts of this web page and<00:09:17.519><c> scrape</c><00:09:18.000><c> those</c><00:09:18.320><c> as</c><00:09:18.560><c> well.</c><00:09:19.120><c> And</c><00:09:19.279><c> it</c><00:09:19.440><c> does</c><00:09:19.519><c> it</c> and scrape those as well. And it does it and scrape those as well. And it does it in<00:09:19.839><c> a</c><00:09:20.000><c> recursive</c><00:09:20.560><c> way</c><00:09:20.959><c> where</c><00:09:21.200><c> we</c><00:09:21.360><c> can</c><00:09:21.519><c> specify</c> in a recursive way where we can specify in a recursive way where we can specify the<00:09:22.240><c> depth</c><00:09:22.640><c> like</c><00:09:22.800><c> how</c><00:09:23.040><c> many</c><00:09:23.519><c> levels</c><00:09:23.839><c> we</c><00:09:24.000><c> want</c> the depth like how many levels we want the depth like how many levels we want it<00:09:24.240><c> to</c><00:09:24.399><c> go</c><00:09:24.560><c> down.</c><00:09:25.040><c> So</c><00:09:25.200><c> it</c><00:09:25.440><c> can</c><00:09:25.600><c> search</c><00:09:25.760><c> for</c><00:09:26.000><c> all</c> it to go down. So it can search for all it to go down. So it can search for all the<00:09:26.320><c> different</c><00:09:26.560><c> URLs</c><00:09:27.040><c> that</c><00:09:27.200><c> we</c><00:09:27.360><c> have</c><00:09:27.440><c> for</c><00:09:27.680><c> this</c> the different URLs that we have for this the different URLs that we have for this web<00:09:28.000><c> page.</c><00:09:28.240><c> So</c><00:09:28.399><c> it</c><00:09:28.560><c> can</c><00:09:28.720><c> scrape</c><00:09:29.040><c> everything</c> web page. So it can scrape everything web page. So it can scrape everything essentially<00:09:30.320><c> as</c><00:09:30.560><c> if</c><00:09:30.720><c> we</c><00:09:30.959><c> gave</c><00:09:31.120><c> it</c><00:09:31.279><c> a</c> essentially as if we gave it a essentially as if we gave it a sitemap.xml.<00:09:33.200><c> So</c><00:09:33.440><c> very</c><00:09:33.760><c> very</c><00:09:34.160><c> powerful</c> sitemap.xml. So very very powerful sitemap.xml. So very very powerful stuff.<00:09:35.120><c> The</c><00:09:35.360><c> sponsor</c><00:09:35.680><c> of</c><00:09:35.839><c> today's</c><00:09:36.160><c> video</c><00:09:36.399><c> is</c> stuff. The sponsor of today's video is stuff. The sponsor of today's video is Aqua<00:09:37.200><c> Voice,</c><00:09:37.600><c> an</c><00:09:37.760><c> insanely</c><00:09:38.399><c> powerful</c><00:09:38.959><c> and</c> Aqua Voice, an insanely powerful and Aqua Voice, an insanely powerful and accurate<00:09:39.760><c> AI</c><00:09:40.240><c> voice</c><00:09:40.560><c> system</c><00:09:41.040><c> that</c><00:09:41.360><c> works</c><00:09:41.600><c> on</c> accurate AI voice system that works on accurate AI voice system that works on any<00:09:42.240><c> application</c><00:09:42.800><c> on</c><00:09:43.120><c> your</c><00:09:43.279><c> Mac</c><00:09:43.519><c> or</c><00:09:43.839><c> Windows</c> any application on your Mac or Windows any application on your Mac or Windows computer.<00:09:45.120><c> You</c><00:09:45.360><c> just</c><00:09:45.519><c> have</c><00:09:45.680><c> to</c><00:09:45.839><c> install</c><00:09:46.240><c> Aqua</c> computer. You just have to install Aqua computer. You just have to install Aqua Voice<00:09:46.959><c> once</c><00:09:47.200><c> and</c><00:09:47.440><c> you</c><00:09:47.519><c> can</c><00:09:47.600><c> use</c><00:09:47.760><c> it</c><00:09:47.920><c> anywhere</c> Voice once and you can use it anywhere Voice once and you can use it anywhere with<00:09:48.560><c> literally</c><00:09:48.880><c> the</c><00:09:49.120><c> press</c><00:09:49.360><c> of</c><00:09:49.519><c> a</c><00:09:49.760><c> button.</c> with literally the press of a button. with literally the press of a button. Take<00:09:50.240><c> a</c><00:09:50.320><c> look</c><00:09:50.480><c> at</c><00:09:50.640><c> this.</c><00:09:51.360><c> Archon</c><00:09:51.920><c> is</c><00:09:52.080><c> my</c><00:09:52.320><c> AI</c> Take a look at this. Archon is my AI Take a look at this. Archon is my AI agent<00:09:53.040><c> builder</c><00:09:53.440><c> that</c><00:09:53.680><c> uses</c><00:09:54.000><c> Crawl</c><00:09:54.320><c> for</c><00:09:54.560><c> AI,</c> agent builder that uses Crawl for AI, agent builder that uses Crawl for AI, Pideantic<00:09:55.600><c> AI,</c><00:09:56.080><c> and</c><00:09:56.480><c> Superbase.</c><00:09:57.360><c> And</c><00:09:57.519><c> then</c><00:09:57.600><c> I</c> Pideantic AI, and Superbase. And then I Pideantic AI, and Superbase. And then I let<00:09:57.920><c> go</c><00:09:58.000><c> of</c><00:09:58.160><c> the</c><00:09:58.320><c> button</c><00:09:58.800><c> and</c><00:09:59.120><c> look</c><00:09:59.279><c> at</c><00:09:59.440><c> how</c> let go of the button and look at how let go of the button and look at how fast<00:10:00.000><c> that</c><00:10:00.240><c> was</c><00:10:00.399><c> and</c><00:10:00.640><c> also</c><00:10:00.880><c> how</c><00:10:01.120><c> accurate</c><00:10:01.440><c> it</c> fast that was and also how accurate it fast that was and also how accurate it is<00:10:01.839><c> as</c><00:10:02.000><c> well</c><00:10:02.160><c> with</c><00:10:02.480><c> words</c><00:10:02.720><c> like</c><00:10:03.120><c> pyantic</c><00:10:03.760><c> AI</c> is as well with words like pyantic AI is as well with words like pyantic AI and<00:10:04.240><c> crawl</c><00:10:04.560><c> for</c><00:10:04.800><c> AI</c><00:10:05.120><c> that</c><00:10:05.360><c> usually</c><00:10:05.680><c> these</c> and crawl for AI that usually these and crawl for AI that usually these voice<00:10:06.240><c> systems</c><00:10:06.640><c> would</c><00:10:06.959><c> completely</c><00:10:07.600><c> botch.</c> voice systems would completely botch. voice systems would completely botch. And<00:10:08.399><c> talking</c><00:10:08.720><c> numbers,</c><00:10:09.120><c> Aqua</c><00:10:09.600><c> will</c><00:10:09.760><c> start</c><00:10:09.920><c> up</c> And talking numbers, Aqua will start up And talking numbers, Aqua will start up in<00:10:10.320><c> around</c><00:10:10.640><c> 50</c><00:10:10.959><c> milliseconds</c><00:10:11.680><c> and</c><00:10:12.000><c> get</c><00:10:12.160><c> you</c> in around 50 milliseconds and get you in around 50 milliseconds and get you responses<00:10:12.880><c> in</c><00:10:13.120><c> as</c><00:10:13.360><c> fast</c><00:10:13.600><c> as</c><00:10:14.200><c> 450</c> responses in as fast as 450 responses in as fast as 450 milliseconds.<00:10:16.480><c> And</c><00:10:16.720><c> it</c><00:10:16.959><c> makes</c><00:10:17.360><c> 17</c><00:10:17.760><c> times</c> milliseconds. And it makes 17 times milliseconds. And it makes 17 times fewer<00:10:18.480><c> mistakes</c><00:10:18.800><c> than</c><00:10:19.040><c> Siri</c><00:10:19.440><c> and</c><00:10:19.680><c> Google</c> fewer mistakes than Siri and Google fewer mistakes than Siri and Google voice<00:10:20.240><c> typing.</c><00:10:20.640><c> So</c><00:10:20.800><c> you</c><00:10:20.959><c> get</c><00:10:21.120><c> insane</c><00:10:21.600><c> speed</c> voice typing. So you get insane speed voice typing. So you get insane speed and<00:10:22.480><c> accuracy.</c><00:10:23.200><c> And</c><00:10:23.360><c> I</c><00:10:23.600><c> have</c><00:10:23.760><c> not</c><00:10:23.920><c> seen</c> and accuracy. And I have not seen and accuracy. And I have not seen something<00:10:24.800><c> as</c><00:10:25.120><c> smooth</c><00:10:25.360><c> as</c><00:10:25.519><c> this</c><00:10:25.760><c> before.</c><00:10:26.560><c> And</c> something as smooth as this before. And something as smooth as this before. And my<00:10:27.040><c> favorite</c><00:10:27.279><c> way</c><00:10:27.440><c> to</c><00:10:27.680><c> use</c><00:10:27.920><c> Aqua</c><00:10:28.399><c> is</c><00:10:28.560><c> within</c><00:10:28.880><c> my</c> my favorite way to use Aqua is within my my favorite way to use Aqua is within my AI<00:10:29.440><c> coding</c><00:10:29.760><c> assistants</c><00:10:30.240><c> like</c><00:10:30.480><c> Windsurf</c> AI coding assistants like Windsurf AI coding assistants like Windsurf because<00:10:31.440><c> Aqua</c><00:10:32.000><c> has</c><00:10:32.320><c> this</c><00:10:32.640><c> feature</c><00:10:32.880><c> called</c> because Aqua has this feature called because Aqua has this feature called deep<00:10:33.600><c> context</c><00:10:34.079><c> where</c><00:10:34.240><c> it</c><00:10:34.399><c> can</c><00:10:34.480><c> view</c><00:10:34.640><c> your</c> deep context where it can view your deep context where it can view your screen<00:10:35.360><c> to</c><00:10:35.680><c> understand</c><00:10:36.079><c> what</c><00:10:36.240><c> you're</c> screen to understand what you're screen to understand what you're currently<00:10:36.720><c> working</c><00:10:36.880><c> on.</c><00:10:37.200><c> So</c><00:10:37.360><c> it</c><00:10:37.519><c> can</c> currently working on. So it can currently working on. So it can reference<00:10:38.079><c> certain</c><00:10:38.399><c> components</c><00:10:38.800><c> of</c><00:10:38.959><c> your</c> reference certain components of your reference certain components of your code,<00:10:39.760><c> spell</c><00:10:40.160><c> things</c><00:10:40.399><c> correctly,</c><00:10:40.959><c> really</c> code, spell things correctly, really code, spell things correctly, really help<00:10:41.279><c> you</c><00:10:41.519><c> communicate</c><00:10:42.079><c> effectively</c><00:10:42.560><c> with</c> help you communicate effectively with help you communicate effectively with your<00:10:43.040><c> AI</c><00:10:43.519><c> IDE.</c><00:10:44.399><c> For</c><00:10:44.680><c> example,</c><00:10:45.680><c> update</c><00:10:46.079><c> my</c> your AI IDE. For example, update my your AI IDE. For example, update my async<00:10:46.880><c> webcrawler</c><00:10:47.519><c> call</c><00:10:48.079><c> to</c><00:10:48.320><c> use</c><00:10:48.560><c> the</c><00:10:48.800><c> browser</c> async webcrawler call to use the browser async webcrawler call to use the browser config<00:10:49.600><c> that</c><00:10:49.760><c> I</c><00:10:49.839><c> imported</c><00:10:50.160><c> from</c><00:10:50.320><c> crawl</c><00:10:50.560><c> for</c> config that I imported from crawl for config that I imported from crawl for AAI<00:10:51.120><c> in</c><00:10:51.279><c> line</c><00:10:51.600><c> 2.</c><00:10:52.079><c> And</c><00:10:52.320><c> boom,</c><00:10:52.800><c> it</c><00:10:53.040><c> spelled</c> AAI in line 2. And boom, it spelled AAI in line 2. And boom, it spelled everything<00:10:53.839><c> correctly</c><00:10:54.320><c> like</c><00:10:54.480><c> my</c><00:10:54.640><c> async</c> everything correctly like my async everything correctly like my async webcrawler,<00:10:55.600><c> browser</c><00:10:56.000><c> config.</c><00:10:56.399><c> It</c><00:10:56.560><c> really</c> webcrawler, browser config. It really webcrawler, browser config. It really understands<00:10:57.279><c> the</c><00:10:57.440><c> code</c><00:10:57.600><c> that</c><00:10:57.839><c> I'm</c><00:10:58.000><c> working</c><00:10:58.160><c> on</c> understands the code that I'm working on understands the code that I'm working on so<00:10:58.560><c> I</c><00:10:58.800><c> can</c><00:10:58.880><c> communicate</c><00:10:59.360><c> effectively</c><00:11:00.160><c> with</c> so I can communicate effectively with so I can communicate effectively with Windsurf.<00:11:01.279><c> And</c><00:11:01.440><c> within</c><00:11:01.680><c> the</c><00:11:01.839><c> Aqua</c><00:11:02.240><c> app,</c><00:11:02.480><c> you</c> Windsurf. And within the Aqua app, you Windsurf. And within the Aqua app, you can<00:11:02.800><c> tweak</c><00:11:03.040><c> your</c><00:11:03.279><c> settings.</c><00:11:03.680><c> You</c><00:11:03.839><c> can</c><00:11:03.920><c> toggle</c> can tweak your settings. You can toggle can tweak your settings. You can toggle deep<00:11:04.560><c> context</c><00:11:04.959><c> on</c><00:11:05.200><c> and</c><00:11:05.360><c> off.</c><00:11:05.839><c> Add</c><00:11:06.079><c> things</c><00:11:06.240><c> to</c> deep context on and off. Add things to deep context on and off. Add things to your<00:11:06.560><c> dictionary</c><00:11:07.040><c> so</c><00:11:07.200><c> it</c><00:11:07.360><c> dictates</c><00:11:07.760><c> it</c> your dictionary so it dictates it your dictionary so it dictates it properly.<00:11:08.720><c> Give</c><00:11:08.959><c> custom</c><00:11:09.279><c> instructions</c><00:11:10.000><c> based</c> properly. Give custom instructions based properly. Give custom instructions based on<00:11:10.399><c> different</c><00:11:10.720><c> applications.</c><00:11:11.519><c> There's</c><00:11:11.760><c> so</c> on different applications. There's so on different applications. There's so much<00:11:12.240><c> control</c><00:11:12.560><c> that</c><00:11:12.800><c> you</c><00:11:13.040><c> have</c><00:11:13.200><c> here.</c><00:11:13.680><c> And</c> much control that you have here. And much control that you have here. And then<00:11:14.000><c> the</c><00:11:14.240><c> main</c><00:11:14.480><c> component</c><00:11:14.880><c> of</c><00:11:15.040><c> this</c><00:11:15.279><c> GitHub</c> then the main component of this GitHub then the main component of this GitHub repository<00:11:16.240><c> is</c><00:11:16.560><c> I</c><00:11:16.880><c> created</c><00:11:17.200><c> an</c><00:11:17.360><c> AI</c><00:11:17.760><c> agent</c><00:11:18.399><c> that</c> repository is I created an AI agent that repository is I created an AI agent that has<00:11:18.959><c> this</c><00:11:19.279><c> script</c><00:11:19.600><c> as</c><00:11:19.839><c> well</c><00:11:20.000><c> to</c><00:11:20.240><c> insert</c> has this script as well to insert has this script as well to insert documents<00:11:21.120><c> into</c><00:11:21.440><c> its</c><00:11:21.760><c> knowledge</c><00:11:22.079><c> base</c><00:11:22.640><c> that</c> documents into its knowledge base that documents into its knowledge base that combines<00:11:23.519><c> all</c><00:11:23.760><c> three</c><00:11:24.079><c> strategies.</c><00:11:24.720><c> So</c><00:11:24.959><c> you</c> combines all three strategies. So you combines all three strategies. So you can<00:11:25.360><c> give</c><00:11:25.680><c> this</c><00:11:25.920><c> script</c><00:11:26.160><c> a</c><00:11:26.399><c> URL</c><00:11:27.040><c> and</c><00:11:27.200><c> it</c><00:11:27.440><c> will</c> can give this script a URL and it will can give this script a URL and it will intelligently<00:11:28.160><c> determine</c><00:11:28.640><c> is</c><00:11:28.800><c> this</c><00:11:28.959><c> a</c> intelligently determine is this a intelligently determine is this a sitemap,<00:11:29.519><c> an</c><00:11:29.760><c> LLM.ext</c><00:11:30.720><c> or</c><00:11:30.959><c> a</c><00:11:31.200><c> regular</c><00:11:31.519><c> web</c> sitemap, an LLM.ext or a regular web sitemap, an LLM.ext or a regular web page<00:11:32.240><c> and</c><00:11:32.480><c> then</c><00:11:32.720><c> use</c><00:11:33.040><c> that</c><00:11:33.440><c> specific</c><00:11:34.000><c> strategy</c> page and then use that specific strategy page and then use that specific strategy depending<00:11:34.959><c> on</c><00:11:35.200><c> which</c><00:11:35.519><c> type</c><00:11:35.680><c> of</c><00:11:35.839><c> URL</c><00:11:36.320><c> it</c><00:11:36.560><c> is.</c> depending on which type of URL it is. depending on which type of URL it is. And<00:11:37.360><c> then</c><00:11:37.600><c> this</c><00:11:37.760><c> is</c><00:11:37.920><c> all</c><00:11:38.079><c> set</c><00:11:38.240><c> up</c><00:11:38.640><c> with</c><00:11:38.880><c> a</c> And then this is all set up with a And then this is all set up with a pyantic<00:11:39.839><c> AI</c><00:11:40.240><c> rag</c><00:11:40.640><c> agent</c><00:11:41.200><c> that</c><00:11:41.440><c> is</c><00:11:41.600><c> using</c> pyantic AI rag agent that is using pyantic AI rag agent that is using Chroma<00:11:42.480><c> DB</c><00:11:42.880><c> for</c><00:11:43.200><c> its</c><00:11:43.440><c> vector</c><00:11:43.760><c> database.</c><00:11:44.240><c> So</c><00:11:44.320><c> I</c> Chroma DB for its vector database. So I Chroma DB for its vector database. So I just<00:11:44.560><c> wanted</c><00:11:44.800><c> something</c><00:11:44.959><c> really</c><00:11:45.600><c> simple</c><00:11:46.000><c> and</c> just wanted something really simple and just wanted something really simple and that<00:11:46.399><c> you</c><00:11:46.560><c> can</c><00:11:46.720><c> run</c><00:11:46.880><c> locally.</c><00:11:47.279><c> So</c><00:11:47.360><c> that's</c><00:11:47.519><c> why</c> that you can run locally. So that's why that you can run locally. So that's why I<00:11:47.760><c> chose</c><00:11:48.000><c> Chroma</c><00:11:48.399><c> DB.</c><00:11:48.959><c> But</c><00:11:49.040><c> you</c><00:11:49.200><c> could</c> I chose Chroma DB. But you could I chose Chroma DB. But you could obviously<00:11:49.680><c> use</c><00:11:49.920><c> Superbase</c><00:11:50.480><c> or</c><00:11:50.640><c> Quadrant</c><00:11:51.120><c> or</c> obviously use Superbase or Quadrant or obviously use Superbase or Quadrant or Pine<00:11:51.600><c> Cone</c><00:11:51.920><c> something</c><00:11:52.079><c> else</c><00:11:52.320><c> for</c><00:11:52.800><c> your</c><00:11:53.040><c> vector</c> Pine Cone something else for your vector Pine Cone something else for your vector database<00:11:53.920><c> as</c><00:11:54.160><c> well.</c><00:11:54.480><c> So</c><00:11:54.880><c> a</c><00:11:55.040><c> very</c><00:11:55.279><c> simple</c><00:11:55.519><c> agent</c> database as well. So a very simple agent database as well. So a very simple agent overall<00:11:56.560><c> just</c><00:11:56.800><c> leveraging</c><00:11:57.279><c> a</c><00:11:57.519><c> tool</c><00:11:58.079><c> that</c><00:11:58.320><c> will</c> overall just leveraging a tool that will overall just leveraging a tool that will allow<00:11:58.800><c> us</c><00:11:58.959><c> to</c><00:11:59.200><c> search</c><00:11:59.600><c> all</c><00:11:59.760><c> of</c><00:11:59.920><c> this</c><00:12:00.160><c> knowledge</c> allow us to search all of this knowledge allow us to search all of this knowledge that<00:12:00.720><c> we</c><00:12:00.959><c> give</c><00:12:01.200><c> to</c><00:12:01.440><c> our</c><00:12:01.600><c> vector</c><00:12:02.000><c> database</c> that we give to our vector database that we give to our vector database through<00:12:02.720><c> what</c><00:12:02.880><c> we</c><00:12:03.040><c> crawl</c><00:12:03.440><c> with</c><00:12:03.839><c> crawl</c><00:12:04.240><c> for</c> through what we crawl with crawl for through what we crawl with crawl for AAI.<00:12:05.040><c> And</c><00:12:05.200><c> within</c><00:12:05.440><c> the</c><00:12:05.600><c> readme</c><00:12:06.000><c> that</c><00:12:06.079><c> I</c><00:12:06.240><c> have</c> AAI. And within the readme that I have AAI. And within the readme that I have for<00:12:06.560><c> this</c><00:12:06.720><c> repository,</c><00:12:07.440><c> I</c><00:12:07.680><c> show</c><00:12:07.760><c> you</c><00:12:07.920><c> how</c><00:12:08.079><c> to</c> for this repository, I show you how to for this repository, I show you how to get<00:12:08.399><c> everything</c><00:12:08.800><c> up</c><00:12:08.959><c> and</c><00:12:09.120><c> running.</c><00:12:09.440><c> So</c> get everything up and running. So get everything up and running. So prerequisites,<00:12:10.639><c> installation</c> prerequisites, installation prerequisites, installation instructions,<00:12:11.920><c> setting</c><00:12:12.160><c> up</c><00:12:12.320><c> your</c> instructions, setting up your instructions, setting up your environment<00:12:12.959><c> variables,</c><00:12:13.760><c> how</c><00:12:13.920><c> you</c><00:12:14.160><c> can</c><00:12:14.399><c> use</c> environment variables, how you can use environment variables, how you can use these<00:12:15.200><c> different</c><00:12:15.440><c> scripts</c><00:12:15.760><c> to</c><00:12:16.000><c> get</c><00:12:16.160><c> the</c> these different scripts to get the these different scripts to get the knowledge<00:12:16.560><c> base</c><00:12:16.800><c> set</c><00:12:16.959><c> up</c><00:12:17.040><c> and</c><00:12:17.200><c> to</c><00:12:17.360><c> run</c><00:12:17.519><c> the</c> knowledge base set up and to run the knowledge base set up and to run the agent<00:12:18.079><c> itself.</c><00:12:18.639><c> So</c><00:12:18.880><c> all</c><00:12:19.040><c> the</c><00:12:19.200><c> instructions</c> agent itself. So all the instructions agent itself. So all the instructions are<00:12:19.760><c> here</c><00:12:19.920><c> and</c><00:12:20.160><c> I</c><00:12:20.320><c> can</c><00:12:20.480><c> actually</c><00:12:20.800><c> show</c><00:12:20.959><c> you</c><00:12:21.440><c> a</c> are here and I can actually show you a are here and I can actually show you a demo<00:12:22.000><c> of</c><00:12:22.160><c> this</c><00:12:22.480><c> live.</c><00:12:22.800><c> So,</c><00:12:22.959><c> I'm</c><00:12:23.200><c> going</c><00:12:23.279><c> to</c><00:12:23.440><c> run</c> demo of this live. So, I'm going to run demo of this live. So, I'm going to run the<00:12:24.160><c> insert</c><00:12:24.720><c> docs</c><00:12:25.279><c> function</c><00:12:26.240><c> and</c><00:12:26.480><c> then</c><00:12:26.639><c> I'm</c> the insert docs function and then I'm the insert docs function and then I'm going<00:12:26.959><c> to</c><00:12:27.279><c> copy</c><00:12:27.920><c> the</c><00:12:28.320><c> URL</c><00:12:29.040><c> for</c><00:12:29.279><c> the</c><00:12:29.440><c> sitemap</c> going to copy the URL for the sitemap going to copy the URL for the sitemap for<00:12:30.160><c> crawl</c><00:12:30.480><c> for</c><00:12:30.639><c> AAI.</c><00:12:30.959><c> So,</c><00:12:31.040><c> I'm</c><00:12:31.279><c> going</c><00:12:31.360><c> to</c><00:12:31.440><c> send</c> for crawl for AAI. So, I'm going to send for crawl for AAI. So, I'm going to send this<00:12:31.839><c> in.</c><00:12:32.079><c> It's</c><00:12:32.320><c> going</c><00:12:32.399><c> to</c><00:12:32.560><c> determine</c><00:12:32.880><c> that</c><00:12:33.040><c> it</c> this in. It's going to determine that it this in. It's going to determine that it has<00:12:33.360><c> to</c><00:12:33.519><c> use</c><00:12:34.079><c> that</c><00:12:34.639><c> first</c><00:12:34.959><c> strategy</c><00:12:35.519><c> to</c><00:12:36.160><c> scrape</c> has to use that first strategy to scrape has to use that first strategy to scrape everything<00:12:36.959><c> from</c><00:12:37.360><c> a</c><00:12:37.600><c> sitemap.</c><00:12:38.320><c> And</c><00:12:38.480><c> look</c><00:12:38.560><c> at</c> everything from a sitemap. And look at everything from a sitemap. And look at that.<00:12:38.880><c> We're</c><00:12:39.120><c> fetching</c><00:12:39.519><c> all</c><00:12:39.839><c> of</c><00:12:40.079><c> these</c><00:12:40.639><c> URLs</c> that. We're fetching all of these URLs that. We're fetching all of these URLs in<00:12:41.440><c> batches.</c><00:12:41.839><c> I</c><00:12:42.000><c> think</c><00:12:42.079><c> I</c><00:12:42.240><c> have</c><00:12:42.320><c> a</c><00:12:42.480><c> batch</c><00:12:42.800><c> size</c> in batches. I think I have a batch size in batches. I think I have a batch size of<00:12:43.600><c> five</c><00:12:43.920><c> or</c><00:12:44.240><c> something</c><00:12:44.399><c> like</c><00:12:44.639><c> that.</c><00:12:45.040><c> So,</c><00:12:45.200><c> it's</c> of five or something like that. So, it's of five or something like that. So, it's it's<00:12:45.839><c> scraping</c><00:12:46.240><c> five</c><00:12:46.480><c> at</c><00:12:46.639><c> a</c><00:12:46.800><c> time.</c><00:12:47.279><c> Doing</c><00:12:47.440><c> this</c> it's scraping five at a time. Doing this it's scraping five at a time. Doing this very<00:12:48.000><c> very</c><00:12:48.240><c> quickly.</c><00:12:48.560><c> And</c><00:12:48.800><c> so</c><00:12:49.040><c> there</c><00:12:49.279><c> are</c> very very quickly. And so there are very very quickly. And so there are quite<00:12:49.760><c> a</c><00:12:50.000><c> few</c><00:12:50.240><c> pages</c><00:12:50.560><c> that</c><00:12:50.800><c> we</c><00:12:51.040><c> have</c><00:12:51.279><c> for</c><00:12:51.760><c> crawl</c> quite a few pages that we have for crawl quite a few pages that we have for crawl for<00:12:52.320><c> AI.</c><00:12:52.720><c> It</c><00:12:52.959><c> created</c><00:12:53.720><c> 457</c><00:12:54.720><c> chunks</c><00:12:55.519><c> in</c><00:12:55.680><c> total</c> for AI. It created 457 chunks in total for AI. It created 457 chunks in total that<00:12:56.160><c> it's</c><00:12:56.320><c> now</c><00:12:56.480><c> inserting</c><00:12:56.880><c> into</c><00:12:57.120><c> Chroma</c><00:12:57.600><c> DB.</c> that it's now inserting into Chroma DB. that it's now inserting into Chroma DB. And<00:12:58.399><c> actually</c><00:12:58.959><c> basically</c><00:12:59.360><c> the</c><00:12:59.600><c> insert</c><00:12:59.920><c> into</c> And actually basically the insert into And actually basically the insert into Chroma<00:13:00.560><c> DB</c><00:13:01.200><c> takes</c><00:13:01.519><c> longer</c><00:13:01.839><c> than</c><00:13:02.079><c> the</c><00:13:02.320><c> scraping</c> Chroma DB takes longer than the scraping Chroma DB takes longer than the scraping itself.<00:13:03.279><c> That</c><00:13:03.440><c> is</c><00:13:03.600><c> how</c><00:13:04.000><c> blazing</c><00:13:04.560><c> fast</c><00:13:05.120><c> crawl</c> itself. That is how blazing fast crawl itself. That is how blazing fast crawl for<00:13:05.600><c> AAI</c><00:13:05.920><c> is.</c><00:13:06.240><c> And</c><00:13:06.399><c> we</c><00:13:06.560><c> could</c><00:13:06.639><c> even</c><00:13:06.880><c> make</c><00:13:06.959><c> it</c><00:13:07.120><c> so</c> for AAI is. And we could even make it so for AAI is. And we could even make it so that<00:13:07.360><c> it</c><00:13:07.519><c> batches</c><00:13:08.000><c> in</c><00:13:08.240><c> sets</c><00:13:08.560><c> of</c><00:13:08.720><c> 10</c><00:13:08.959><c> or</c><00:13:09.279><c> 20.</c><00:13:09.600><c> So</c> that it batches in sets of 10 or 20. So that it batches in sets of 10 or 20. So it<00:13:09.839><c> scrapes</c><00:13:10.480><c> even</c><00:13:10.800><c> faster.</c><00:13:11.440><c> And</c><00:13:11.600><c> there</c><00:13:11.760><c> we</c><00:13:11.920><c> go.</c> it scrapes even faster. And there we go. it scrapes even faster. And there we go. We<00:13:12.240><c> have</c><00:13:12.399><c> everything</c><00:13:12.720><c> inserted</c><00:13:13.120><c> into</c><00:13:13.360><c> Chroma</c> We have everything inserted into Chroma We have everything inserted into Chroma DB.<00:13:14.079><c> So</c><00:13:14.240><c> that</c><00:13:14.480><c> process</c><00:13:14.880><c> is</c><00:13:15.120><c> now</c><00:13:15.360><c> done.</c><00:13:15.680><c> But</c> DB. So that process is now done. But DB. So that process is now done. But what<00:13:15.920><c> I</c><00:13:16.079><c> can</c><00:13:16.240><c> do</c><00:13:16.639><c> is</c><00:13:16.800><c> just</c><00:13:17.120><c> run</c><00:13:17.360><c> this</c><00:13:17.600><c> another</c> what I can do is just run this another what I can do is just run this another time,<00:13:18.240><c> but</c><00:13:18.399><c> instead</c><00:13:18.639><c> of</c><00:13:18.800><c> using</c><00:13:18.959><c> the</c><00:13:19.120><c> crawl</c><00:13:19.360><c> for</c> time, but instead of using the crawl for time, but instead of using the crawl for ai<00:13:19.839><c> sitemap,</c><00:13:20.560><c> how</c><00:13:20.720><c> about</c><00:13:20.880><c> this</c><00:13:21.120><c> time</c><00:13:21.360><c> we</c><00:13:21.600><c> use</c> ai sitemap, how about this time we use ai sitemap, how about this time we use the<00:13:22.320><c> pidantic</c><00:13:23.120><c> web</c><00:13:23.360><c> page.</c><00:13:23.680><c> So</c><00:13:23.839><c> not</c><00:13:24.000><c> a</c><00:13:24.160><c> sitemap</c> the pidantic web page. So not a sitemap the pidantic web page. So not a sitemap or<00:13:24.800><c> llm's.ext.</c><00:13:25.760><c> So</c><00:13:25.920><c> I'm</c><00:13:26.079><c> going</c><00:13:26.079><c> to</c><00:13:26.160><c> go</c><00:13:26.240><c> ahead</c> or llm's.ext. So I'm going to go ahead or llm's.ext. So I'm going to go ahead copy<00:13:26.959><c> this</c><00:13:27.120><c> URL,</c><00:13:27.600><c> paste</c><00:13:27.839><c> it</c><00:13:28.000><c> here.</c><00:13:28.320><c> Now</c><00:13:28.480><c> it'll</c> copy this URL, paste it here. Now it'll copy this URL, paste it here. Now it'll say<00:13:28.880><c> that</c><00:13:29.040><c> it</c><00:13:29.200><c> detects</c><00:13:29.519><c> that</c><00:13:29.680><c> it</c><00:13:29.839><c> is</c><00:13:29.920><c> a</c><00:13:30.160><c> regular</c> say that it detects that it is a regular say that it detects that it is a regular web<00:13:30.720><c> page</c><00:13:30.880><c> that</c><00:13:31.040><c> it</c><00:13:31.200><c> has</c><00:13:31.360><c> to</c><00:13:31.519><c> crawl.</c><00:13:31.920><c> Regular</c> web page that it has to crawl. Regular web page that it has to crawl. Regular URL<00:13:33.120><c> and</c><00:13:33.360><c> we'll</c><00:13:33.519><c> give</c><00:13:33.600><c> it</c><00:13:33.760><c> a</c><00:13:33.920><c> second</c><00:13:34.160><c> and</c><00:13:34.399><c> boom,</c> URL and we'll give it a second and boom, URL and we'll give it a second and boom, there<00:13:34.800><c> we</c><00:13:34.959><c> go.</c><00:13:35.120><c> It</c><00:13:35.279><c> starts</c><00:13:35.519><c> with</c><00:13:35.680><c> the</c><00:13:35.839><c> homepage</c> there we go. It starts with the homepage there we go. It starts with the homepage and<00:13:36.800><c> then</c><00:13:37.040><c> it</c><00:13:37.200><c> checks</c><00:13:37.440><c> the</c><00:13:37.680><c> navigation.</c><00:13:38.079><c> It</c> and then it checks the navigation. It and then it checks the navigation. It looks<00:13:38.399><c> for</c><00:13:38.560><c> what</c><00:13:38.720><c> are</c><00:13:38.880><c> called</c><00:13:39.120><c> internal</c> looks for what are called internal looks for what are called internal links.<00:13:40.000><c> That's</c><00:13:40.160><c> the</c><00:13:40.480><c> phrase</c><00:13:40.800><c> used</c><00:13:40.959><c> with</c><00:13:41.120><c> crawl</c> links. That's the phrase used with crawl links. That's the phrase used with crawl for<00:13:41.600><c> AAI</c><00:13:42.079><c> to</c><00:13:42.320><c> find</c><00:13:42.560><c> all</c><00:13:42.639><c> the</c><00:13:42.880><c> different</c><00:13:43.040><c> web</c> for AAI to find all the different web for AAI to find all the different web pages.<00:13:43.600><c> go</c><00:13:43.839><c> through</c><00:13:44.000><c> there,</c><00:13:44.560><c> find</c><00:13:44.800><c> even</c><00:13:45.040><c> more</c> pages. go through there, find even more pages. go through there, find even more links<00:13:45.760><c> to</c><00:13:46.079><c> other</c><00:13:46.399><c> parts</c><00:13:46.639><c> of</c><00:13:46.800><c> the</c><00:13:46.959><c> web</c><00:13:47.200><c> page.</c> links to other parts of the web page. links to other parts of the web page. Really<00:13:48.000><c> trying</c><00:13:48.160><c> to</c><00:13:48.320><c> hit</c><00:13:48.480><c> on</c><00:13:48.720><c> everything.</c><00:13:49.200><c> Like</c> Really trying to hit on everything. Like Really trying to hit on everything. Like I<00:13:49.760><c> don't</c><00:13:49.839><c> have</c><00:13:49.920><c> the</c><00:13:50.440><c> sitemap.xml.</c><00:13:51.440><c> So</c><00:13:51.680><c> if</c><00:13:51.920><c> I</c> I don't have the sitemap.xml. So if I I don't have the sitemap.xml. So if I have<00:13:52.160><c> a</c><00:13:52.399><c> certain</c><00:13:52.639><c> depth,</c><00:13:52.880><c> like</c><00:13:53.040><c> I</c><00:13:53.200><c> go</c><00:13:53.440><c> three</c> have a certain depth, like I go three have a certain depth, like I go three levels<00:13:54.000><c> deep,</c><00:13:54.480><c> I'm</c><00:13:54.720><c> not</c><00:13:54.880><c> absolutely</c> levels deep, I'm not absolutely levels deep, I'm not absolutely guaranteed<00:13:56.000><c> to</c><00:13:56.320><c> hit</c><00:13:56.639><c> every</c><00:13:56.880><c> single</c><00:13:57.199><c> web</c><00:13:57.440><c> page,</c> guaranteed to hit every single web page, guaranteed to hit every single web page, but<00:13:58.160><c> you</c><00:13:58.320><c> can</c><00:13:58.480><c> set</c><00:13:58.639><c> that</c><00:13:58.880><c> depth</c><00:13:59.120><c> to</c><00:13:59.360><c> something</c> but you can set that depth to something but you can set that depth to something more<00:13:59.920><c> like</c><00:14:00.160><c> five</c><00:14:00.399><c> or</c><00:14:00.639><c> six</c><00:14:00.800><c> if</c><00:14:01.040><c> you</c><00:14:01.120><c> want</c><00:14:01.279><c> as</c> more like five or six if you want as more like five or six if you want as well.<00:14:01.600><c> And</c><00:14:01.760><c> then</c><00:14:01.920><c> pretty</c><00:14:02.079><c> much</c><00:14:02.240><c> you</c><00:14:02.480><c> are</c><00:14:02.639><c> going</c> well. And then pretty much you are going well. And then pretty much you are going to<00:14:02.880><c> hit</c><00:14:03.120><c> on</c><00:14:03.600><c> any</c><00:14:03.920><c> page</c><00:14:04.240><c> you</c><00:14:04.399><c> could</c><00:14:04.560><c> possibly</c> to hit on any page you could possibly to hit on any page you could possibly have<00:14:05.199><c> within</c><00:14:05.519><c> this</c><00:14:05.839><c> website.</c><00:14:06.560><c> Especially</c> have within this website. Especially have within this website. Especially things<00:14:07.279><c> for</c><00:14:07.839><c> documentation</c><00:14:08.560><c> like</c><00:14:08.800><c> Pantic</c><00:14:09.279><c> AI</c> things for documentation like Pantic AI things for documentation like Pantic AI or<00:14:09.680><c> Langraphph</c><00:14:10.240><c> where</c><00:14:10.560><c> you're</c><00:14:10.800><c> not</c><00:14:10.880><c> really</c> or Langraphph where you're not really or Langraphph where you're not really going<00:14:11.120><c> to</c><00:14:11.279><c> go</c><00:14:11.440><c> that</c><00:14:11.680><c> deep.</c><00:14:12.000><c> the</c><00:14:12.240><c> navigation</c><00:14:12.800><c> on</c> going to go that deep. the navigation on going to go that deep. the navigation on the<00:14:13.199><c> lefth</c><00:14:13.360><c> hand</c><00:14:13.600><c> side</c><00:14:13.920><c> usually</c><00:14:14.240><c> it's</c><00:14:14.399><c> going</c> the lefth hand side usually it's going the lefth hand side usually it's going to<00:14:14.560><c> cover</c><00:14:14.800><c> most</c><00:14:15.279><c> of</c><00:14:15.519><c> what's</c><00:14:15.839><c> available</c><00:14:16.240><c> in</c><00:14:16.480><c> the</c> to cover most of what's available in the to cover most of what's available in the website<00:14:17.519><c> and</c><00:14:17.680><c> so</c><00:14:17.839><c> this</c><00:14:18.079><c> takes</c><00:14:18.399><c> a</c><00:14:18.639><c> little</c><00:14:18.720><c> bit</c> website and so this takes a little bit website and so this takes a little bit longer<00:14:19.279><c> overall</c><00:14:19.680><c> because</c><00:14:19.839><c> it</c><00:14:20.079><c> has</c><00:14:20.160><c> to</c><00:14:20.320><c> do</c><00:14:20.399><c> with</c> longer overall because it has to do with longer overall because it has to do with more<00:14:20.639><c> of</c><00:14:20.800><c> this</c><00:14:20.959><c> recursive</c><00:14:21.519><c> searching</c><00:14:22.000><c> and</c><00:14:22.160><c> so</c> more of this recursive searching and so more of this recursive searching and so I<00:14:22.720><c> will</c><00:14:22.880><c> pause</c><00:14:23.120><c> and</c><00:14:23.279><c> come</c><00:14:23.440><c> back</c><00:14:23.680><c> once</c><00:14:24.079><c> this</c> I will pause and come back once this I will pause and come back once this scraping<00:14:24.720><c> is</c><00:14:25.040><c> complete</c><00:14:25.839><c> and</c><00:14:26.000><c> there</c><00:14:26.160><c> we</c><00:14:26.320><c> go</c><00:14:26.480><c> we</c> scraping is complete and there we go we scraping is complete and there we go we are<00:14:26.880><c> done</c><00:14:27.040><c> and</c><00:14:27.199><c> this</c><00:14:27.360><c> time</c><00:14:27.519><c> it</c><00:14:27.760><c> inserted</c> are done and this time it inserted are done and this time it inserted 2,420<00:14:30.320><c> chunks</c><00:14:30.720><c> into</c><00:14:31.120><c> chroma</c><00:14:31.839><c> so</c><00:14:32.160><c> definitely</c> 2,420 chunks into chroma so definitely 2,420 chunks into chroma so definitely the<00:14:32.880><c> podantic</c><00:14:33.680><c> documentation</c><00:14:34.320><c> is</c><00:14:34.560><c> just</c><00:14:34.800><c> much</c> the podantic documentation is just much the podantic documentation is just much larger<00:14:35.600><c> than</c><00:14:35.760><c> what</c><00:14:35.839><c> we</c><00:14:36.000><c> have</c><00:14:36.160><c> in</c><00:14:36.399><c> crawl</c><00:14:36.720><c> for</c><00:14:36.959><c> AI</c> larger than what we have in crawl for AI larger than what we have in crawl for AI and<00:14:37.680><c> then</c><00:14:37.920><c> the</c><00:14:38.079><c> very</c><00:14:38.240><c> last</c><00:14:38.480><c> test</c><00:14:38.880><c> we</c><00:14:39.040><c> obviously</c> and then the very last test we obviously and then the very last test we obviously just<00:14:39.680><c> want</c><00:14:39.839><c> to</c><00:14:40.079><c> use</c><00:14:40.480><c> an</c><00:14:40.639><c> LLM's</c><00:14:41.519><c> text.</c><00:14:41.839><c> And</c><00:14:42.000><c> so</c> just want to use an LLM's text. And so just want to use an LLM's text. And so I'm<00:14:42.399><c> going</c><00:14:42.480><c> to</c><00:14:42.639><c> remove</c><00:14:42.880><c> that</c><00:14:43.120><c> link</c><00:14:43.279><c> to</c><00:14:43.440><c> pantic</c> I'm going to remove that link to pantic I'm going to remove that link to pantic AI<00:14:44.480><c> and</c><00:14:44.639><c> then</c><00:14:44.800><c> paste</c><00:14:45.040><c> in</c><00:14:45.199><c> the</c><00:14:45.279><c> llm.ext</c><00:14:46.240><c> for</c> AI and then paste in the llm.ext for AI and then paste in the llm.ext for langraph,<00:14:47.279><c> which</c><00:14:47.440><c> is</c><00:14:47.600><c> my</c><00:14:48.079><c> favorite</c><00:14:48.399><c> AI</c><00:14:48.959><c> agent</c> langraph, which is my favorite AI agent langraph, which is my favorite AI agent framework<00:14:49.760><c> to</c><00:14:50.000><c> orchestrate</c><00:14:50.560><c> different</c> framework to orchestrate different framework to orchestrate different agents<00:14:51.279><c> together.</c><00:14:52.000><c> And</c><00:14:52.160><c> so</c><00:14:52.399><c> this</c><00:14:52.560><c> time</c><00:14:52.959><c> it's</c> agents together. And so this time it's agents together. And so this time it's going<00:14:53.279><c> to</c><00:14:53.440><c> just</c><00:14:53.600><c> pull</c><00:14:53.839><c> that</c><00:14:54.079><c> single</c><00:14:54.480><c> page</c> going to just pull that single page going to just pull that single page instead<00:14:55.040><c> of</c><00:14:55.199><c> going</c><00:14:55.360><c> to</c><00:14:55.600><c> many</c><00:14:55.920><c> different</c><00:14:56.160><c> pages</c> instead of going to many different pages instead of going to many different pages and<00:14:56.959><c> it's</c><00:14:57.120><c> going</c><00:14:57.279><c> to</c><00:14:57.440><c> chunk</c><00:14:57.760><c> that</c><00:14:57.920><c> up.</c><00:14:58.160><c> So</c><00:14:58.320><c> it's</c> and it's going to chunk that up. So it's and it's going to chunk that up. So it's very<00:14:58.800><c> very</c><00:14:59.120><c> fast</c><00:14:59.279><c> now.</c><00:14:59.519><c> It</c><00:14:59.680><c> pulled</c><00:14:59.920><c> that</c><00:15:00.079><c> one</c> very very fast now. It pulled that one very very fast now. It pulled that one page,<00:15:00.720><c> split</c><00:15:00.959><c> it</c><00:15:01.120><c> into</c><00:15:01.639><c> 788</c><00:15:02.639><c> chunks,</c><00:15:03.120><c> and</c><00:15:03.360><c> now</c> page, split it into 788 chunks, and now page, split it into 788 chunks, and now it's<00:15:03.680><c> inserting</c><00:15:04.079><c> that</c><00:15:04.240><c> into</c><00:15:04.560><c> Chroma.</c><00:15:04.959><c> So</c><00:15:05.040><c> I'll</c> it's inserting that into Chroma. So I'll it's inserting that into Chroma. So I'll pause<00:15:05.440><c> and</c><00:15:05.600><c> come</c><00:15:05.760><c> back</c><00:15:05.920><c> again</c><00:15:06.160><c> once</c><00:15:06.480><c> that</c><00:15:06.720><c> is</c> pause and come back again once that is pause and come back again once that is complete.<00:15:07.440><c> And</c><00:15:07.600><c> there</c><00:15:07.760><c> we</c><00:15:07.920><c> go.</c><00:15:08.160><c> We've</c> complete. And there we go. We've complete. And there we go. We've inserted<00:15:08.880><c> all</c><00:15:09.120><c> of</c><00:15:09.199><c> our</c><00:15:09.360><c> langraph</c><00:15:09.920><c> chunks</c><00:15:10.320><c> into</c> inserted all of our langraph chunks into inserted all of our langraph chunks into Chroma<00:15:11.199><c> DB.</c><00:15:11.600><c> And</c><00:15:11.760><c> now</c><00:15:12.320><c> I've</c><00:15:12.560><c> showed</c><00:15:12.800><c> you</c><00:15:12.959><c> every</c> Chroma DB. And now I've showed you every Chroma DB. And now I've showed you every single<00:15:13.360><c> method.</c><00:15:13.760><c> Now</c><00:15:13.920><c> I</c><00:15:14.079><c> want</c><00:15:14.160><c> to</c><00:15:14.320><c> demo</c><00:15:14.560><c> the</c> single method. Now I want to demo the single method. Now I want to demo the agent<00:15:15.040><c> to</c><00:15:15.199><c> you.</c><00:15:15.440><c> Ask</c><00:15:15.600><c> it</c><00:15:15.760><c> some</c><00:15:16.000><c> questions</c><00:15:16.399><c> just</c> agent to you. Ask it some questions just agent to you. Ask it some questions just to<00:15:16.720><c> make</c><00:15:16.880><c> sure</c><00:15:16.959><c> that</c><00:15:17.199><c> all</c><00:15:17.279><c> the</c><00:15:17.519><c> knowledge</c><00:15:17.680><c> that</c> to make sure that all the knowledge that to make sure that all the knowledge that we<00:15:18.079><c> brought</c><00:15:18.240><c> into</c><00:15:18.399><c> our</c><00:15:18.560><c> agent</c><00:15:18.880><c> from</c><00:15:19.040><c> call</c><00:15:19.279><c> for</c> we brought into our agent from call for we brought into our agent from call for AAI<00:15:19.760><c> is</c><00:15:20.079><c> working</c><00:15:20.320><c> well.</c><00:15:20.639><c> So</c><00:15:20.800><c> I</c><00:15:20.959><c> have</c><00:15:21.040><c> a</c> AAI is working well. So I have a AAI is working well. So I have a streamlet<00:15:21.680><c> interface</c><00:15:22.079><c> created</c><00:15:22.399><c> that</c><00:15:22.639><c> I</c><00:15:22.800><c> show</c> streamlet interface created that I show streamlet interface created that I show you<00:15:23.040><c> how</c><00:15:23.120><c> to</c><00:15:23.279><c> set</c><00:15:23.360><c> up</c><00:15:23.519><c> in</c><00:15:23.680><c> the</c><00:15:23.839><c> readme.</c><00:15:24.399><c> So</c><00:15:24.560><c> I'm</c> you how to set up in the readme. So I'm you how to set up in the readme. So I'm just<00:15:24.800><c> going</c><00:15:24.880><c> to</c><00:15:24.959><c> run</c><00:15:25.040><c> the</c><00:15:25.279><c> command</c><00:15:25.519><c> streamllet</c> just going to run the command streamllet just going to run the command streamllet run<00:15:26.399><c> in</c><00:15:26.639><c> the</c><00:15:26.800><c> name</c><00:15:26.959><c> of</c><00:15:27.120><c> my</c><00:15:27.360><c> streamllet</c><00:15:27.839><c> python</c> run in the name of my streamllet python run in the name of my streamllet python script.<00:15:28.639><c> This</c><00:15:28.720><c> is</c><00:15:28.880><c> going</c><00:15:29.040><c> to</c><00:15:29.199><c> spin</c><00:15:29.440><c> up</c><00:15:29.600><c> a</c><00:15:29.760><c> page</c> script. This is going to spin up a page script. This is going to spin up a page in<00:15:30.160><c> the</c><00:15:30.320><c> browser</c><00:15:30.880><c> so</c><00:15:31.040><c> we</c><00:15:31.279><c> can</c><00:15:31.360><c> start</c><00:15:31.600><c> talking</c> in the browser so we can start talking in the browser so we can start talking to<00:15:32.160><c> our</c><00:15:32.480><c> agent.</c><00:15:32.880><c> And</c><00:15:33.040><c> it</c><00:15:33.199><c> takes</c><00:15:33.360><c> a</c><00:15:33.519><c> little</c><00:15:33.680><c> bit</c> to our agent. And it takes a little bit to our agent. And it takes a little bit for<00:15:34.160><c> the</c><00:15:34.399><c> first</c><00:15:34.639><c> message</c><00:15:34.959><c> to</c><00:15:35.199><c> go</c><00:15:35.360><c> through</c> for the first message to go through for the first message to go through because<00:15:35.920><c> it</c><00:15:36.160><c> has</c><00:15:36.240><c> to</c><00:15:36.399><c> load</c><00:15:36.560><c> the</c><00:15:36.720><c> Chroma</c><00:15:37.120><c> DB</c> because it has to load the Chroma DB because it has to load the Chroma DB instance.<00:15:37.920><c> But</c><00:15:38.000><c> otherwise,</c><00:15:38.560><c> these</c><00:15:38.880><c> messages</c> instance. But otherwise, these messages instance. But otherwise, these messages get<00:15:39.839><c> a</c><00:15:40.000><c> responses</c><00:15:40.480><c> from</c><00:15:40.639><c> the</c><00:15:40.800><c> agent</c><00:15:41.199><c> blazing</c> get a responses from the agent blazing get a responses from the agent blazing fast.<00:15:42.079><c> So,</c><00:15:42.320><c> first</c><00:15:42.480><c> I'll</c><00:15:42.800><c> have</c><00:15:42.880><c> it</c><00:15:43.120><c> verify</c><00:15:43.839><c> that</c> fast. So, first I'll have it verify that fast. So, first I'll have it verify that it<00:15:44.560><c> has</c><00:15:44.800><c> access</c><00:15:45.199><c> to</c><00:15:45.360><c> the</c><00:15:45.519><c> Piantic</c><00:15:46.079><c> AI</c><00:15:46.320><c> doc.</c><00:15:46.639><c> So,</c> it has access to the Piantic AI doc. So, it has access to the Piantic AI doc. So, verify<00:15:47.120><c> that</c><00:15:47.360><c> you</c><00:15:47.680><c> have</c><00:15:48.000><c> access</c><00:15:48.880><c> to</c><00:15:49.279><c> the</c> verify that you have access to the verify that you have access to the Pyantic<00:15:50.560><c> AI</c><00:15:51.040><c> doc.</c><00:15:51.360><c> So,</c><00:15:51.519><c> I'll</c><00:15:51.680><c> do</c><00:15:51.759><c> a</c><00:15:52.000><c> quick</c> Pyantic AI doc. So, I'll do a quick Pyantic AI doc. So, I'll do a quick search.<00:15:52.720><c> Confirm</c><00:15:53.040><c> for</c><00:15:53.279><c> me</c><00:15:53.360><c> that</c><00:15:53.519><c> it</c><00:15:53.759><c> has</c> search. Confirm for me that it has search. Confirm for me that it has access<00:15:54.240><c> to</c><00:15:54.399><c> the</c><00:15:54.560><c> documentation.</c><00:15:55.279><c> Good.</c><00:15:55.759><c> And</c> access to the documentation. Good. And access to the documentation. Good. And I'll<00:15:56.160><c> say</c><00:15:56.480><c> now</c><00:15:56.880><c> confirm</c><00:15:57.519><c> Superbase.</c><00:15:58.160><c> This</c><00:15:58.240><c> is</c> I'll say now confirm Superbase. This is I'll say now confirm Superbase. This is one<00:15:58.480><c> where</c><00:15:58.639><c> it</c><00:15:58.880><c> doesn't</c><00:15:59.120><c> actually</c><00:15:59.360><c> have</c><00:15:59.519><c> that</c> one where it doesn't actually have that one where it doesn't actually have that access.<00:16:00.320><c> And</c><00:16:00.480><c> so,</c><00:16:00.880><c> yep,</c><00:16:01.199><c> there</c><00:16:01.279><c> we</c><00:16:01.360><c> go.</c><00:16:01.519><c> The</c> access. And so, yep, there we go. The access. And so, yep, there we go. The documentation<00:16:02.240><c> available</c><00:16:02.639><c> does</c><00:16:02.880><c> not</c><00:16:03.040><c> contain</c> documentation available does not contain documentation available does not contain anything<00:16:03.759><c> about</c><00:16:04.079><c> superbase</c><00:16:04.720><c> because</c><00:16:04.880><c> we</c><00:16:05.120><c> only</c> anything about superbase because we only anything about superbase because we only crawled<00:16:05.839><c> crawl</c><00:16:06.079><c> for</c><00:16:06.320><c> AI,</c><00:16:06.720><c> pyantic</c><00:16:07.360><c> AI</c><00:16:08.000><c> and</c> crawled crawl for AI, pyantic AI and crawled crawl for AI, pyantic AI and langraph.<00:16:09.040><c> And</c><00:16:09.199><c> so</c><00:16:09.360><c> now</c><00:16:09.519><c> I</c><00:16:09.759><c> can</c><00:16:09.920><c> refresh</c><00:16:10.320><c> the</c> langraph. And so now I can refresh the langraph. And so now I can refresh the conversation<00:16:11.040><c> here.</c><00:16:11.199><c> I'll</c><00:16:11.440><c> just</c><00:16:11.519><c> ask</c><00:16:11.680><c> it</c><00:16:11.920><c> a</c> conversation here. I'll just ask it a conversation here. I'll just ask it a simple<00:16:12.320><c> question</c><00:16:12.880><c> about</c><00:16:13.120><c> pyantic</c><00:16:13.680><c> AI.</c><00:16:14.000><c> Just</c> simple question about pyantic AI. Just simple question about pyantic AI. Just show<00:16:14.240><c> me</c><00:16:14.399><c> how</c><00:16:14.560><c> to</c><00:16:14.720><c> create</c><00:16:15.040><c> a</c><00:16:15.360><c> very</c><00:16:15.759><c> basic</c> show me how to create a very basic show me how to create a very basic agent.<00:16:16.720><c> And</c><00:16:16.880><c> so</c><00:16:17.199><c> it</c><00:16:17.440><c> doesn't</c><00:16:17.600><c> give</c><00:16:17.759><c> me</c><00:16:17.839><c> a</c><00:16:18.000><c> step</c> agent. And so it doesn't give me a step agent. And so it doesn't give me a step by<00:16:18.399><c> step</c><00:16:18.560><c> in</c><00:16:18.720><c> the</c><00:16:18.880><c> documentation,</c><00:16:19.440><c> which</c><00:16:19.680><c> is</c> by step in the documentation, which is by step in the documentation, which is fine.<00:16:20.480><c> I</c><00:16:20.720><c> don't</c><00:16:20.800><c> really</c><00:16:21.040><c> expect</c><00:16:21.279><c> it</c><00:16:21.440><c> to</c><00:16:21.519><c> have</c> fine. I don't really expect it to have fine. I don't really expect it to have that,<00:16:21.839><c> but</c><00:16:22.000><c> I'll</c><00:16:22.160><c> just</c><00:16:22.320><c> say</c><00:16:22.800><c> give</c><00:16:23.040><c> me</c> that, but I'll just say give me that, but I'll just say give me something<00:16:24.000><c> very</c><00:16:24.480><c> basic</c><00:16:24.880><c> here.</c><00:16:25.120><c> So</c><00:16:25.199><c> just</c><00:16:25.360><c> so</c><00:16:25.440><c> I</c> something very basic here. So just so I something very basic here. So just so I can<00:16:25.680><c> see</c><00:16:25.759><c> that</c><00:16:25.920><c> it</c><00:16:26.079><c> yeah,</c><00:16:26.240><c> it</c><00:16:26.480><c> got</c><00:16:26.639><c> something</c> can see that it yeah, it got something can see that it yeah, it got something from<00:16:27.040><c> the</c><00:16:27.279><c> documentation.</c><00:16:27.920><c> So</c><00:16:28.079><c> there</c><00:16:28.240><c> we</c><00:16:28.399><c> go.</c> from the documentation. So there we go. from the documentation. So there we go. That<00:16:29.040><c> is</c><00:16:29.199><c> looking</c><00:16:29.440><c> good.</c><00:16:29.680><c> All</c><00:16:29.680><c> right.</c><00:16:29.839><c> Right.</c> That is looking good. All right. Right. That is looking good. All right. Right. So,<00:16:30.320><c> refresh</c><00:16:30.639><c> the</c><00:16:30.800><c> conversation.</c><00:16:31.519><c> Now,</c><00:16:31.680><c> we</c> So, refresh the conversation. Now, we So, refresh the conversation. Now, we can<00:16:32.000><c> try</c><00:16:32.160><c> something</c><00:16:32.320><c> out</c><00:16:32.560><c> with</c><00:16:32.800><c> crawl</c><00:16:33.120><c> for</c><00:16:33.360><c> AI.</c> can try something out with crawl for AI. can try something out with crawl for AI. So,<00:16:33.839><c> I'll</c><00:16:34.000><c> ask</c><00:16:34.160><c> it</c><00:16:34.399><c> something</c><00:16:34.560><c> basic</c><00:16:34.880><c> like</c><00:16:35.199><c> how</c> So, I'll ask it something basic like how So, I'll ask it something basic like how do<00:16:35.680><c> I</c><00:16:36.079><c> install</c><00:16:36.800><c> crawl</c><00:16:37.279><c> for</c><00:16:37.600><c> AI?</c><00:16:38.000><c> We'll</c><00:16:38.160><c> see</c><00:16:38.240><c> if</c> do I install crawl for AI? We'll see if do I install crawl for AI? We'll see if it<00:16:38.399><c> can</c><00:16:38.480><c> give</c><00:16:38.560><c> me</c><00:16:38.720><c> those</c><00:16:38.880><c> pip</c><00:16:39.199><c> commands</c><00:16:39.440><c> like</c> it can give me those pip commands like it can give me those pip commands like we<00:16:39.759><c> saw</c><00:16:39.920><c> earlier.</c><00:16:40.399><c> Yeah,</c><00:16:40.639><c> there</c><00:16:40.800><c> we</c><00:16:40.880><c> go.</c><00:16:41.120><c> So,</c> we saw earlier. Yeah, there we go. So, we saw earlier. Yeah, there we go. So, crawl<00:16:41.519><c> for</c><00:16:41.680><c> AAI</c><00:16:42.000><c> setup.</c><00:16:42.320><c> So,</c><00:16:42.480><c> all</c><00:16:42.560><c> the</c><00:16:42.800><c> setup</c> crawl for AAI setup. So, all the setup crawl for AAI setup. So, all the setup commands<00:16:43.360><c> as</c><00:16:43.519><c> well.</c><00:16:43.839><c> Looking</c><00:16:44.160><c> really</c><00:16:44.399><c> good.</c> commands as well. Looking really good. commands as well. Looking really good. And<00:16:44.720><c> then</c><00:16:44.800><c> I</c><00:16:44.959><c> can</c><00:16:45.040><c> do</c><00:16:45.120><c> something</c><00:16:45.279><c> for</c> And then I can do something for And then I can do something for langraph.<00:16:46.000><c> I</c><00:16:46.079><c> could</c><00:16:46.240><c> just</c><00:16:46.320><c> ask</c><00:16:46.480><c> the</c><00:16:46.720><c> same</c> langraph. I could just ask the same langraph. I could just ask the same question<00:16:47.040><c> here.</c><00:16:47.199><c> I</c><00:16:47.360><c> just</c><00:16:47.519><c> want</c><00:16:47.680><c> something</c> question here. I just want something question here. I just want something really<00:16:48.240><c> basic</c><00:16:48.639><c> because</c><00:16:48.800><c> I'm</c><00:16:48.959><c> focused</c><00:16:49.199><c> on</c> really basic because I'm focused on really basic because I'm focused on crawl<00:16:49.680><c> for</c><00:16:49.839><c> AI,</c><00:16:50.240><c> not</c><00:16:50.399><c> rag</c><00:16:51.199><c> um</c><00:16:51.360><c> and</c><00:16:51.759><c> chromadb</c> crawl for AI, not rag um and chromadb crawl for AI, not rag um and chromadb too<00:16:52.639><c> much</c><00:16:52.720><c> in</c><00:16:52.880><c> this</c><00:16:53.040><c> video.</c><00:16:53.199><c> So,</c><00:16:53.360><c> I'll</c><00:16:53.519><c> just</c> too much in this video. So, I'll just too much in this video. So, I'll just say<00:16:54.320><c> how</c><00:16:54.639><c> do</c><00:16:54.880><c> I</c><00:16:55.199><c> install</c><00:16:55.839><c> langraph?</c><00:16:56.480><c> We'll</c><00:16:56.720><c> see</c> say how do I install langraph? We'll see say how do I install langraph? We'll see if<00:16:56.880><c> we</c><00:16:56.959><c> can</c><00:16:57.120><c> get</c><00:16:57.199><c> the</c><00:16:57.360><c> instructions</c><00:16:57.839><c> for</c><00:16:58.079><c> that</c> if we can get the instructions for that if we can get the instructions for that as<00:16:58.880><c> well</c><00:16:59.199><c> through</c><00:16:59.600><c> the</c><00:17:00.240><c> documentation.</c><00:17:00.800><c> Yeah,</c> as well through the documentation. Yeah, as well through the documentation. Yeah, pip<00:17:01.279><c> install</c><00:17:01.519><c> lang</c><00:17:01.839><c> graph</c><00:17:02.240><c> really</c><00:17:02.560><c> basic.</c> pip install lang graph really basic. pip install lang graph really basic. Maybe<00:17:03.440><c> the</c><00:17:03.600><c> LLM</c><00:17:04.079><c> would</c><00:17:04.240><c> have</c><00:17:04.400><c> been</c><00:17:04.559><c> able</c><00:17:04.799><c> to</c> Maybe the LLM would have been able to Maybe the LLM would have been able to get<00:17:05.360><c> this</c><00:17:05.760><c> just</c><00:17:06.000><c> with</c><00:17:06.240><c> its</c><00:17:06.480><c> own</c><00:17:06.640><c> knowledge,</c> get this just with its own knowledge, get this just with its own knowledge, but<00:17:07.360><c> I</c><00:17:07.600><c> know</c><00:17:07.760><c> that</c><00:17:07.919><c> it's</c><00:17:08.160><c> searching</c><00:17:08.480><c> through</c> but I know that it's searching through but I know that it's searching through the<00:17:08.880><c> database</c><00:17:09.199><c> under</c><00:17:09.360><c> the</c><00:17:09.520><c> hood</c><00:17:09.679><c> and</c><00:17:09.760><c> we</c><00:17:09.919><c> saw</c> the database under the hood and we saw the database under the hood and we saw that<00:17:10.160><c> it</c><00:17:10.319><c> definitely</c><00:17:10.559><c> needed</c><00:17:10.799><c> to</c><00:17:10.959><c> do</c><00:17:11.039><c> that</c><00:17:11.199><c> for</c> that it definitely needed to do that for that it definitely needed to do that for things<00:17:11.600><c> like</c><00:17:11.839><c> crawl</c><00:17:12.079><c> for</c><00:17:12.319><c> AAI</c><00:17:12.720><c> and</c><00:17:13.039><c> Pantic</c><00:17:13.600><c> AI.</c> things like crawl for AAI and Pantic AI. things like crawl for AAI and Pantic AI. So<00:17:14.240><c> yeah,</c><00:17:14.480><c> this</c><00:17:14.720><c> is</c><00:17:14.880><c> working</c><00:17:15.199><c> great.</c><00:17:15.760><c> So,</c><00:17:15.919><c> I</c> So yeah, this is working great. So, I So yeah, this is working great. So, I know<00:17:16.240><c> that</c><00:17:16.400><c> in</c><00:17:16.640><c> general</c><00:17:16.880><c> I</c><00:17:17.120><c> haven't</c><00:17:17.360><c> covered</c> know that in general I haven't covered know that in general I haven't covered the<00:17:17.760><c> nitty-gritty</c><00:17:18.319><c> details</c><00:17:18.640><c> of</c><00:17:18.799><c> the</c><00:17:19.039><c> code</c> the nitty-gritty details of the code the nitty-gritty details of the code that<00:17:19.520><c> much</c><00:17:19.679><c> in</c><00:17:19.919><c> this</c><00:17:20.079><c> video</c><00:17:20.319><c> because</c><00:17:20.559><c> I</c><00:17:20.720><c> wanted</c> that much in this video because I wanted that much in this video because I wanted to<00:17:21.039><c> give</c><00:17:21.120><c> you</c><00:17:21.360><c> a</c><00:17:21.679><c> very</c><00:17:21.839><c> highlevel</c><00:17:22.400><c> overview</c><00:17:22.720><c> of</c> to give you a very highlevel overview of to give you a very highlevel overview of how<00:17:23.120><c> this</c><00:17:23.280><c> agent</c><00:17:23.600><c> works,</c><00:17:24.079><c> how</c><00:17:24.319><c> you</c><00:17:24.480><c> can</c><00:17:24.640><c> scrape</c> how this agent works, how you can scrape how this agent works, how you can scrape websites<00:17:25.439><c> in</c><00:17:25.679><c> different</c><00:17:25.839><c> ways,</c><00:17:26.000><c> and</c><00:17:26.240><c> you</c><00:17:26.319><c> can</c> websites in different ways, and you can websites in different ways, and you can just<00:17:26.640><c> use</c><00:17:26.880><c> this</c><00:17:27.120><c> repository</c><00:17:28.000><c> as</c><00:17:28.319><c> your</c> just use this repository as your just use this repository as your template<00:17:28.880><c> to</c><00:17:29.120><c> get</c><00:17:29.280><c> you</c><00:17:29.520><c> started.</c><00:17:29.919><c> You</c><00:17:30.160><c> can</c> template to get you started. You can template to get you started. You can take<00:17:30.480><c> the</c><00:17:30.720><c> functionality</c><00:17:31.520><c> from</c><00:17:31.840><c> any</c><00:17:32.000><c> of</c><00:17:32.080><c> these</c> take the functionality from any of these take the functionality from any of these examples<00:17:32.880><c> if</c><00:17:33.039><c> you</c><00:17:33.120><c> want</c><00:17:33.280><c> to</c><00:17:33.360><c> pull</c><00:17:33.600><c> a</c><00:17:33.840><c> specific</c> examples if you want to pull a specific examples if you want to pull a specific method<00:17:34.799><c> or</c><00:17:35.039><c> you</c><00:17:35.200><c> can</c><00:17:35.360><c> take</c><00:17:35.440><c> a</c><00:17:35.600><c> look</c><00:17:35.760><c> at</c><00:17:36.000><c> all</c><00:17:36.320><c> the</c> method or you can take a look at all the method or you can take a look at all the details<00:17:36.799><c> how</c><00:17:37.039><c> I</c><00:17:37.200><c> implemented</c><00:17:37.600><c> that</c><00:17:37.760><c> agent</c> details how I implemented that agent details how I implemented that agent that<00:17:38.240><c> I</c><00:17:38.480><c> just</c><00:17:38.799><c> demonstrated</c><00:17:39.360><c> for</c><00:17:39.600><c> you.</c><00:17:40.240><c> And</c><00:17:40.480><c> so</c> that I just demonstrated for you. And so that I just demonstrated for you. And so with<00:17:40.880><c> that,</c><00:17:41.200><c> the</c><00:17:41.360><c> last</c><00:17:41.600><c> thing</c><00:17:41.760><c> that</c><00:17:42.080><c> I</c><00:17:42.240><c> want</c><00:17:42.400><c> to</c> with that, the last thing that I want to with that, the last thing that I want to show<00:17:42.799><c> you</c><00:17:43.360><c> is</c><00:17:43.600><c> just</c><00:17:43.840><c> a</c><00:17:44.160><c> quick</c><00:17:44.480><c> dive</c><00:17:44.799><c> into</c><00:17:45.120><c> each</c> show you is just a quick dive into each show you is just a quick dive into each of<00:17:45.440><c> these</c><00:17:45.760><c> different</c><00:17:46.000><c> strategies,</c><00:17:46.799><c> how</c><00:17:47.039><c> that</c> of these different strategies, how that of these different strategies, how that works<00:17:47.520><c> within</c><00:17:47.919><c> crawl</c><00:17:48.160><c> for</c><00:17:48.400><c> AAI.</c><00:17:48.640><c> I</c><00:17:48.799><c> just</c><00:17:48.880><c> want</c> works within crawl for AAI. I just want works within crawl for AAI. I just want to<00:17:49.039><c> give</c><00:17:49.120><c> you</c><00:17:49.200><c> a</c><00:17:49.360><c> more</c><00:17:49.520><c> higher</c><00:17:49.760><c> level</c><00:17:50.080><c> idea</c><00:17:50.720><c> of</c> to give you a more higher level idea of to give you a more higher level idea of how<00:17:51.280><c> these</c><00:17:51.600><c> strategies</c><00:17:52.160><c> are</c><00:17:52.400><c> implemented.</c> how these strategies are implemented. how these strategies are implemented. Starting<00:17:53.520><c> with</c><00:17:53.840><c> the</c><00:17:54.080><c> first</c><00:17:54.320><c> one</c><00:17:54.640><c> for</c><00:17:54.960><c> crawling</c> Starting with the first one for crawling Starting with the first one for crawling our<00:17:55.600><c> site</c><00:17:55.919><c> maps.</c><00:17:56.320><c> And</c><00:17:56.559><c> obviously</c><00:17:57.039><c> since</c><00:17:57.280><c> this</c> our site maps. And obviously since this our site maps. And obviously since this is<00:17:57.760><c> just</c><00:17:58.000><c> more</c><00:17:58.160><c> of</c><00:17:58.240><c> a</c><00:17:58.480><c> demo</c><00:17:58.799><c> script</c><00:17:59.200><c> showing</c> is just more of a demo script showing is just more of a demo script showing you<00:17:59.600><c> at</c><00:17:59.760><c> a</c><00:17:59.919><c> high</c><00:18:00.080><c> level</c><00:18:00.320><c> how</c><00:18:00.480><c> to</c><00:18:00.640><c> use</c><00:18:00.799><c> the</c> you at a high level how to use the you at a high level how to use the sitemap<00:18:01.520><c> crawler,</c><00:18:02.160><c> I</c><00:18:02.400><c> just</c><00:18:02.559><c> have</c><00:18:02.720><c> the</c><00:18:02.880><c> URL</c> sitemap crawler, I just have the URL sitemap crawler, I just have the URL hardcoded<00:18:04.080><c> here.</c><00:18:04.320><c> It</c><00:18:04.480><c> was</c><00:18:04.640><c> dynamic</c><00:18:05.039><c> with</c><00:18:05.280><c> that</c> hardcoded here. It was dynamic with that hardcoded here. It was dynamic with that insert<00:18:05.840><c> doc</c><00:18:06.160><c> script</c><00:18:06.400><c> that</c><00:18:06.559><c> I</c><00:18:06.640><c> showed</c><00:18:06.799><c> you</c><00:18:06.960><c> in</c> insert doc script that I showed you in insert doc script that I showed you in the<00:18:07.280><c> demo.</c><00:18:07.600><c> Here</c><00:18:07.919><c> it's</c><00:18:08.160><c> just</c><00:18:08.320><c> hard-coded,</c><00:18:08.880><c> but</c> the demo. Here it's just hard-coded, but the demo. Here it's just hard-coded, but we<00:18:09.280><c> get</c><00:18:09.360><c> the</c><00:18:09.600><c> contents</c><00:18:09.919><c> of</c><00:18:10.000><c> the</c><00:18:10.160><c> sitemap</c><00:18:10.720><c> and</c> we get the contents of the sitemap and we get the contents of the sitemap and then<00:18:11.039><c> we</c><00:18:11.200><c> extract</c><00:18:11.520><c> all</c><00:18:11.679><c> the</c><00:18:11.840><c> URLs</c><00:18:12.240><c> from</c><00:18:12.400><c> it</c> then we extract all the URLs from it then we extract all the URLs from it that<00:18:12.720><c> we</c><00:18:12.880><c> want</c><00:18:13.039><c> to</c><00:18:13.280><c> crawl</c><00:18:13.600><c> and</c><00:18:13.760><c> then</c><00:18:13.919><c> we</c><00:18:14.240><c> call</c> that we want to crawl and then we call that we want to crawl and then we call this<00:18:14.640><c> crawl</c><00:18:14.960><c> parallel</c><00:18:15.360><c> function.</c><00:18:15.919><c> We</c><00:18:16.160><c> can</c> this crawl parallel function. We can this crawl parallel function. We can also<00:18:16.480><c> determine</c><00:18:17.039><c> how</c><00:18:17.280><c> many</c><00:18:17.440><c> URLs</c><00:18:17.919><c> it's</c><00:18:18.160><c> going</c> also determine how many URLs it's going also determine how many URLs it's going to<00:18:18.559><c> process</c><00:18:18.960><c> in</c><00:18:19.200><c> each</c><00:18:19.440><c> batch</c><00:18:19.760><c> when</c><00:18:20.000><c> it's</c><00:18:20.160><c> doing</c> to process in each batch when it's doing to process in each batch when it's doing things<00:18:20.640><c> in</c><00:18:20.960><c> parallel.</c><00:18:21.919><c> And</c><00:18:22.080><c> so</c><00:18:22.320><c> within</c><00:18:22.960><c> this</c> things in parallel. And so within this things in parallel. And so within this crawl<00:18:23.760><c> parallel,</c><00:18:24.480><c> we</c><00:18:24.720><c> set</c><00:18:24.880><c> up</c><00:18:25.039><c> a</c><00:18:25.280><c> lot</c><00:18:25.360><c> of</c> crawl parallel, we set up a lot of crawl parallel, we set up a lot of things<00:18:25.840><c> to</c><00:18:26.720><c> manage</c><00:18:27.039><c> the</c><00:18:27.280><c> memory</c><00:18:27.679><c> for</c><00:18:28.160><c> our</c> things to manage the memory for our things to manage the memory for our crawl<00:18:28.720><c> for</c><00:18:28.960><c> AAI</c><00:18:29.280><c> instance</c><00:18:29.600><c> that</c><00:18:29.760><c> I</c><00:18:29.919><c> don't</c><00:18:30.000><c> want</c> crawl for AAI instance that I don't want crawl for AAI instance that I don't want to<00:18:30.240><c> get</c><00:18:30.320><c> into</c><00:18:30.720><c> right</c><00:18:30.960><c> now.</c><00:18:31.360><c> But</c><00:18:31.440><c> then</c><00:18:31.679><c> we</c> to get into right now. But then we to get into right now. But then we create<00:18:32.000><c> the</c><00:18:32.320><c> async</c><00:18:32.799><c> web</c><00:18:33.120><c> crawler.</c><00:18:33.840><c> And</c><00:18:34.080><c> so</c> create the async web crawler. And so create the async web crawler. And so that's<00:18:34.480><c> exactly</c><00:18:34.799><c> what</c><00:18:34.960><c> we</c><00:18:35.120><c> created</c><00:18:35.440><c> in</c><00:18:35.600><c> that</c> that's exactly what we created in that that's exactly what we created in that very<00:18:36.080><c> first</c><00:18:36.480><c> example</c><00:18:37.360><c> like</c><00:18:37.600><c> we</c><00:18:37.760><c> saw</c><00:18:38.080><c> right</c> very first example like we saw right very first example like we saw right here.<00:18:39.120><c> And</c><00:18:39.360><c> now</c><00:18:39.520><c> we're</c><00:18:39.760><c> just</c><00:18:40.000><c> going</c><00:18:40.080><c> to</c><00:18:40.320><c> use</c> here. And now we're just going to use here. And now we're just going to use the<00:18:40.799><c> A</c><00:18:41.039><c> run</c><00:18:41.360><c> mini</c><00:18:41.679><c> function.</c><00:18:42.000><c> So</c><00:18:42.160><c> instead</c><00:18:42.480><c> of</c> the A run mini function. So instead of the A run mini function. So instead of just<00:18:42.720><c> the</c><00:18:42.960><c> basic</c><00:18:43.280><c> A</c><00:18:43.600><c> run</c><00:18:43.840><c> function,</c><00:18:44.240><c> we</c><00:18:44.400><c> want</c> just the basic A run function, we want just the basic A run function, we want to<00:18:45.120><c> crawl</c><00:18:45.440><c> many</c><00:18:45.760><c> URLs</c><00:18:46.240><c> in</c><00:18:46.559><c> parallel</c><00:18:46.880><c> with</c> to crawl many URLs in parallel with to crawl many URLs in parallel with these<00:18:47.440><c> batches</c><00:18:47.919><c> that</c><00:18:48.160><c> we</c><00:18:48.320><c> set</c><00:18:48.559><c> up.</c><00:18:48.799><c> And</c><00:18:48.960><c> so</c> these batches that we set up. And so these batches that we set up. And so it's<00:18:49.679><c> going</c><00:18:49.840><c> to</c><00:18:50.480><c> get</c><00:18:50.640><c> the</c><00:18:50.880><c> markdown</c><00:18:51.360><c> from</c><00:18:51.520><c> all</c> it's going to get the markdown from all it's going to get the markdown from all these<00:18:51.840><c> pages</c><00:18:52.160><c> at</c><00:18:52.320><c> the</c><00:18:52.480><c> same</c><00:18:52.640><c> time.</c><00:18:53.280><c> And</c><00:18:53.440><c> then</c> these pages at the same time. And then these pages at the same time. And then we<00:18:53.919><c> can</c><00:18:54.160><c> chunk</c><00:18:54.480><c> that</c><00:18:54.640><c> and</c><00:18:54.799><c> insert</c><00:18:55.120><c> that</c><00:18:55.280><c> into</c> we can chunk that and insert that into we can chunk that and insert that into our<00:18:55.679><c> vector</c><00:18:56.080><c> database.</c><00:18:56.559><c> And</c><00:18:56.720><c> so</c><00:18:56.880><c> this</c><00:18:57.120><c> script</c> our vector database. And so this script our vector database. And so this script stops<00:18:58.000><c> because</c><00:18:58.240><c> it's</c><00:18:58.480><c> just</c><00:18:58.640><c> an</c><00:18:58.880><c> example.</c><00:18:59.440><c> it</c> stops because it's just an example. it stops because it's just an example. it stops<00:19:00.080><c> at</c><00:19:00.240><c> the</c><00:19:00.400><c> point</c><00:19:00.480><c> that</c><00:19:00.640><c> we</c><00:19:00.880><c> get</c><00:19:01.039><c> the</c> stops at the point that we get the stops at the point that we get the markdown<00:19:02.000><c> for</c><00:19:02.400><c> that</c><00:19:02.720><c> page</c><00:19:03.120><c> just</c><00:19:03.360><c> here</c><00:19:03.520><c> in</c><00:19:03.760><c> the</c> markdown for that page just here in the markdown for that page just here in the results.<00:19:04.960><c> But</c><00:19:05.120><c> you</c><00:19:05.360><c> can</c><00:19:05.440><c> take</c><00:19:05.600><c> this</c> results. But you can take this results. But you can take this functionality,<00:19:06.720><c> bring</c><00:19:06.880><c> it</c><00:19:07.039><c> into</c><00:19:07.280><c> your</c><00:19:07.520><c> own</c> functionality, bring it into your own functionality, bring it into your own agents<00:19:08.320><c> just</c><00:19:08.559><c> like</c><00:19:08.720><c> I</c><00:19:08.960><c> did</c><00:19:09.200><c> for</c><00:19:09.600><c> mine</c><00:19:09.919><c> right</c> agents just like I did for mine right agents just like I did for mine right here.<00:19:10.559><c> Like</c><00:19:10.720><c> I</c><00:19:10.960><c> took</c><00:19:11.200><c> this</c><00:19:11.440><c> functionality</c><00:19:12.080><c> in</c> here. Like I took this functionality in here. Like I took this functionality in script<00:19:12.880><c> number</c><00:19:13.039><c> three</c><00:19:13.280><c> in</c><00:19:13.520><c> that</c><00:19:13.760><c> example</c><00:19:14.320><c> and</c> script number three in that example and script number three in that example and I<00:19:14.720><c> baked</c><00:19:15.039><c> that</c><00:19:15.280><c> into</c><00:19:15.520><c> my</c><00:19:15.760><c> insert</c><00:19:16.160><c> docs.</c><00:19:16.480><c> So</c><00:19:16.640><c> if</c> I baked that into my insert docs. So if I baked that into my insert docs. So if it<00:19:16.960><c> detected</c><00:19:17.280><c> that</c><00:19:17.520><c> it</c><00:19:17.760><c> needed</c><00:19:18.000><c> to</c><00:19:18.640><c> scrape</c><00:19:19.039><c> a</c> it detected that it needed to scrape a it detected that it needed to scrape a sitemap<00:19:19.919><c> file</c><00:19:20.559><c> like</c><00:19:20.799><c> using</c><00:19:21.039><c> this</c><00:19:21.280><c> function</c> sitemap file like using this function sitemap file like using this function right<00:19:21.760><c> here,</c><00:19:22.400><c> then</c><00:19:22.720><c> we</c><00:19:22.960><c> would</c><00:19:23.120><c> call</c><00:19:23.360><c> the</c> right here, then we would call the right here, then we would call the functionality<00:19:24.559><c> that</c><00:19:24.799><c> is</c><00:19:25.120><c> very</c><00:19:25.520><c> similar</c><00:19:25.919><c> to</c> functionality that is very similar to functionality that is very similar to what<00:19:26.320><c> we</c><00:19:26.480><c> saw</c><00:19:26.799><c> in</c><00:19:27.120><c> the</c><00:19:27.360><c> example</c><00:19:27.840><c> script</c><00:19:28.160><c> to</c> what we saw in the example script to what we saw in the example script to crawl<00:19:28.720><c> in</c><00:19:28.960><c> batches</c><00:19:29.520><c> where</c><00:19:29.760><c> we're</c><00:19:30.000><c> going</c><00:19:30.160><c> to</c> crawl in batches where we're going to crawl in batches where we're going to use<00:19:30.799><c> the</c><00:19:30.960><c> A-on</c><00:19:31.440><c> mini</c><00:19:31.679><c> just</c><00:19:31.840><c> on</c><00:19:32.000><c> all</c><00:19:32.160><c> these</c><00:19:32.400><c> URLs</c> use the A-on mini just on all these URLs use the A-on mini just on all these URLs getting<00:19:33.360><c> them</c><00:19:33.600><c> all</c><00:19:33.760><c> from</c><00:19:34.080><c> our</c><00:19:34.400><c> site</c><00:19:34.799><c> map.</c><00:19:35.120><c> So</c> getting them all from our site map. So getting them all from our site map. So that<00:19:35.840><c> is</c><00:19:36.080><c> number</c><00:19:36.320><c> three.</c><00:19:36.799><c> And</c><00:19:36.960><c> then</c><00:19:37.120><c> for</c> that is number three. And then for that is number three. And then for number<00:19:37.679><c> four,</c><00:19:38.080><c> things</c><00:19:38.320><c> look</c><00:19:38.559><c> a</c><00:19:38.880><c> lot</c><00:19:39.039><c> different</c> number four, things look a lot different number four, things look a lot different because<00:19:39.520><c> we</c><00:19:39.760><c> just</c><00:19:39.919><c> have</c><00:19:40.080><c> to</c><00:19:40.240><c> scrape</c><00:19:40.640><c> a</c><00:19:40.880><c> single</c> because we just have to scrape a single because we just have to scrape a single page.<00:19:41.760><c> And</c><00:19:42.000><c> so</c><00:19:42.480><c> really</c><00:19:42.720><c> we</c><00:19:42.960><c> take</c><00:19:43.200><c> the</c><00:19:43.360><c> URL</c><00:19:44.240><c> and</c> page. And so really we take the URL and page. And so really we take the URL and then<00:19:44.799><c> with</c><00:19:45.120><c> that</c><00:19:45.360><c> URL</c><00:19:45.919><c> we're</c><00:19:46.160><c> going</c><00:19:46.320><c> to</c><00:19:46.640><c> call</c> then with that URL we're going to call then with that URL we're going to call the<00:19:47.120><c> AUN</c><00:19:47.760><c> function.</c><00:19:48.240><c> So</c><00:19:48.480><c> just</c><00:19:48.640><c> like</c><00:19:48.799><c> we</c><00:19:49.039><c> called</c> the AUN function. So just like we called the AUN function. So just like we called a<00:19:49.520><c> run</c><00:19:49.679><c> in</c><00:19:49.840><c> our</c><00:19:50.000><c> very</c><00:19:50.160><c> simple</c><00:19:50.480><c> example</c><00:19:50.799><c> to</c> a run in our very simple example to a run in our very simple example to crawl<00:19:51.200><c> one</c><00:19:51.440><c> page,</c><00:19:52.000><c> we're</c><00:19:52.240><c> doing</c><00:19:52.400><c> the</c><00:19:52.640><c> same</c> crawl one page, we're doing the same crawl one page, we're doing the same thing<00:19:53.039><c> here.</c><00:19:53.919><c> But</c><00:19:54.080><c> because</c><00:19:54.400><c> that's</c><00:19:54.720><c> so</c> thing here. But because that's so thing here. But because that's so simple,<00:19:55.200><c> I</c><00:19:55.360><c> just</c><00:19:55.520><c> took</c><00:19:55.679><c> this</c><00:19:55.840><c> as</c><00:19:56.000><c> an</c> simple, I just took this as an simple, I just took this as an opportunity<00:19:56.640><c> to</c><00:19:56.880><c> also</c><00:19:57.120><c> show</c><00:19:57.360><c> you</c><00:19:57.679><c> a</c><00:19:57.919><c> little</c> opportunity to also show you a little opportunity to also show you a little bit<00:19:58.240><c> more</c><00:19:58.480><c> complex</c><00:19:58.960><c> logic</c><00:19:59.600><c> for</c><00:19:59.919><c> some</c><00:20:00.160><c> chunking</c> bit more complex logic for some chunking bit more complex logic for some chunking strategies<00:20:00.960><c> that</c><00:20:01.120><c> I've</c><00:20:01.280><c> been</c><00:20:01.440><c> playing</c><00:20:01.600><c> around</c> strategies that I've been playing around strategies that I've been playing around with.<00:20:02.080><c> And</c><00:20:02.320><c> so</c><00:20:02.799><c> I</c><00:20:03.120><c> could</c><00:20:03.360><c> do</c><00:20:03.520><c> an</c><00:20:03.840><c> entire</c><00:20:04.480><c> video</c> with. And so I could do an entire video with. And so I could do an entire video on<00:20:05.039><c> chunking</c><00:20:05.520><c> strategies.</c><00:20:05.919><c> And</c><00:20:06.080><c> I</c><00:20:06.240><c> might</c> on chunking strategies. And I might on chunking strategies. And I might actually<00:20:06.640><c> do</c><00:20:06.799><c> that</c><00:20:07.039><c> soon.</c><00:20:07.760><c> But</c><00:20:08.000><c> what</c><00:20:08.160><c> I</c><00:20:08.320><c> do</c> actually do that soon. But what I do actually do that soon. But what I do with<00:20:08.559><c> a</c><00:20:08.799><c> markdown</c><00:20:09.440><c> is</c><00:20:09.679><c> I</c><00:20:09.919><c> split</c><00:20:10.240><c> based</c><00:20:10.480><c> on</c> with a markdown is I split based on with a markdown is I split based on headers.<00:20:11.120><c> And</c><00:20:11.360><c> so</c><00:20:11.679><c> I</c><00:20:11.919><c> chunk</c><00:20:12.240><c> all</c><00:20:12.480><c> of</c><00:20:12.640><c> the</c> headers. And so I chunk all of the headers. And so I chunk all of the documents<00:20:13.919><c> based</c><00:20:14.240><c> on</c><00:20:14.640><c> the</c><00:20:15.120><c> primary</c><00:20:15.600><c> headers</c> documents based on the primary headers documents based on the primary headers like<00:20:16.160><c> just</c><00:20:16.320><c> with</c><00:20:16.480><c> that</c><00:20:16.720><c> single</c><00:20:17.039><c> pound.</c><00:20:17.440><c> And</c> like just with that single pound. And like just with that single pound. And then<00:20:17.919><c> I</c><00:20:18.160><c> also</c><00:20:18.480><c> chunk</c><00:20:18.799><c> based</c><00:20:19.120><c> on</c><00:20:19.600><c> the</c> then I also chunk based on the then I also chunk based on the subsections<00:20:20.640><c> that</c><00:20:20.799><c> we</c><00:20:20.960><c> have</c><00:20:21.039><c> as</c><00:20:21.200><c> well.</c><00:20:21.440><c> So</c><00:20:21.520><c> we</c> subsections that we have as well. So we subsections that we have as well. So we have<00:20:21.760><c> a</c><00:20:21.919><c> bunch</c><00:20:22.080><c> of</c><00:20:22.160><c> these</c><00:20:22.400><c> chunks</c><00:20:22.720><c> now</c><00:20:23.120><c> that</c> have a bunch of these chunks now that have a bunch of these chunks now that are<00:20:23.760><c> the</c><00:20:24.080><c> core</c><00:20:24.559><c> sections</c><00:20:25.200><c> split</c><00:20:25.520><c> up</c><00:20:25.760><c> for</c><00:20:26.000><c> the</c> are the core sections split up for the are the core sections split up for the documentation<00:20:26.720><c> that</c><00:20:26.960><c> we</c><00:20:27.120><c> crawled</c><00:20:27.679><c> within</c> documentation that we crawled within documentation that we crawled within this<00:20:28.400><c> single</c><00:20:28.919><c> lm.ext</c><00:20:29.919><c> page.</c><00:20:30.400><c> And</c><00:20:30.480><c> then</c><00:20:30.640><c> I</c><00:20:30.799><c> also</c> this single lm.ext page. And then I also this single lm.ext page. And then I also played<00:20:31.280><c> around</c><00:20:31.440><c> with</c><00:20:31.600><c> some</c><00:20:31.760><c> more</c><00:20:31.919><c> chunking</c> played around with some more chunking played around with some more chunking strategies<00:20:33.200><c> within</c><00:20:33.600><c> insert</c><00:20:34.080><c> docs.</c><00:20:34.480><c> If</c><00:20:34.559><c> you</c> strategies within insert docs. If you strategies within insert docs. If you want<00:20:34.799><c> to</c><00:20:34.960><c> take</c><00:20:35.039><c> a</c><00:20:35.200><c> look</c><00:20:35.360><c> at</c><00:20:35.520><c> my</c><00:20:35.919><c> chunking</c> want to take a look at my chunking want to take a look at my chunking function<00:20:36.799><c> here</c><00:20:37.120><c> as</c><00:20:37.360><c> well,</c><00:20:37.840><c> I</c><00:20:38.080><c> call</c><00:20:38.159><c> it</c><00:20:38.400><c> smart</c> function here as well, I call it smart function here as well, I call it smart chunk<00:20:39.039><c> markdown.</c><00:20:39.760><c> You</c><00:20:40.000><c> can</c><00:20:40.080><c> definitely</c><00:20:40.400><c> take</c> chunk markdown. You can definitely take chunk markdown. You can definitely take a<00:20:40.640><c> look</c><00:20:40.720><c> at</c><00:20:40.799><c> this.</c><00:20:41.039><c> I</c><00:20:41.280><c> don't</c><00:20:41.360><c> have</c><00:20:41.440><c> the</c><00:20:41.679><c> time</c><00:20:41.760><c> to</c> a look at this. I don't have the time to a look at this. I don't have the time to dive<00:20:42.240><c> into</c><00:20:42.400><c> this</c><00:20:42.640><c> right</c><00:20:42.880><c> now.</c><00:20:43.440><c> Um,</c><00:20:43.679><c> but</c><00:20:44.000><c> there</c> dive into this right now. Um, but there dive into this right now. Um, but there are<00:20:44.400><c> a</c><00:20:44.720><c> lot</c><00:20:44.799><c> of</c><00:20:45.200><c> strategies</c><00:20:45.760><c> for</c><00:20:46.159><c> working</c><00:20:46.400><c> with</c> are a lot of strategies for working with are a lot of strategies for working with markdown<00:20:47.280><c> specifically</c><00:20:47.840><c> because</c><00:20:48.320><c> the</c> markdown specifically because the markdown specifically because the documents<00:20:49.440><c> are</c><00:20:49.600><c> formatted</c><00:20:50.159><c> so</c><00:20:50.400><c> nicely</c><00:20:50.640><c> with</c> documents are formatted so nicely with documents are formatted so nicely with these<00:20:51.039><c> headings</c><00:20:51.360><c> and</c><00:20:51.520><c> subheadings.</c><00:20:52.400><c> You</c><00:20:52.559><c> can</c> these headings and subheadings. You can these headings and subheadings. You can work<00:20:52.880><c> with</c><00:20:53.120><c> that</c><00:20:53.360><c> to</c><00:20:53.760><c> really</c><00:20:54.080><c> make</c><00:20:54.240><c> sure</c><00:20:54.400><c> that</c> work with that to really make sure that work with that to really make sure that you<00:20:54.880><c> split</c><00:20:55.200><c> documents</c><00:20:55.760><c> well,</c><00:20:56.000><c> but</c><00:20:56.240><c> also</c><00:20:56.480><c> do</c><00:20:56.640><c> it</c> you split documents well, but also do it you split documents well, but also do it in<00:20:56.880><c> a</c><00:20:56.960><c> way</c><00:20:57.120><c> where</c><00:20:57.280><c> the</c><00:20:57.520><c> distinct</c><00:20:58.000><c> sections</c><00:20:58.559><c> are</c> in a way where the distinct sections are in a way where the distinct sections are all<00:20:59.120><c> kept</c><00:20:59.440><c> together</c><00:20:59.760><c> in</c><00:21:00.000><c> those</c><00:21:00.159><c> chunks.</c><00:21:00.559><c> You</c> all kept together in those chunks. You all kept together in those chunks. You don't<00:21:00.880><c> lose</c><00:21:01.120><c> that</c><00:21:01.600><c> contextual</c><00:21:02.320><c> information.</c> don't lose that contextual information. don't lose that contextual information. So,<00:21:03.600><c> that</c><00:21:03.919><c> is</c><00:21:04.080><c> number</c><00:21:04.400><c> four.</c><00:21:04.799><c> And</c><00:21:05.039><c> then</c><00:21:05.200><c> our</c> So, that is number four. And then our So, that is number four. And then our last<00:21:05.600><c> strategy</c><00:21:06.080><c> is</c><00:21:06.480><c> crawling</c><00:21:07.120><c> websites</c> last strategy is crawling websites last strategy is crawling websites recursively<00:21:08.640><c> because</c><00:21:09.039><c> now</c><00:21:09.520><c> we</c><00:21:09.760><c> don't</c><00:21:09.919><c> have</c><00:21:10.000><c> a</c> recursively because now we don't have a recursively because now we don't have a sitemap<00:21:10.720><c> to</c><00:21:10.880><c> guide</c><00:21:11.039><c> us.</c><00:21:11.360><c> We</c><00:21:11.520><c> don't</c><00:21:11.600><c> have</c><00:21:11.679><c> an</c> sitemap to guide us. We don't have an sitemap to guide us. We don't have an LMS.ext<00:21:12.799><c> to</c><00:21:13.039><c> bring</c><00:21:13.200><c> everything</c><00:21:13.440><c> together</c><00:21:13.760><c> for</c> LMS.ext to bring everything together for LMS.ext to bring everything together for us.<00:21:14.240><c> We</c><00:21:14.400><c> just</c><00:21:14.559><c> have</c><00:21:14.640><c> a</c><00:21:14.880><c> single</c><00:21:15.200><c> URL</c><00:21:16.000><c> and</c><00:21:16.240><c> we</c> us. We just have a single URL and we us. We just have a single URL and we want<00:21:16.640><c> to</c><00:21:16.880><c> dynamically</c><00:21:17.600><c> determine</c><00:21:18.400><c> all</c><00:21:18.640><c> of</c><00:21:18.799><c> the</c> want to dynamically determine all of the want to dynamically determine all of the pages<00:21:19.440><c> that</c><00:21:19.760><c> we</c><00:21:19.919><c> need</c><00:21:20.080><c> to</c><00:21:20.320><c> scrape</c><00:21:20.799><c> based</c><00:21:21.120><c> on</c> pages that we need to scrape based on pages that we need to scrape based on what<00:21:21.520><c> we</c><00:21:21.679><c> have</c><00:21:21.760><c> in</c><00:21:22.000><c> the</c><00:21:22.159><c> navigation</c><00:21:22.720><c> for</c><00:21:23.200><c> this</c> what we have in the navigation for this what we have in the navigation for this homepage.<00:21:23.919><c> Like</c><00:21:24.080><c> right</c><00:21:24.240><c> here</c><00:21:24.400><c> we</c><00:21:24.559><c> have</c><00:21:24.640><c> the</c> homepage. Like right here we have the homepage. Like right here we have the homepage<00:21:25.200><c> for</c><00:21:25.520><c> the</c><00:21:25.760><c> Pantic</c><00:21:26.320><c> AI</c> homepage for the Pantic AI homepage for the Pantic AI documentation.<00:21:27.679><c> And</c><00:21:27.840><c> so</c><00:21:28.000><c> we</c><00:21:28.159><c> pass</c><00:21:28.400><c> that</c><00:21:28.559><c> into</c> documentation. And so we pass that into documentation. And so we pass that into this<00:21:29.120><c> crawl</c><00:21:29.679><c> recursive</c><00:21:30.159><c> batch</c><00:21:30.400><c> where</c><00:21:30.559><c> we</c><00:21:30.720><c> have</c> this crawl recursive batch where we have this crawl recursive batch where we have a<00:21:30.880><c> list</c><00:21:31.039><c> of</c><00:21:31.200><c> start</c><00:21:31.520><c> URLs.</c><00:21:32.000><c> So</c><00:21:32.159><c> this</c><00:21:32.320><c> can</c><00:21:32.480><c> also</c> a list of start URLs. So this can also a list of start URLs. So this can also handle<00:21:33.280><c> more</c><00:21:33.600><c> than</c><00:21:33.840><c> one</c><00:21:34.240><c> starting</c><00:21:34.880><c> web</c><00:21:35.200><c> page</c> handle more than one starting web page handle more than one starting web page if<00:21:35.840><c> you</c><00:21:36.000><c> want</c><00:21:36.640><c> and</c><00:21:36.880><c> it's</c><00:21:37.120><c> going</c><00:21:37.280><c> to</c><00:21:37.520><c> use</c><00:21:37.919><c> the</c><00:21:38.480><c> A-</c> if you want and it's going to use the A- if you want and it's going to use the A- run<00:21:39.039><c> many</c><00:21:39.280><c> function</c><00:21:39.520><c> to</c><00:21:39.679><c> scrape</c><00:21:40.000><c> all</c><00:21:40.080><c> these</c> run many function to scrape all these run many function to scrape all these URLs<00:21:41.120><c> loop</c><00:21:41.440><c> through</c><00:21:41.679><c> these</c><00:21:42.000><c> results</c><00:21:42.799><c> and</c><00:21:42.960><c> then</c> URLs loop through these results and then URLs loop through these results and then the<00:21:43.360><c> key</c><00:21:43.600><c> part</c><00:21:43.840><c> to</c><00:21:44.080><c> this</c><00:21:44.400><c> entire</c><00:21:44.799><c> workflow</c><00:21:45.440><c> is</c> the key part to this entire workflow is the key part to this entire workflow is that<00:21:45.840><c> we</c><00:21:46.000><c> can</c><00:21:46.159><c> access</c><00:21:46.480><c> what</c><00:21:46.720><c> are</c><00:21:46.880><c> called</c> that we can access what are called that we can access what are called internal<00:21:47.600><c> links</c><00:21:47.919><c> in</c><00:21:48.159><c> crawl</c><00:21:48.480><c> forai.</c><00:21:49.280><c> So</c><00:21:49.440><c> we</c><00:21:49.600><c> get</c> internal links in crawl forai. So we get internal links in crawl forai. So we get the<00:21:49.919><c> result</c><00:21:50.240><c> like</c><00:21:50.400><c> we</c><00:21:50.559><c> get</c><00:21:50.640><c> the</c><00:21:50.799><c> markdown</c><00:21:51.280><c> back</c> the result like we get the markdown back the result like we get the markdown back from<00:21:51.760><c> the</c><00:21:52.000><c> web</c><00:21:52.159><c> page</c><00:21:52.559><c> and</c><00:21:52.799><c> then</c><00:21:52.880><c> we</c><00:21:53.039><c> can</c><00:21:53.120><c> call</c> from the web page and then we can call from the web page and then we can call result.link.get<00:21:55.280><c> and</c><00:21:55.440><c> then</c><00:21:55.679><c> get</c><00:21:55.840><c> the</c> result.link.get and then get the result.link.get and then get the internal<00:21:56.559><c> links.</c><00:21:56.960><c> are</c><00:21:57.120><c> called</c><00:21:57.280><c> internal</c> internal links. are called internal internal links. are called internal because<00:21:58.320><c> we're</c><00:21:58.559><c> looking</c><00:21:58.799><c> for</c><00:21:59.200><c> links</c><00:21:59.520><c> where</c> because we're looking for links where because we're looking for links where the<00:22:00.080><c> domain</c><00:22:00.480><c> is</c><00:22:00.640><c> the</c><00:22:00.880><c> same</c><00:22:00.960><c> as</c><00:22:01.200><c> the</c><00:22:01.440><c> original</c> the domain is the same as the original the domain is the same as the original page<00:22:01.919><c> that</c><00:22:02.159><c> we</c><00:22:02.320><c> scraped.</c><00:22:02.799><c> That's</c><00:22:02.960><c> how</c><00:22:03.120><c> we're</c> page that we scraped. That's how we're page that we scraped. That's how we're able<00:22:03.520><c> to</c><00:22:03.760><c> navigate</c><00:22:04.320><c> between</c><00:22:04.960><c> all</c><00:22:05.120><c> the</c> able to navigate between all the able to navigate between all the different<00:22:05.520><c> pages</c><00:22:05.840><c> that</c><00:22:06.000><c> we</c><00:22:06.240><c> have</c><00:22:06.400><c> in</c><00:22:06.720><c> the</c> different pages that we have in the different pages that we have in the website<00:22:07.360><c> as</c><00:22:07.679><c> a</c><00:22:07.840><c> whole.</c><00:22:08.240><c> And</c><00:22:08.400><c> so</c><00:22:08.559><c> we're</c><00:22:08.720><c> going</c> website as a whole. And so we're going website as a whole. And so we're going to<00:22:08.960><c> get</c><00:22:09.200><c> a</c><00:22:09.360><c> list</c><00:22:09.520><c> of</c><00:22:09.679><c> all</c><00:22:09.919><c> of</c><00:22:10.000><c> these</c><00:22:10.240><c> URLs</c><00:22:11.039><c> that</c> to get a list of all of these URLs that to get a list of all of these URLs that it<00:22:11.520><c> fetches</c><00:22:12.000><c> from</c><00:22:12.159><c> these</c><00:22:12.400><c> internal</c><00:22:12.799><c> links.</c> it fetches from these internal links. it fetches from these internal links. And<00:22:13.600><c> then</c><00:22:13.760><c> we're</c><00:22:13.919><c> just</c><00:22:14.080><c> going</c><00:22:14.159><c> to</c><00:22:14.240><c> loop</c><00:22:14.559><c> back</c> And then we're just going to loop back And then we're just going to loop back up<00:22:14.880><c> to</c><00:22:15.039><c> the</c><00:22:15.280><c> top</c><00:22:15.440><c> here</c><00:22:15.760><c> just</c><00:22:15.919><c> based</c><00:22:16.159><c> on</c><00:22:16.320><c> that</c> up to the top here just based on that up to the top here just based on that depth<00:22:17.039><c> that</c><00:22:17.280><c> I</c><00:22:17.440><c> talked</c><00:22:17.679><c> about</c><00:22:17.919><c> earlier.</c><00:22:18.480><c> And</c> depth that I talked about earlier. And depth that I talked about earlier. And we're<00:22:18.799><c> going</c><00:22:18.880><c> to</c><00:22:19.039><c> call</c><00:22:19.440><c> those</c><00:22:19.840><c> web</c><00:22:20.080><c> pages</c><00:22:20.480><c> as</c> we're going to call those web pages as we're going to call those web pages as well.<00:22:21.039><c> So</c><00:22:21.200><c> we</c><00:22:21.440><c> go</c><00:22:21.760><c> deeper</c><00:22:22.080><c> and</c><00:22:22.320><c> deeper</c><00:22:22.880><c> just</c> well. So we go deeper and deeper just well. So we go deeper and deeper just scraping<00:22:23.520><c> all</c><00:22:23.679><c> these</c><00:22:23.919><c> links</c><00:22:24.159><c> dynamically</c><00:22:24.720><c> as</c> scraping all these links dynamically as scraping all these links dynamically as we<00:22:25.120><c> go</c><00:22:25.520><c> until</c><00:22:25.919><c> we</c><00:22:26.159><c> hit</c><00:22:26.320><c> that</c><00:22:26.559><c> depth</c><00:22:26.880><c> limit</c><00:22:27.120><c> of</c> we go until we hit that depth limit of we go until we hit that depth limit of three<00:22:27.679><c> or</c><00:22:27.919><c> five</c><00:22:28.159><c> or</c><00:22:28.400><c> whatever</c><00:22:28.720><c> you</c><00:22:28.880><c> have</c><00:22:29.360><c> and</c> three or five or whatever you have and three or five or whatever you have and then<00:22:29.840><c> finally</c><00:22:30.159><c> we</c><00:22:30.400><c> have</c><00:22:30.559><c> a</c><00:22:30.799><c> bunch</c><00:22:30.960><c> of</c><00:22:31.120><c> markdown</c> then finally we have a bunch of markdown then finally we have a bunch of markdown from<00:22:31.760><c> all</c><00:22:31.840><c> these</c><00:22:32.080><c> different</c><00:22:32.240><c> websites</c><00:22:32.640><c> that</c> from all these different websites that from all these different websites that we<00:22:33.120><c> visited</c><00:22:33.679><c> that</c><00:22:33.919><c> we</c><00:22:34.159><c> can</c><00:22:34.400><c> return.</c><00:22:35.200><c> And</c><00:22:35.360><c> so</c> we visited that we can return. And so we visited that we can return. And so this<00:22:36.080><c> basically</c><00:22:36.720><c> builds</c><00:22:37.039><c> up</c><00:22:37.200><c> a</c><00:22:37.440><c> site</c><00:22:37.840><c> map</c> this basically builds up a site map this basically builds up a site map dynamically<00:22:38.880><c> over</c><00:22:39.120><c> time.</c><00:22:39.440><c> So</c><00:22:39.600><c> the</c><00:22:39.760><c> site</c><00:22:40.080><c> map</c> dynamically over time. So the site map dynamically over time. So the site map is<00:22:40.480><c> still</c><00:22:40.960><c> better.</c><00:22:41.360><c> It's</c><00:22:41.520><c> more</c><00:22:41.760><c> reliable</c><00:22:42.240><c> if</c> is still better. It's more reliable if is still better. It's more reliable if you<00:22:42.640><c> have</c><00:22:42.799><c> that</c><00:22:43.039><c> because</c><00:22:43.280><c> then</c><00:22:43.520><c> you're</c> you have that because then you're you have that because then you're guaranteed<00:22:44.159><c> to</c><00:22:44.320><c> have</c><00:22:44.480><c> all</c><00:22:44.640><c> the</c><00:22:44.799><c> different</c> guaranteed to have all the different guaranteed to have all the different links.<00:22:45.440><c> But</c><00:22:45.760><c> this</c><00:22:46.000><c> is</c><00:22:46.159><c> just</c><00:22:46.320><c> a</c><00:22:46.559><c> nice</c><00:22:46.720><c> way</c><00:22:46.880><c> to</c><00:22:47.120><c> be</c> links. But this is just a nice way to be links. But this is just a nice way to be more<00:22:47.520><c> flexible</c><00:22:48.320><c> if</c><00:22:48.559><c> you're</c><00:22:48.799><c> running</c><00:22:49.039><c> into</c><00:22:49.360><c> a</c> more flexible if you're running into a more flexible if you're running into a page<00:22:49.840><c> and</c><00:22:50.000><c> you'll</c><00:22:50.159><c> see</c><00:22:50.320><c> this</c><00:22:50.480><c> a</c><00:22:50.720><c> lot</c><00:22:50.960><c> that</c> page and you'll see this a lot that page and you'll see this a lot that doesn't<00:22:51.600><c> have</c><00:22:51.760><c> a</c><00:22:52.000><c> site</c><00:22:52.400><c> map.</c><00:22:52.720><c> So</c><00:22:53.360><c> those</c><00:22:53.679><c> are</c> doesn't have a site map. So those are doesn't have a site map. So those are the<00:22:54.080><c> three</c><00:22:54.320><c> strategies</c><00:22:54.720><c> and</c><00:22:54.960><c> how</c><00:22:55.120><c> I've</c> the three strategies and how I've the three strategies and how I've implemented<00:22:55.679><c> them.</c><00:22:56.159><c> And</c><00:22:56.320><c> again,</c><00:22:56.640><c> take</c><00:22:56.799><c> these</c> implemented them. And again, take these implemented them. And again, take these and<00:22:57.280><c> implement</c><00:22:57.679><c> them</c><00:22:57.840><c> for</c><00:22:58.159><c> yourself.</c><00:22:58.559><c> I</c><00:22:58.720><c> put</c><00:22:58.880><c> a</c> and implement them for yourself. I put a and implement them for yourself. I put a lot<00:22:59.280><c> of</c><00:22:59.440><c> time</c><00:22:59.679><c> into</c><00:23:00.000><c> learning</c><00:23:00.240><c> crawl</c><00:23:00.559><c> for</c><00:23:00.720><c> AAI</c> lot of time into learning crawl for AAI lot of time into learning crawl for AAI and<00:23:01.120><c> getting</c><00:23:01.280><c> all</c><00:23:01.440><c> this</c><00:23:01.679><c> set</c><00:23:01.760><c> up</c><00:23:01.919><c> for</c><00:23:02.159><c> you.</c><00:23:02.400><c> So</c> and getting all this set up for you. So and getting all this set up for you. So please<00:23:02.880><c> use</c><00:23:03.120><c> this</c><00:23:03.280><c> as</c><00:23:03.520><c> a</c><00:23:03.760><c> resource</c><00:23:04.159><c> and</c><00:23:04.640><c> also</c> please use this as a resource and also please use this as a resource and also take<00:23:05.120><c> a</c><00:23:05.280><c> look</c><00:23:05.360><c> at</c><00:23:05.760><c> more</c><00:23:05.919><c> of</c><00:23:06.080><c> the</c><00:23:06.240><c> code</c><00:23:06.400><c> with</c><00:23:06.480><c> my</c> take a look at more of the code with my take a look at more of the code with my padantic<00:23:07.280><c> AI</c><00:23:07.520><c> agent</c><00:23:07.840><c> and</c><00:23:08.080><c> things</c><00:23:08.240><c> with</c> padantic AI agent and things with padantic AI agent and things with Chromma<00:23:08.799><c> DB.</c><00:23:09.120><c> So</c><00:23:09.200><c> you</c><00:23:09.280><c> can</c><00:23:09.360><c> see</c><00:23:09.520><c> how</c><00:23:09.600><c> I</c><00:23:09.760><c> set</c> Chromma DB. So you can see how I set Chromma DB. So you can see how I set that<00:23:10.159><c> up</c><00:23:10.480><c> if</c><00:23:10.720><c> you</c><00:23:10.880><c> are</c><00:23:11.039><c> curious</c><00:23:11.520><c> as</c><00:23:11.760><c> well.</c><00:23:12.240><c> So,</c> that up if you are curious as well. So, that up if you are curious as well. So, the<00:23:12.720><c> last</c><00:23:12.880><c> thing</c><00:23:12.960><c> that</c><00:23:13.200><c> I</c><00:23:13.360><c> want</c><00:23:13.440><c> to</c><00:23:13.600><c> talk</c><00:23:13.760><c> about</c> the last thing that I want to talk about the last thing that I want to talk about that<00:23:14.240><c> very</c><00:23:14.400><c> much</c><00:23:14.640><c> relates</c><00:23:14.880><c> to</c><00:23:15.039><c> what</c><00:23:15.200><c> we</c><00:23:15.280><c> were</c> that very much relates to what we were that very much relates to what we were just<00:23:15.600><c> covering</c><00:23:15.760><c> with</c><00:23:15.919><c> Crawl</c><00:23:16.240><c> forAI</c><00:23:17.039><c> is</c> just covering with Crawl forAI is just covering with Crawl forAI is Archon.<00:23:18.000><c> This</c><00:23:18.159><c> is</c><00:23:18.240><c> my</c><00:23:18.480><c> open-</c><00:23:18.799><c> source</c><00:23:19.120><c> AI</c><00:23:19.520><c> agent</c> Archon. This is my open- source AI agent Archon. This is my open- source AI agent builder,<00:23:20.400><c> and</c><00:23:20.559><c> I'm</c><00:23:20.799><c> thinking</c><00:23:20.960><c> about</c><00:23:21.200><c> making</c> builder, and I'm thinking about making builder, and I'm thinking about making some<00:23:21.840><c> big</c><00:23:22.240><c> changes</c><00:23:22.640><c> with</c><00:23:22.880><c> it.</c><00:23:23.200><c> So,</c><00:23:23.600><c> please</c> some big changes with it. So, please some big changes with it. So, please hear<00:23:24.000><c> me</c><00:23:24.159><c> out</c><00:23:24.240><c> on</c><00:23:24.400><c> this.</c><00:23:24.640><c> If</c><00:23:24.799><c> you</c><00:23:24.880><c> care</c><00:23:25.039><c> about</c> hear me out on this. If you care about hear me out on this. If you care about Archon,<00:23:25.760><c> you've</c><00:23:26.000><c> got</c><00:23:26.080><c> some</c><00:23:26.320><c> feedback</c><00:23:26.640><c> for</c><00:23:26.880><c> me.</c> Archon, you've got some feedback for me. Archon, you've got some feedback for me. I<00:23:27.360><c> want</c><00:23:27.520><c> to</c><00:23:27.600><c> share</c><00:23:27.840><c> with</c><00:23:28.000><c> you</c><00:23:28.320><c> my</c><00:23:29.039><c> ideas</c><00:23:29.360><c> that</c><00:23:29.600><c> I</c> I want to share with you my ideas that I I want to share with you my ideas that I have<00:23:29.919><c> for</c><00:23:30.400><c> where</c><00:23:30.640><c> I</c><00:23:30.799><c> want</c><00:23:30.880><c> to</c><00:23:31.039><c> take</c><00:23:31.200><c> Archon.</c> have for where I want to take Archon. have for where I want to take Archon. And<00:23:32.000><c> then</c><00:23:32.159><c> I</c><00:23:32.320><c> want</c><00:23:32.480><c> to</c><00:23:32.559><c> know</c><00:23:32.720><c> in</c><00:23:32.960><c> the</c><00:23:33.039><c> comments</c> And then I want to know in the comments And then I want to know in the comments what<00:23:33.679><c> you</c><00:23:33.919><c> think</c><00:23:34.080><c> about</c><00:23:34.320><c> what</c><00:23:34.559><c> I'm</c><00:23:34.720><c> planning</c> what you think about what I'm planning what you think about what I'm planning on<00:23:35.200><c> doing</c><00:23:35.360><c> here.</c><00:23:35.679><c> And</c><00:23:35.840><c> so</c><00:23:36.080><c> at</c><00:23:36.240><c> a</c><00:23:36.400><c> high</c><00:23:36.640><c> level,</c> on doing here. And so at a high level, on doing here. And so at a high level, Archon<00:23:38.000><c> is</c><00:23:38.240><c> able</c><00:23:38.480><c> to</c><00:23:39.120><c> both</c><00:23:39.679><c> ingest</c> Archon is able to both ingest Archon is able to both ingest documentation<00:23:41.120><c> for</c><00:23:41.360><c> things</c><00:23:41.520><c> like</c><00:23:41.760><c> Pyantic</c><00:23:42.400><c> AI</c> documentation for things like Pyantic AI documentation for things like Pyantic AI in<00:23:42.799><c> its</c><00:23:42.960><c> knowledge</c><00:23:43.280><c> base</c><00:23:43.679><c> and</c><00:23:43.919><c> then</c><00:23:44.080><c> also</c><00:23:44.559><c> code</c> in its knowledge base and then also code in its knowledge base and then also code the<00:23:45.039><c> agent</c><00:23:45.360><c> itself.</c><00:23:45.840><c> So</c><00:23:46.000><c> it's</c><00:23:46.360><c> multi-purpose</c> the agent itself. So it's multi-purpose the agent itself. So it's multi-purpose in<00:23:47.679><c> isolation.</c><00:23:48.320><c> It</c><00:23:48.480><c> itself</c><00:23:48.880><c> is</c><00:23:49.280><c> enough</c><00:23:49.679><c> to</c> in isolation. It itself is enough to in isolation. It itself is enough to create<00:23:50.320><c> a</c><00:23:50.559><c> full</c><00:23:50.799><c> AI</c><00:23:51.200><c> agent</c><00:23:51.600><c> for</c><00:23:51.840><c> you.</c><00:23:52.720><c> But</c><00:23:52.880><c> what</c> create a full AI agent for you. But what create a full AI agent for you. But what I'm<00:23:53.280><c> thinking</c><00:23:53.520><c> about</c><00:23:53.760><c> doing</c><00:23:54.000><c> is</c><00:23:54.320><c> turning</c><00:23:54.559><c> it</c> I'm thinking about doing is turning it I'm thinking about doing is turning it into<00:23:55.039><c> a</c><00:23:55.360><c> better</c><00:23:55.679><c> version</c><00:23:55.919><c> of</c><00:23:56.080><c> something</c><00:23:56.400><c> like</c> into a better version of something like into a better version of something like Context<00:23:57.280><c> 7.</c><00:23:57.760><c> So,</c><00:23:58.080><c> context</c><00:23:58.559><c> 7</c><00:23:58.960><c> is</c><00:23:59.120><c> an</c><00:23:59.360><c> MCP</c> Context 7. So, context 7 is an MCP Context 7. So, context 7 is an MCP server<00:24:00.159><c> that</c><00:24:00.400><c> you</c><00:24:00.559><c> add</c><00:24:00.720><c> into</c><00:24:00.960><c> your</c><00:24:01.120><c> AI</c><00:24:01.440><c> coding</c> server that you add into your AI coding server that you add into your AI coding assistance<00:24:02.240><c> to</c><00:24:02.400><c> give</c><00:24:02.559><c> it</c><00:24:02.799><c> more</c><00:24:02.960><c> knowledge</c><00:24:03.360><c> to</c> assistance to give it more knowledge to assistance to give it more knowledge to work<00:24:04.080><c> with</c><00:24:04.320><c> different</c><00:24:04.640><c> tools</c><00:24:04.960><c> and</c><00:24:05.120><c> frameworks</c> work with different tools and frameworks work with different tools and frameworks like<00:24:05.760><c> MongoDB</c><00:24:06.480><c> or</c><00:24:06.640><c> Superbase</c><00:24:07.200><c> or</c><00:24:07.360><c> MCP,</c> like MongoDB or Superbase or MCP, like MongoDB or Superbase or MCP, whatever<00:24:08.640><c> that</c><00:24:08.880><c> might</c><00:24:09.039><c> be.</c><00:24:09.440><c> And</c><00:24:09.600><c> I</c><00:24:09.840><c> like</c><00:24:10.000><c> this</c> whatever that might be. And I like this whatever that might be. And I like this a<00:24:10.480><c> lot.</c><00:24:10.960><c> The</c><00:24:11.600><c> context</c><00:24:12.080><c> 7</c><00:24:12.400><c> MCP</c><00:24:12.880><c> server</c><00:24:13.200><c> itself</c> a lot. The context 7 MCP server itself a lot. The context 7 MCP server itself doesn't<00:24:14.159><c> create</c><00:24:14.400><c> any</c><00:24:14.720><c> code,</c><00:24:15.200><c> but</c><00:24:15.440><c> it</c><00:24:15.679><c> provides</c> doesn't create any code, but it provides doesn't create any code, but it provides knowledge<00:24:16.640><c> for</c><00:24:16.880><c> the</c><00:24:17.039><c> AI</c><00:24:17.440><c> coding</c><00:24:17.760><c> assistants</c> knowledge for the AI coding assistants knowledge for the AI coding assistants to<00:24:18.480><c> do</c><00:24:18.640><c> so.</c><00:24:19.520><c> And</c><00:24:19.760><c> right</c><00:24:19.919><c> now</c><00:24:20.080><c> with</c><00:24:20.240><c> Archon,</c><00:24:20.799><c> I'm</c> to do so. And right now with Archon, I'm to do so. And right now with Archon, I'm kind<00:24:21.120><c> of</c><00:24:21.279><c> tripping</c><00:24:21.600><c> over</c><00:24:21.840><c> the</c><00:24:22.000><c> toes</c><00:24:22.320><c> of</c><00:24:22.400><c> AI</c> kind of tripping over the toes of AI kind of tripping over the toes of AI coding<00:24:23.039><c> assistance</c><00:24:23.440><c> because</c><00:24:23.679><c> you</c><00:24:23.840><c> can</c> coding assistance because you can coding assistance because you can integrate<00:24:24.240><c> it</c><00:24:24.400><c> with</c><00:24:24.640><c> Windsurf</c><00:24:25.279><c> or</c><00:24:25.360><c> Cursor,</c> integrate it with Windsurf or Cursor, integrate it with Windsurf or Cursor, anything<00:24:26.559><c> like</c><00:24:26.799><c> that.</c><00:24:27.360><c> But</c><00:24:27.600><c> when</c><00:24:27.840><c> it</c> anything like that. But when it anything like that. But when it generates<00:24:28.400><c> the</c><00:24:28.640><c> code</c><00:24:28.799><c> for</c><00:24:29.039><c> the</c><00:24:29.200><c> agent,</c><00:24:30.000><c> the</c><00:24:30.159><c> AI</c> generates the code for the agent, the AI generates the code for the agent, the AI IDE<00:24:31.279><c> then</c><00:24:31.520><c> also</c><00:24:31.919><c> has</c><00:24:32.159><c> to</c><00:24:32.320><c> generate</c><00:24:32.640><c> the</c><00:24:32.880><c> code</c> IDE then also has to generate the code IDE then also has to generate the code as<00:24:33.200><c> well</c><00:24:33.360><c> to</c><00:24:33.600><c> put</c><00:24:33.679><c> it</c><00:24:33.840><c> into</c><00:24:34.000><c> the</c><00:24:34.159><c> files.</c><00:24:34.480><c> So</c><00:24:34.559><c> you</c> as well to put it into the files. So you as well to put it into the files. So you have<00:24:34.799><c> a</c><00:24:34.960><c> lot</c><00:24:35.039><c> of</c><00:24:35.120><c> duplicate</c><00:24:35.600><c> work</c><00:24:35.760><c> there</c><00:24:36.320><c> which</c> have a lot of duplicate work there which have a lot of duplicate work there which is<00:24:36.640><c> prone</c><00:24:36.960><c> to</c><00:24:37.279><c> errors.</c><00:24:38.159><c> That's</c><00:24:38.320><c> why</c><00:24:38.480><c> I'm</c> is prone to errors. That's why I'm is prone to errors. That's why I'm thinking<00:24:38.880><c> about</c><00:24:39.039><c> maybe</c><00:24:39.279><c> turning</c><00:24:39.520><c> Archon</c><00:24:40.000><c> more</c> thinking about maybe turning Archon more thinking about maybe turning Archon more into<00:24:40.720><c> a</c><00:24:41.039><c> knowledgebased</c><00:24:41.919><c> specific</c><00:24:42.400><c> project</c> into a knowledgebased specific project into a knowledgebased specific project like<00:24:43.039><c> focusing</c><00:24:43.440><c> a</c><00:24:43.679><c> lot</c><00:24:43.760><c> more</c><00:24:43.919><c> on</c><00:24:44.240><c> rag</c><00:24:44.799><c> to</c><00:24:45.120><c> help</c> like focusing a lot more on rag to help like focusing a lot more on rag to help AI<00:24:45.760><c> coding</c><00:24:46.200><c> assistants</c><00:24:47.200><c> build</c><00:24:47.679><c> agents</c> AI coding assistants build agents AI coding assistants build agents instead<00:24:48.799><c> of</c><00:24:48.960><c> it</c><00:24:49.200><c> itself</c><00:24:49.679><c> creating</c><00:24:50.000><c> the</c><00:24:50.240><c> agent</c> instead of it itself creating the agent instead of it itself creating the agent code.<00:24:51.200><c> Because</c><00:24:51.520><c> another</c><00:24:51.840><c> thing</c><00:24:51.919><c> that</c><00:24:52.080><c> I've</c> code. Because another thing that I've code. Because another thing that I've been<00:24:52.480><c> thinking</c><00:24:52.640><c> about</c><00:24:53.200><c> just</c><00:24:53.440><c> as</c><00:24:53.600><c> I've</c><00:24:53.840><c> been</c> been thinking about just as I've been been thinking about just as I've been diving<00:24:54.400><c> into</c><00:24:55.200><c> processes</c><00:24:55.840><c> for</c><00:24:56.159><c> using</c><00:24:56.480><c> AI</c> diving into processes for using AI diving into processes for using AI coding<00:24:57.200><c> assistance,</c><00:24:57.679><c> like</c><00:24:57.840><c> there's</c><00:24:58.080><c> so</c><00:24:58.320><c> much</c> coding assistance, like there's so much coding assistance, like there's so much functionality<00:24:59.120><c> that's</c><00:24:59.440><c> already</c><00:24:59.760><c> there</c> functionality that's already there functionality that's already there within<00:25:00.320><c> things</c><00:25:00.559><c> like</c><00:25:00.720><c> wind</c><00:25:00.960><c> surf</c><00:25:01.200><c> and</c><00:25:01.360><c> cursor</c> within things like wind surf and cursor within things like wind surf and cursor that<00:25:02.080><c> I</c><00:25:02.240><c> just</c><00:25:02.400><c> want</c><00:25:02.480><c> to</c><00:25:02.640><c> leverage</c><00:25:02.960><c> that</c><00:25:03.200><c> and</c> that I just want to leverage that and that I just want to leverage that and then<00:25:03.600><c> just</c><00:25:03.760><c> have</c><00:25:04.000><c> archon</c><00:25:04.480><c> be</c><00:25:04.640><c> the</c><00:25:04.880><c> knowledge</c> then just have archon be the knowledge then just have archon be the knowledge engine<00:25:05.600><c> behind</c><00:25:05.919><c> the</c><00:25:06.159><c> scenes</c><00:25:06.720><c> instead</c><00:25:07.200><c> of</c> engine behind the scenes instead of engine behind the scenes instead of trying<00:25:07.520><c> to</c><00:25:07.679><c> just</c><00:25:07.919><c> do</c><00:25:08.080><c> it</c><00:25:08.320><c> all.</c><00:25:08.799><c> I</c><00:25:08.960><c> think</c><00:25:09.120><c> we'll</c> trying to just do it all. I think we'll trying to just do it all. I think we'll get<00:25:09.440><c> better</c><00:25:09.679><c> results</c><00:25:10.000><c> overall.</c><00:25:10.480><c> It'll</c><00:25:10.720><c> also</c> get better results overall. It'll also get better results overall. It'll also just<00:25:11.039><c> make</c><00:25:11.279><c> archon</c><00:25:12.240><c> more</c><00:25:12.559><c> expandable</c><00:25:13.200><c> like</c><00:25:13.440><c> we</c> just make archon more expandable like we just make archon more expandable like we can<00:25:13.679><c> more</c><00:25:13.919><c> easily</c><00:25:14.240><c> add</c><00:25:14.799><c> more</c><00:25:15.120><c> documentation</c> can more easily add more documentation can more easily add more documentation into<00:25:15.919><c> it</c><00:25:16.240><c> kind</c><00:25:16.320><c> of</c><00:25:16.400><c> like</c><00:25:16.640><c> we</c><00:25:16.880><c> have</c><00:25:17.039><c> here</c><00:25:17.279><c> with</c> into it kind of like we have here with into it kind of like we have here with context<00:25:18.080><c> 7.</c><00:25:18.559><c> So</c><00:25:18.720><c> it</c><00:25:18.880><c> can</c><00:25:19.039><c> be</c><00:25:19.120><c> useful</c><00:25:19.440><c> for</c><00:25:19.600><c> a</c><00:25:19.840><c> lot</c> context 7. So it can be useful for a lot context 7. So it can be useful for a lot more<00:25:20.240><c> things</c><00:25:20.480><c> than</c><00:25:20.799><c> just</c><00:25:21.039><c> building</c><00:25:21.360><c> agents</c><00:25:21.760><c> as</c> more things than just building agents as more things than just building agents as well.<00:25:22.080><c> Like</c><00:25:22.240><c> right</c><00:25:22.400><c> now</c><00:25:22.559><c> it's</c><00:25:22.799><c> very</c><00:25:23.039><c> limited</c> well. Like right now it's very limited well. Like right now it's very limited to<00:25:23.840><c> only</c><00:25:24.080><c> podantic</c><00:25:24.640><c> AI</c><00:25:24.880><c> and</c><00:25:25.039><c> soon</c><00:25:25.279><c> lang</c><00:25:25.600><c> graph</c> to only podantic AI and soon lang graph to only podantic AI and soon lang graph and<00:25:25.919><c> we're</c><00:25:26.080><c> adding</c><00:25:26.320><c> some</c><00:25:26.480><c> more</c><00:25:26.880><c> frameworks</c> and we're adding some more frameworks and we're adding some more frameworks and<00:25:27.520><c> stuff</c><00:25:27.679><c> into</c><00:25:27.840><c> it.</c><00:25:28.159><c> But</c><00:25:28.400><c> I</c><00:25:28.640><c> think</c><00:25:28.960><c> being</c> and stuff into it. But I think being and stuff into it. But I think being able<00:25:29.440><c> to</c><00:25:29.600><c> just</c><00:25:29.760><c> focus</c><00:25:30.080><c> more</c><00:25:30.320><c> on</c><00:25:30.559><c> the</c><00:25:30.799><c> knowledge</c> able to just focus more on the knowledge able to just focus more on the knowledge engine<00:25:31.520><c> under</c><00:25:31.760><c> the</c><00:25:31.919><c> hood.</c><00:25:32.400><c> That's</c><00:25:32.559><c> what</c><00:25:32.720><c> a</c><00:25:32.880><c> lot</c> engine under the hood. That's what a lot engine under the hood. That's what a lot of<00:25:33.039><c> people</c><00:25:33.120><c> have</c><00:25:33.279><c> been</c><00:25:33.440><c> telling</c><00:25:33.600><c> me</c><00:25:33.679><c> as</c><00:25:33.840><c> well</c> of people have been telling me as well of people have been telling me as well is<00:25:34.159><c> like</c><00:25:34.320><c> they're</c><00:25:34.480><c> actually</c><00:25:34.720><c> more</c><00:25:34.880><c> excited</c> is like they're actually more excited is like they're actually more excited for<00:25:35.360><c> that</c><00:25:35.600><c> part</c><00:25:35.760><c> of</c><00:25:35.919><c> Archon</c><00:25:36.640><c> versus</c><00:25:36.960><c> the</c> for that part of Archon versus the for that part of Archon versus the actual<00:25:37.520><c> code</c><00:25:37.840><c> generation</c><00:25:38.320><c> because</c><00:25:38.559><c> AI</c><00:25:38.960><c> coding</c> actual code generation because AI coding actual code generation because AI coding assistants<00:25:40.000><c> are</c><00:25:40.320><c> already</c><00:25:40.640><c> knocking</c><00:25:41.039><c> that</c><00:25:41.279><c> out</c> assistants are already knocking that out assistants are already knocking that out of<00:25:41.600><c> the</c><00:25:41.760><c> park.</c><00:25:42.080><c> And</c><00:25:42.240><c> so</c><00:25:43.039><c> that's</c><00:25:43.279><c> enough</c><00:25:43.440><c> of</c><00:25:43.600><c> me</c> of the park. And so that's enough of me of the park. And so that's enough of me babbling<00:25:44.159><c> about</c><00:25:44.480><c> what</c><00:25:44.720><c> I'm</c><00:25:44.880><c> planning</c><00:25:45.120><c> on</c> babbling about what I'm planning on babbling about what I'm planning on changing<00:25:45.600><c> here.</c><00:25:45.760><c> It</c><00:25:45.919><c> is</c><00:25:46.080><c> a</c><00:25:46.240><c> really</c><00:25:46.480><c> big</c><00:25:46.640><c> shift</c> changing here. It is a really big shift changing here. It is a really big shift though<00:25:47.200><c> because</c><00:25:47.360><c> I'm</c><00:25:47.600><c> focusing</c><00:25:48.000><c> I'm</c><00:25:48.240><c> very</c> though because I'm focusing I'm very though because I'm focusing I'm very much<00:25:48.559><c> honing</c><00:25:48.880><c> in</c><00:25:49.039><c> on</c><00:25:49.200><c> one</c><00:25:49.440><c> component</c><00:25:49.679><c> of</c> much honing in on one component of much honing in on one component of Archon<00:25:50.320><c> now.</c><00:25:50.640><c> But</c><00:25:50.880><c> I</c><00:25:51.120><c> think</c><00:25:51.279><c> this</c><00:25:51.520><c> is</c><00:25:51.760><c> best</c><00:25:52.000><c> for</c> Archon now. But I think this is best for Archon now. But I think this is best for the<00:25:52.480><c> future</c><00:25:52.720><c> of</c><00:25:52.960><c> Archon.</c><00:25:53.520><c> But</c><00:25:53.600><c> it</c><00:25:53.840><c> is</c><00:25:53.919><c> a</c><00:25:54.159><c> big</c> the future of Archon. But it is a big the future of Archon. But it is a big decision.<00:25:54.799><c> So</c><00:25:55.039><c> please</c><00:25:55.600><c> let</c><00:25:55.760><c> me</c><00:25:55.919><c> know</c><00:25:56.080><c> what</c><00:25:56.320><c> you</c> decision. So please let me know what you decision. So please let me know what you think.<00:25:57.120><c> That's</c><00:25:57.279><c> what</c><00:25:57.440><c> I've</c><00:25:57.600><c> got</c><00:25:57.760><c> going</c><00:25:57.919><c> on</c><00:25:58.080><c> for</c> think. That's what I've got going on for think. That's what I've got going on for Archon<00:25:58.720><c> right</c><00:25:58.880><c> now.</c><00:25:59.279><c> I</c><00:25:59.520><c> hope</c><00:25:59.600><c> that</c><00:25:59.760><c> this</c><00:26:00.000><c> video</c> Archon right now. I hope that this video Archon right now. I hope that this video has<00:26:00.559><c> really</c><00:26:00.799><c> helped</c><00:26:01.039><c> you</c><00:26:01.200><c> level</c><00:26:01.520><c> up</c><00:26:01.679><c> your</c><00:26:01.840><c> RAG</c> has really helped you level up your RAG has really helped you level up your RAG game,<00:26:02.640><c> taking</c><00:26:02.960><c> pretty</c><00:26:03.200><c> much</c><00:26:03.360><c> any</c><00:26:03.679><c> website</c><00:26:04.080><c> and</c> game, taking pretty much any website and game, taking pretty much any website and bringing<00:26:04.640><c> it</c><00:26:04.799><c> into</c><00:26:05.120><c> your</c><00:26:05.520><c> Vector</c><00:26:05.919><c> database.</c> bringing it into your Vector database. bringing it into your Vector database. And<00:26:06.880><c> also</c><00:26:07.200><c> I</c><00:26:07.360><c> have</c><00:26:07.520><c> a</c><00:26:07.760><c> lot</c><00:26:07.919><c> more</c><00:26:08.240><c> RAG</c><00:26:08.720><c> content</c> And also I have a lot more RAG content And also I have a lot more RAG content coming<00:26:09.360><c> soon,</c><00:26:09.840><c> especially</c><00:26:10.320><c> covering</c> coming soon, especially covering coming soon, especially covering different<00:26:11.360><c> strategies</c><00:26:11.919><c> for</c><00:26:12.080><c> RAG</c><00:26:12.480><c> that</c><00:26:12.640><c> I</c> different strategies for RAG that I different strategies for RAG that I haven't<00:26:13.039><c> talked</c><00:26:13.200><c> about</c><00:26:13.440><c> much</c><00:26:13.679><c> on</c><00:26:13.919><c> my</c><00:26:14.080><c> channel</c> haven't talked about much on my channel haven't talked about much on my channel before.<00:26:14.960><c> I</c><00:26:15.279><c> really</c><00:26:15.600><c> want</c><00:26:15.760><c> to</c><00:26:15.919><c> cover</c><00:26:16.159><c> these</c> before. I really want to cover these before. I really want to cover these things<00:26:16.720><c> like</c><00:26:17.200><c> hierarchical</c><00:26:17.919><c> rag,</c><00:26:18.559><c> contextual</c> things like hierarchical rag, contextual things like hierarchical rag, contextual retrieval,<00:26:19.679><c> query</c><00:26:20.000><c> expansion,</c><00:26:20.480><c> read</c> retrieval, query expansion, read retrieval, query expansion, read ranking.<00:26:21.120><c> There</c><00:26:21.200><c> are</c><00:26:21.360><c> so</c><00:26:21.520><c> many</c><00:26:21.679><c> different</c> ranking. There are so many different ranking. There are so many different strategies<00:26:22.400><c> that</c><00:26:22.640><c> also</c><00:26:22.880><c> go</c><00:26:23.039><c> along</c><00:26:23.360><c> well</c><00:26:23.520><c> with</c> strategies that also go along well with strategies that also go along well with what<00:26:23.840><c> we</c><00:26:24.000><c> just</c><00:26:24.159><c> covered</c><00:26:24.400><c> with</c><00:26:24.720><c> crawl</c><00:26:24.960><c> for</c><00:26:25.200><c> AI.</c> what we just covered with crawl for AI. what we just covered with crawl for AI. So<00:26:26.159><c> definitely</c><00:26:26.720><c> stay</c><00:26:27.039><c> tuned</c><00:26:27.279><c> for</c><00:26:27.520><c> that.</c><00:26:28.159><c> If</c> So definitely stay tuned for that. If So definitely stay tuned for that. If you<00:26:28.559><c> appreciated</c><00:26:28.960><c> this</c><00:26:29.200><c> content</c><00:26:29.440><c> and</c><00:26:29.600><c> you're</c> you appreciated this content and you're you appreciated this content and you're looking<00:26:29.919><c> forward</c><00:26:30.159><c> to</c><00:26:30.400><c> more</c><00:26:30.720><c> things</c><00:26:31.039><c> ragg</c><00:26:31.520><c> and</c> looking forward to more things ragg and looking forward to more things ragg and AI<00:26:31.919><c> agents,</c><00:26:32.559><c> I</c><00:26:32.720><c> would</c><00:26:32.880><c> really</c><00:26:33.120><c> appreciate</c><00:26:33.440><c> a</c> AI agents, I would really appreciate a AI agents, I would really appreciate a like<00:26:33.919><c> and</c><00:26:34.080><c> a</c><00:26:34.320><c> subscribe.</c><00:26:34.799><c> And</c><00:26:35.039><c> with</c><00:26:35.200><c> that,</c><00:26:35.520><c> I</c> like and a subscribe. And with that, I like and a subscribe. And with that, I will<00:26:35.919><c> see</c><00:26:36.080><c> you</c><00:26:36.320><c> in</c><00:26:36.559><c> the</c><00:26:36.720><c> next</c>",
  "extraction_time": "2025-05-15T01:44:33.854598"
}